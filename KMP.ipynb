{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import requests\n",
    "import io\n",
    "import PyPDF2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Implementing KMP Algorithm\n",
    "def KMP(p, t):\n",
    "    M = len(p)  # length of pattern is M\n",
    "    N = len(t)  # length of text is N\n",
    "    # initialization\n",
    "    pi = [0] * M\n",
    "    j = 0\n",
    "    # calculate pi table for the pattern\n",
    "    PiTable(p, M, pi)\n",
    "    i = 0  # index for text to iterate over\n",
    "    while (N - i) >= (M - j):\n",
    "        if p[j] == t[i]:\n",
    "            i += 1\n",
    "            j += 1\n",
    "        if j == M:\n",
    "            print(\"Pattern matched at index \" + str(i - j))\n",
    "            j = pi[j - 1]\n",
    "        # mismatch after j matches\n",
    "        elif i < N and p[j] != t[i]:\n",
    "            # Do not match pi[0..pi[j-1]] characters,\n",
    "            # they will match anyway\n",
    "            if j != 0:\n",
    "                j = pi[j - 1]\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "def PiTable(pat, M, pi):\n",
    "    sub = 0  # length of the previous longest prefix suffix\n",
    "    pi[0] = 0  # lps[0] is always 0\n",
    "    i = 1\n",
    "    # the loop calculates lps[i] for i = 1 to M-1\n",
    "    while i < M:\n",
    "        if pat[i] == pat[sub]:\n",
    "            sub += 1\n",
    "            pi[i] = sub\n",
    "            i += 1\n",
    "        else:\n",
    "            if sub != 0:\n",
    "                sub = pi[sub - 1]\n",
    "                # Also, note that we do not increment i here\n",
    "            else:\n",
    "                pi[i] = 0\n",
    "                i += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Code to extract papers from Arxiv database\n",
    "\n",
    "# Method to extract papers found based on a query, and extract the text and return the concatenated string\n",
    "def extract_papers(query, volume):\n",
    "    search = arxiv.Search(\n",
    "        query = query,\n",
    "        max_results = volume,\n",
    "    )\n",
    "    string = \"\"\n",
    "    for result in search.results():\n",
    "        # Get binary data of the PDF\n",
    "        response = requests.get(result.pdf_url)\n",
    "        pdf_file = io.BytesIO(response.content)\n",
    "        # Read the PDF file\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        num_pages = len(pdf_reader.pages)\n",
    "        # Iterate through each page and extract the text\n",
    "        for page_number in range(num_pages):\n",
    "            pdf_page = pdf_reader.pages[page_number]\n",
    "            text = pdf_page.extract_text()\n",
    "            string += text\n",
    "    return string"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Smoothing Trafﬁc Flow via Control of\n",
      "Autonomous Vehicles\n",
      "Yang Zheng, Member, IEEE , Jiawei Wang, Student Member, IEEE , and Keqiang Li\n",
      "Abstract —The emergence of autonomous vehicles is expected\n",
      "to revolutionize road transportation in the near future. Although\n",
      "large-scale numerical simulations and small-scale experiments\n",
      "have shown promising results, a comprehensive theoretical un-\n",
      "derstanding to smooth trafﬁc ﬂow via autonomous vehicles is\n",
      "lacking. In this paper, from a control-theoretic perspective, we\n",
      "establish analytical results on the controllability, stabilizability,\n",
      "and reachability of a mixed trafﬁc system consisting of human-\n",
      "driven vehicles and autonomous vehicles in a ring road. We show\n",
      "that the mixed trafﬁc system is not completely controllable, but\n",
      "is stabilizable, indicating that autonomous vehicles can not only\n",
      "suppress unstable trafﬁc waves but also guide the trafﬁc ﬂow to\n",
      "a higher speed. Accordingly, we establish the maximum trafﬁc\n",
      "speed achievable via controlling autonomous vehicles. Numerical\n",
      "results show that the trafﬁc speed can be increased by over 6%\n",
      "when there are only 5% autonomous vehicles. We also design\n",
      "an optimal control strategy for autonomous vehicles to actively\n",
      "dampen undesirable perturbations. These theoretical ﬁndings\n",
      "validate the high potential of autonomous vehicles to smooth\n",
      "trafﬁc ﬂow.\n",
      "Index Terms —Autonomous vehicle, mixed trafﬁc ﬂow, control-\n",
      "lability, stabilizability.\n",
      "I. I NTRODUCTION\n",
      "MODERN societies are increasingly relying on complex\n",
      "road transportation systems to support our daily mobil-\n",
      "ity needs. In some big cities, the trafﬁc demand is placing a\n",
      "heavy burden on existing transportation infrastructures, some-\n",
      "times leading to severely congested road networks [1]. Trafﬁc\n",
      "congestion not only results in the loss of fuel economy and\n",
      "travel efﬁciency, but also increases the potential risk of trafﬁc\n",
      "accidents and public health [2].\n",
      "Understanding trafﬁc dynamics is essential if we are to\n",
      "redesign infrastructures, or to guide/control transportation, to\n",
      "mitigate road congestions and smooth trafﬁc ﬂow [3], [4].\n",
      "The subject of trafﬁc dynamics has attracted research interest\n",
      "from many disciplines, including mathematics, physics, and\n",
      "engineering. Since the 1930s, a wide range of models at both\n",
      "the macroscopic and microscopic levels have been proposed\n",
      "Copyright (c) 20xx IEEE. Personal use of this material is permitted.\n",
      "However, permission to use this material for any other purposes must be\n",
      "obtained from the IEEE by sending a request to pubs-permissions@ieee.org.\n",
      "This work is supported by National Key R&D Program of China with\n",
      "2016YFB0100906. The authors also acknowledge the support from TOYOTA.\n",
      "Yang Zheng was with the Department of Engineering Science, University\n",
      "of Oxford, Oxford, OX1 2JD, U.K. He is now with the School of Engineering\n",
      "and Applied Sciences, and the Harvard Center for Green Buildings and Cities,\n",
      "Harvard University, Cambridge, MA 02138 (zhengy@g.harvard.edu).\n",
      "J. Wang and K. Li are with the School of Vehicle and Mobility, Tsinghua\n",
      "University, Beijing, China, and with the Center for Intelligent Connected\n",
      "Vehicles & Transportation, Tsinghua University, Beijing China. (e-mail: wang-\n",
      "jw18@mails.tsinghua.edu.cn, likq@tsinghua.edu.cn). Corresponding author:\n",
      "Keqiang Li.to describe trafﬁc behavior [3]. Based on these trafﬁc models,\n",
      "many control methods have been introduced and implemented\n",
      "to improve the performance of road transportation systems [4].\n",
      "Currently, most control strategies rely on actuators at ﬁxed\n",
      "locations. For example, variable speed advisory or variable\n",
      "speed limits [5] are commonly implemented through trafﬁc\n",
      "signs on roadside infrastructure, and ramp metering [6] typi-\n",
      "cally relies on trafﬁc signals located at the freeway entrances.\n",
      "These strategies are essentially external regulation methods\n",
      "imposed on trafﬁc ﬂow.\n",
      "As a key ingredient of trafﬁc ﬂow, the motion of vehicles\n",
      "plays a fundamental role in road transportation systems. In the\n",
      "past decades, major car-manufacturers and technology com-\n",
      "panies have invested in developing vehicles with high levels\n",
      "of automation, and some prototypes of self-driving cars have\n",
      "been tested in real trafﬁc environments [8]. The emergence of\n",
      "autonomous vehicles (A Vs) and vehicular network is expected\n",
      "to revolutionize road transportation [8]–[10]. In particular, the\n",
      "advancements of autonomous vehicles offer new opportunities\n",
      "for trafﬁc control, where autonomous vehicles can receive\n",
      "information from other trafﬁc participants and act as mobile\n",
      "actuators to inﬂuence trafﬁc ﬂow internally . Most research\n",
      "on the control of trafﬁc ﬂow via autonomous vehicles has\n",
      "focused on platooning of a series of adjacent vehicles or\n",
      "cooperative adaptive cruise control (CACC) [11], [12]. In the\n",
      "context of platoon control, all involved vehicles are assumed\n",
      "to be autonomous and can be controlled to maintain a string\n",
      "stable platoon, such that disturbances along the platoon are\n",
      "dissipated. Signiﬁcant theoretical and practical advances have\n",
      "been made in designing sophisticated controllers at the platoon\n",
      "level [13]–[15].\n",
      "While trafﬁc systems with fully autonomous vehicles may\n",
      "be of great interest in the far future, the near future will\n",
      "have to meet a mixed trafﬁc scenario where both autonomous\n",
      "and human-driven vehicles (HDVs) coexist. In fact, early\n",
      "autonomous vehicles need to cooperate in trafﬁc systems\n",
      "where most vehicles are human-driven. This situation is more\n",
      "challenging in terms of theoretical modeling and stability\n",
      "analysis, and many existing studies are based on numerical\n",
      "simulations [16]–[18]. One recent concept is the connected\n",
      "cruise control that considers mixed trafﬁc scenarios where\n",
      "autonomous vehicles can use the information from multiple\n",
      "HDVs ahead to make control decisions [19], [20]. More\n",
      "recently, Cui et al. ﬁrst pointed out the potential of a single\n",
      "autonomous vehicle in stabilizing mixed trafﬁc ﬂow [21], and\n",
      "they also implemented simple control strategies to demonstrate\n",
      "the dissipation of stop-and-go waves via a single autonomous\n",
      "vehicle in real-world experiments [22]. The control principle isarXiv:1812.09544v2  [math.OC]  10 May 20202\n",
      "(a)\n",
      " (b)\n",
      " (c)\n",
      "Fig. 1. Response proﬁles to an impulse perturbation in trafﬁc systems on a ring road. Vehicle no.2 has an initial perturbation, and the parameters of human-\n",
      "driven vehicles are chosen to resemble the wave behavior in the real-world experiment [7]. (a) All the vehicles are human-driven, where the perturbation is\n",
      "ampliﬁed and stop-and go waves will appear accordingly. (b) Vehicle no.1 is a CACC-equipped vehicle which adjusts its behavior passively according to its\n",
      "direct preceding vehicle. In this case, the perturbation is not ampliﬁed but small trafﬁc waves still persist for a long period. (c) Vehicle no.1 adopts an optimal\n",
      "control strategy considering the global behavior of the entire mixed trafﬁc ﬂow to mitigate undesirable perturbations actively. In this case, the perturbation is\n",
      "attenuated, and the trafﬁc ﬂow becomes smooth quickly.\n",
      "essentially a slow-in fast-out approach, which is an intuitive\n",
      "method to dampen trafﬁc jams [23]. This idea was further\n",
      "studied by analyzing head-to-tail string stability [24]. More\n",
      "sophisticated strategies, such as deep reinforcement learning,\n",
      "have also recently been investigated to improve trafﬁc ﬂow in\n",
      "mixed trafﬁc scenarios via numerical simulations [25], [26].\n",
      "Although the potential of autonomous vehicles has been\n",
      "recognized and demonstrated [21], [22], [24]–[26], a compre-\n",
      "hensive theoretical understanding is still lacking. In principle,\n",
      "the behavior of trafﬁc ﬂow emerges from the collective dynam-\n",
      "ics of many individual human-driven and/or autonomous vehi-\n",
      "cles [3], where autonomous vehicles can serve as controllable\n",
      "nodes. In this paper, we introduce a control-theoretic frame-\n",
      "work for analyzing the mixed trafﬁc system with multiple\n",
      "autonomous vehicles and human-driven vehicles. By viewing\n",
      "the autonomous vehicles as controllable nodes, we analyze the\n",
      "controllability and stabilizability of the mixed trafﬁc system.\n",
      "Moreover, we formulate the problem of designing a control\n",
      "strategy for autonomous vehicles to smooth mixed trafﬁc ﬂow\n",
      "as standardH2optimal control, and discuss the reachability\n",
      "of desired trafﬁc state. Speciﬁcally, the contributions of this\n",
      "paper are:\n",
      "1) We prove for the ﬁrst time that a mixed trafﬁc sys-\n",
      "tem consisting of one autonomous vehicle and multiple\n",
      "human-driven vehicles is not completely controllable, but\n",
      "is stabilizable. This result conﬁrms the high potential\n",
      "of autonomous vehicles in mixed trafﬁc systems: the\n",
      "global trafﬁc velocity can be guided to a desired value by\n",
      "controlling autonomous vehicles properly. Our theoretical\n",
      "results validate the empirical experiments in [22] that a\n",
      "single autonomous vehicle is able to stabilize trafﬁc ﬂow.\n",
      "Note that unlike [21], we prove that there always exists\n",
      "an uncontrollable mode.\n",
      "2) We propose an optimal strategy which utilizes a system-\n",
      "level objective for autonomous vehicles: instead of re-\n",
      "sponding to trafﬁc perturbations passively , it considers the\n",
      "global behavior of the entire mixed trafﬁc ﬂow to mitigate\n",
      "undesirable perturbations actively (see Fig.1 for illustra-\n",
      "tion). The feedback control of autonomous vehicles is\n",
      "formulated into the standard H2optimal synthesis prob-lem [27], where the optimal controller can be computed\n",
      "efﬁciently via convex optimization. Numerical results\n",
      "show a better performance of the proposed controller in\n",
      "smoothing trafﬁc ﬂow and improving fuel economy than\n",
      "existing strategies [22].\n",
      "3) Based on reachability analysis, we show an explicit range\n",
      "for the desired trafﬁc state in the mixed trafﬁc system.\n",
      "Moreover, an upper bound of reachable trafﬁc velocity\n",
      "is derived, indicating that a single autonomous vehicle\n",
      "can not only smooth trafﬁc ﬂow but also increase trafﬁc\n",
      "speed. In the numerical experiments, we observed 6%\n",
      "trafﬁc velocity improvement using only 5% autonomous\n",
      "vehicles.\n",
      "4) Finally, we extend our theoretical framework to the case\n",
      "where multiple autonomous vehicles coexist. We prove\n",
      "that the results on controllability, stabilizability and reach-\n",
      "ability remain similar. Unlike previous works focusing\n",
      "on one single autonomous vehicle only [21], [22], we\n",
      "show that autonomous vehicles can cooperate with each\n",
      "other to reduce the time and energy for attenuating\n",
      "perturbations and smoothing trafﬁc ﬂow. As expected, we\n",
      "conﬁrm that controlling multiple autonomous vehicles has\n",
      "a better performance for large-scale mixed trafﬁc systems.\n",
      "The rest of this paper is organized as follows. Section\n",
      "II introduces the theoretical modeling of a mixed trafﬁc\n",
      "system with one autonomous vehicle. The controllability and\n",
      "stabilizability result is presented in Section III, and Section\n",
      "IV describes the proposed system-level optimal controller and\n",
      "analyzes the reachability of the desired system state. The case\n",
      "of multiple autonomous vehicles is presented in Section V.\n",
      "Numerical simulations are presented in Section VI, and we\n",
      "conclude the paper in Section VII.\n",
      "II. T HEORETICAL MODELLING FRAMEWORK OF MIXED\n",
      "TRAFFIC SYSTEMS\n",
      "In this section, we introduce the modeling of a mixed trafﬁc\n",
      "system with one single autonomous vehicle. We consider a\n",
      "single-lane ring road of length Land withnvehicles. As\n",
      "discussed in Cui et al. [21], the ring road setting has several\n",
      "theoretical advantages for modeling a trafﬁc system, including3\n",
      "1) the existence of experimental results that can be used to\n",
      "calibrate model parameters [7], 2) perfect control of average\n",
      "trafﬁc density, and 3) correspondence with an inﬁnite straight\n",
      "road with periodic trafﬁc dynamics.\n",
      "We denote the position of the i-th vehicle as pi(t)along\n",
      "the ring road, and its velocity is denoted as vi(t) = _pi(t). The\n",
      "spacing of vehicle i,i.e., the distance between two adjacent\n",
      "vehicles, is deﬁned as si(t) =pi\u00001(t)\u0000pi(t). Note that\n",
      "we ignore the vehicle length without loss of generality. For\n",
      "simplicity, we assume that there is one autonomous vehicle\n",
      "and the rest are HDVs in this section. The autonomous vehicle\n",
      "is indexed as no.1. The case of multiple autonomous vehicles\n",
      "will be discussed in Section V.\n",
      "A. Modeling Human-driven Vehicles\n",
      "Human car-following dynamics are typically modeled by\n",
      "nonlinear processes [3], [4]\n",
      "_vi(t) =F(si(t);_si(t);vi(t)); (1)\n",
      "meaning that the acceleration of an HDV is a function of its\n",
      "spacingsi(t), the relative velocity between its own and its\n",
      "preceding vehicle _si(t), and its velocity vi(t). Denotes\u0003;v\u0003\n",
      "as the equilibrium spacing and velocity of each HDV , and then\n",
      "(s\u0003;v\u0003)satisﬁes the following equilibrium equation\n",
      "F(s\u0003;0;v\u0003) = 0; (2)\n",
      "which implies a certain relationship between the equilibrium\n",
      "spacing and equilibrium velocity for HDVs. We deﬁne the\n",
      "error state of the i-th HDV as\n",
      "(\n",
      "~si(t) =si(t)\u0000s\u0003;\n",
      "~vi(t) =vi(t)\u0000v\u0003:\n",
      "Applying the ﬁrst-order Taylor expansion to (1) at (s\u0003;v\u0003)\n",
      "yields a linearized model of each HDV\n",
      "(_~si(t) = ~vi\u00001(t)\u0000~vi(t);\n",
      "_~vi(t) =\u000B1~si(t)\u0000\u000B2~vi(t) +\u000B3~vi\u00001(t);(3)\n",
      "with\u000B1=@F\n",
      "@s;\u000B2=@F\n",
      "@_s\u0000@F\n",
      "@v;\u000B3=@F\n",
      "@_sevaluated at the\n",
      "equilibrium state (s\u0003;v\u0003). These three coefﬁcients reﬂect the\n",
      "driver’s sensitivity to the error state. Considering the real driver\n",
      "behavior, the acceleration should increase when the spacing\n",
      "increases, the velocity of the ego vehicle drops, or the velocity\n",
      "of the preceding vehicle increases. Hence, we assume that\n",
      "\u000B1>0,\u000B2>\u000B 3>0[21], [28].\n",
      "In the following, we choose the optimal velocity model\n",
      "(OVM) [4], [29] to derive explicit expressions of (2) and (3).\n",
      "The OVM model is given by\n",
      "F(si(t);_si(t);vi(t)) =\u000B(V(si(t))\u0000vi(t)) +\f_si(t);(4)\n",
      "where\u000B > 0reﬂects the driver’s sensitivity to the differ-\n",
      "ence between the current velocity and the spacing-dependent\n",
      "desired velocity V(si(t)), and\f > 0reﬂects the driver’s\n",
      "sensitivity to the difference between the velocities of the ego\n",
      "Fig. 2. Nonlinear spacing-dependent desired velocity function V(s)in the\n",
      "OVM model. vmax= 30m=s ,sst= 5mandsgo= 35m. The speciﬁc\n",
      "mathematical expression is shown in (5) and (6). Note that this ﬁgure also\n",
      "illustrates the relationship between equilibrium spacing s\u0003and equilibrium\n",
      "velocityv\u0003, as shown in (7).\n",
      "vehicle and the preceding vehicle. V(si(t))is usually modeled\n",
      "by a continuous piecewise function\n",
      "V(s) =8\n",
      "><\n",
      ">:0; s\u0014sst;\n",
      "fv(s); s st<s<s go;\n",
      "vmax; s\u0015sgo;(5)\n",
      "where the desired velocity V(s)is zero for small spacing sst,\n",
      "and reaches a maximum value vmax for large spacing sgo.\n",
      "fv(s)is a monotonically increasing function and deﬁnes the\n",
      "desired velocity when the spacing sis betweensstandsgo.\n",
      "There are many choices of fv(s), either in a linear or nonlinear\n",
      "form. A typical one is of the following nonlinear form\n",
      "fv(s) =vmax\n",
      "2\u0012\n",
      "1\u0000cos(\u0019s\u0000sst\n",
      "sgo\u0000sst)\u0013\n",
      ": (6)\n",
      "Fig.2 demonstrates a typical example of V(s).\n",
      "For the general OVM model (4), it is easy to obtain the\n",
      "following speciﬁc equilibrium state (s\u0003;v\u0003)that satisﬁes (2)\n",
      "v\u0003=V(s\u0003): (7)\n",
      "Furthermore, we can calculate the values of the coefﬁcients in\n",
      "linearized model (3) as follows\n",
      "\u000B1=\u000B_V(s\u0003); \u000B2=\u000B+\f; \u000B 3=\f; (8)\n",
      "where _V(s\u0003)denotes the derivative of V(s)with respect to s\n",
      "evaluated at the equilibrium spacing s\u0003.\n",
      "B. Modeling Mixed Trafﬁc Systems\n",
      "For the autonomous vehicle, indexed as i= 1, the acceler-\n",
      "ation signal is directly used as the control input u(t), and its\n",
      "car-following model is\n",
      "(_~s1(t) = ~vn(t)\u0000~v1(t);\n",
      "_~v1(t) =u(t);(9)\n",
      "where ~s1(t) =s1(t)\u0000s\u0003\n",
      "c;~v1(t) =vi(t)\u0000v\u0003withs\u0003\n",
      "cbeing\n",
      "a tunable spacing for the autonomous vehicle at velocity v\u0003.\n",
      "Note thats\u0003\n",
      "cis a design parameter for the autonomous vehicle,\n",
      "andv\u0003is the desired trafﬁc velocity, which the autonomous\n",
      "vehicle attempts to steer the trafﬁc ﬂow towards. How to\n",
      "choose a suitable s\u0003\n",
      "cis discussed in Section IV-B.4\n",
      "……\n",
      "…… Motion\n",
      "DirectionTraffic Flow\n",
      "DirectionVehicle 1\n",
      "Vehicle 𝑛𝑛\n",
      "AV\n",
      "Vehicle 2\n",
      "Vehicle 𝑖𝑖 − 1\n",
      "Vehicle 𝑖𝑖\n",
      "Vehicle 𝑖𝑖 + 1\n",
      "HDV\n",
      "Fig. 3. Model establishment schematic. A V: autonomous vehicle; HDV: human-driven vehicle. From left to right, we have (a) the ring road trafﬁc scenario\n",
      "that includes one autonomous vehicle (blue) and n\u00001HDVs (green); (b) a simpliﬁed network system schematic. Purple arrows indicate the interaction\n",
      "between adjacent vehicles, meaning that each HDV considers the state of its preceding vehicle only. Orange arrows show the information ﬂow of the whole\n",
      "system, assuming that the trafﬁc state is observable to the autonomous vehicle; (c) the system matrix Aof the mixed trafﬁc dynamics, as shown in (11).\n",
      "Upon combining the error states of all the vehicles as the\n",
      "mixed trafﬁc system state,\n",
      "x(t) =\u0002~s1(t);~v1(t);:::; ~sn(t);~vn(t)\u0003T;\n",
      "we arrive at the following canonical linear dynamics from a\n",
      "global system viewpoint\n",
      "_x(t) =Ax(t) +Bu(t); (10)\n",
      "where\n",
      "A=2\n",
      "66666664C10::: ::: 0C2\n",
      "A2A10::: ::: 0\n",
      "0A2A10::: 0\n",
      "..................\n",
      "0::: 0A2A10\n",
      "0::: ::: 0A2A13\n",
      "77777775;B=2\n",
      "666664B1\n",
      "B2\n",
      "B2\n",
      "...\n",
      "B23\n",
      "777775;(11)\n",
      "with each block matrix given by\n",
      "A1=\u00140\u00001\n",
      "\u000B1\u0000\u000B2\u0015\n",
      "; A2=\u00140 1\n",
      "0\u000B3\u0015\n",
      ";\n",
      "C1=\u00140\u00001\n",
      "0 0\u0015\n",
      "; C2=\u00140 1\n",
      "0 0\u0015\n",
      "; B1=\u00140\n",
      "1\u0015\n",
      "; B2=\u00140\n",
      "0\u0015\n",
      ":\n",
      "In (10), the evolution of each vehicle’s state is determined\n",
      "by its own state and the state of its direct preceding vehicle\n",
      "only; see Fig.3 for an illustration. In the following, we provide\n",
      "a theoretical analysis on the potential of the autonomous\n",
      "vehicle on smoothing the mixed trafﬁc ﬂow and design an\n",
      "optimal control input u(t)for the autonomous vehicle.\n",
      "III. C ONTROLLABILITY AND STABILIZABILITY\n",
      "Several real-world ﬁeld experiments have shown that trafﬁc\n",
      "waves may easily happen and lead to severe congestions in a\n",
      "ring road trafﬁc system with human-driven vehicles [7], [22].\n",
      "Theoretical results were also established that the linearized\n",
      "trafﬁc system is stable if the following condition holds [21]\n",
      "\u000B2\n",
      "2\u0000\u000B2\n",
      "3\u00002\u000B1\u00150; (12)\n",
      "otherwise, the trafﬁc system may become unstable and small\n",
      "perturbations would cause stop-and-go waves. The condi-\n",
      "tion (12) was ﬁrst derived in [21] using frequency analysis;the interested reader can refer to Appendix B for an alternative\n",
      "proof based on eigenvalue analysis. For the OVM model (4),\n",
      "the criterion (12) is reduced to\n",
      "\u000B+ 2\f\u00152_V(s\u0003); (13)\n",
      "which indicates that to guarantee trafﬁc stability, human\n",
      "drivers should have a quicker response to velocity deviations\n",
      "than the sensitivity of the optimal velocity function with\n",
      "respect to the equilibrium spacing; otherwise stop-and-go\n",
      "waves may happen.\n",
      "Instead of modifying human drivers’ behavior, we reveal in\n",
      "this section that a mixed trafﬁc system can be always stabilized\n",
      "by controlling one single autonomous vehicle. Speciﬁcally,\n",
      "we discuss two fundamental concepts, controllability and\n",
      "stabilizability, of the mixed trafﬁc system (10).\n",
      "A. Controllability Analysis\n",
      "The controllability of a dynamical system captures the\n",
      "ability to guide the system’s behavior towards a desired state\n",
      "using appropriate control inputs, and the system is stabilizable\n",
      "if all uncontrollable modes are stable [27]. We ﬁrst present\n",
      "three useful lemmas [27], [30].\n",
      "Lemma 1 (Controllability): The linear system (A;B)in (10)\n",
      "is controllable if and only if\n",
      "rank\u0002B;AB;:::;A2n\u00001B\u0003\n",
      "= 2n:\n",
      "Lemma 1 is the well-known Kalman’s controllability rank\n",
      "test [30], which provides a necessary and sufﬁcient mathe-\n",
      "matical condition for controllability. However, computing the\n",
      "rank requires all the elements of (A;B)to be known, and it\n",
      "might be numerically unreliable to calculate the rank for large-\n",
      "scale systems. To facilitate analysis, we can apply a certain\n",
      "linear transformation and represent the linear system under a\n",
      "different basis, thus simplifying the system dynamics.\n",
      "In particular, given a nonsingular T, we deﬁne a new state\n",
      "~x=T\u00001x, leading to the following dynamics\n",
      "_~x(t) =T\u00001AT~x(t) +T\u00001Bu(t):\n",
      "Then, we obtain an equivalent linear system (T\u00001AT;T\u00001B).5\n",
      "Lemma 2 (Invariance under linear transformation): The\n",
      "linear system (A;B)is controllable if and only if\n",
      "(T\u00001AT;T\u00001B)is controllable for every nonsingular T.\n",
      "If one can diagonalize the system matrix AviaT\u00001AT,\n",
      "then the controllability of (A;B)will be easier to derive. This\n",
      "diagonalization may be nontrivial for its original form (A;B).\n",
      "In this case, we can ﬁrst apply a certain state feedback to\n",
      "simplify the system dynamics. Speciﬁcally, consider a control\n",
      "lawv(t) =u(t) +Kx(t), and we arrive at\n",
      "_x(t) = (A\u0000BK)x(t) +Bv(t):\n",
      "Lemma 3 (Invariance under state feedback): The linear\n",
      "system (A;B)is controllable if and only if (A\u0000BK;B )\n",
      "is controllable for every Kwith compatible dimension.\n",
      "Now, we are ready to present the result on the controllability\n",
      "of the mixed trafﬁc system (10).\n",
      "Theorem 1: Consider the mixed trafﬁc system in a ring road\n",
      "with one A V and n\u00001HDVs given by (10). We have\n",
      "1) The system is not completely controllable.\n",
      "2) There exists one uncontrollable mode corresponding to a\n",
      "zero eigenvalue, and this uncontrollable mode is stable.\n",
      "Proof: Our main idea is to exploit the invariance of\n",
      "controllability under linear transformation and state feedback.\n",
      "Using a sequence of state feedback and linear transformation,\n",
      "we diagonalize the system, leading to an analytical conclusion\n",
      "on the controllability of (10). Our procedure is as follows.\n",
      "(A;B)state feedback\u0000\u0000\u0000\u0000\u0000\u0000\u0000! (^A;B)linear transformation\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000! (eA;eB)\n",
      "First, we transform system (A;B)into(^A;B)by introduc-\n",
      "ing a virtual input ^u(t), deﬁned as\n",
      "^u(t) =u(t)\u0000(\u000B1~s1(t)\u0000\u000B2~v1(t) +\u000B3~vn(t));\n",
      "which is the difference between the actual control value and\n",
      "the acceleration value when the vehicle is controlled by a\n",
      "human driver. Then, the state space model of (^A;B)becomes\n",
      "_x(t) =^Ax(t) +B^u(t);\n",
      "where\n",
      "^A=2\n",
      "66666664A10::: ::: 0A2\n",
      "A2A10::: ::: 0\n",
      "0A2A10::: 0\n",
      "..................\n",
      "0::: 0A2A10\n",
      "0::: ::: 0A2A13\n",
      "77777775: (14)\n",
      "According to Lemma 3, the controllability remains the same\n",
      "between system (^A;B)and the original system (A;B). Note\n",
      "that ^Ais block circulant, and it can be diagonalized by the\n",
      "Fourier matrix Fn[31], [32]. We refer the interested reader\n",
      "to Appendix A for the Fourier matrix Fnas well as precise\n",
      "deﬁnitions and properties of block circulant matrices.\n",
      "Deﬁne!=e2\u0019j\n",
      "nwherej=p\u00001denotes the imaginary\n",
      "unit, and deﬁne Fngiven by (44) in Appendix A. Then, we\n",
      "use the transformation matrix F\u0003\n",
      "n\n",
      "I2to transform (^A;B)\n",
      "into(eA;eB), whereF\u0003\n",
      "ndenotes the conjugate transpose of Fn.\n",
      "The new system matrix is\n",
      "eA= (F\u0003\n",
      "n\n",
      "I2)\u00001^A(F\u0003\n",
      "n\n",
      "I2) =diag(D1;D2;:::;Dn);(15)where\n",
      "denotes the Kronecker product, and\n",
      "Di=A1+A2!(n\u00001)(i\u00001)\n",
      "=\u0014\n",
      "0\u00001 +!(n\u00001)(i\u00001)\n",
      "\u000B1\u0000\u000B2+\u000B3!(n\u00001)(i\u00001)\u0015\n",
      ";i= 1;2;:::;n;(16)\n",
      "and diag (D1;D2;:::;Dn)denotes a block-diagonal matrix\n",
      "withD1;D2;:::;Dnon its diagonal. Using the fact that Fnis\n",
      "a unitary matrix, the new state variable ~xafter transformation\n",
      "becomes\n",
      "~x= (F\u0003\n",
      "n\n",
      "I2)\u00001x= (Fn\n",
      "I2)x; (17)\n",
      "and the new control matrix eBis\n",
      "eB= (F\u0003\n",
      "n\n",
      "I2)\u00001B=1pn2\n",
      "6664B1\n",
      "B1\n",
      "...\n",
      "B13\n",
      "7775:\n",
      "Therefore, the dynamics of ~xare\n",
      "_~x=eA~x(t) +eB^u(t)\n",
      "=2\n",
      "6664D1\n",
      "D2\n",
      "...\n",
      "Dn3\n",
      "7775~x(t) +1pn2\n",
      "6664B1\n",
      "B1\n",
      "...\n",
      "B13\n",
      "7775^u(t):(18)\n",
      "Upon denoting ~x(t) =\u0002~x11;~x12;~x21;~x22;:::; ~xn1;~xn2\u0003T,\n",
      "(eA;eB)is decoupled into nindependent subsystems\n",
      "d\n",
      "dt\u0014~xi1\n",
      "~xi2\u0015\n",
      "=Di\u0014~xi1\n",
      "~xi2\u0015\n",
      "+\u00140\n",
      "1pn\u0015\n",
      "^u(t)\n",
      "=\u00140\u00001 +!(n\u00001)(i\u00001)\n",
      "\u000B1\u0000\u000B2+\u000B3!(n\u00001)(i\u00001)\u0015\u0014~xi1\n",
      "~xi2\u0015\n",
      "+\u00140\n",
      "1pn\u0015\n",
      "^u(t):\n",
      "It is easy to verify that _~x11= 0, which means that ~x11is\n",
      "an uncontrollable component, but remains constant during the\n",
      "dynamic evolution. According to ex= (F\u0003\n",
      "n\n",
      "I2)\u00001x, we know\n",
      "~x11=1pn \n",
      "(s1(t)\u0000s\u0003\n",
      "c) +nX\n",
      "i=2(si(t)\u0000s\u0003)!\n",
      ": (19)\n",
      "Note that system (~A;~B)is equivalent to system (^A;B)due\n",
      "to the linear transformation. Also, system (^A;B)has the same\n",
      "controllability characteristic as the original system (A;B).\n",
      "Therefore, we conclude that the original system (A;B)is not\n",
      "completely controllable and has at least one uncontrollable\n",
      "component which remains constant, as shown in (19).\n",
      "Furthermore, the uncontrollable component ~x11corresponds\n",
      "to a zero eigenvalue. Since this zero eigenvalue only appears in\n",
      "D1(see the expression of Diin (16)), its algebraic multiplicity\n",
      "in^Ais one. Hence, we conclude that the uncontrollable mode\n",
      "is stable.\n",
      "We remark that the uncontrollable mode (19) has a clear\n",
      "physical interpretation: the sum of each vehicle’s spacing\n",
      "should remain constant due to the ring road structure of the\n",
      "mixed trafﬁc system. Theorem 1 differs from the results of [21]\n",
      "in two aspects: 1) we explicitly point out the existence of\n",
      "the uncontrollable mode (19); 2) our proof exploits the block\n",
      "circulant property of the mixed trafﬁc system.6\n",
      "B. Stabilizability Analysis\n",
      "After revealing the uncontrollable component (19), we next\n",
      "prove that the mixed trafﬁc system is stabilizable. We need\n",
      "the following PBH test for our stabilizability analysis.\n",
      "Lemma 4 (PBH controllability criterion): The linear system\n",
      "(A;B)is controllable if and only if rank (\u0015I\u0000A;B) = 2nfor\n",
      "every eigenvalue \u0015ofA. In addition, (A;B)is uncontrollable\n",
      "if and only if there exists !6= 0, such that\n",
      "!TA=\u0015!T;!TB= 0;\n",
      "where!is a left eigenvector of Acorresponding to \u0015, and!\n",
      "corresponds to an uncontrollable mode.\n",
      "Theorem 2: Consider the mixed trafﬁc system in a ring road\n",
      "with one A V and n\u00001HDVs given by (10). We have\n",
      "1) The controllability matrix Qc=\u0002B;AB;:::;A2n\u00001B\u0003\n",
      "satisﬁes\n",
      "rank(Qc) =(\n",
      "2n\u00001;if\u000B1\u0000\u000B2\u000B3+\u000B2\n",
      "36= 0;\n",
      "n; if\u000B1\u0000\u000B2\u000B3+\u000B2\n",
      "3= 0:(20)\n",
      "2) The mixed trafﬁc system (10) is stabilizable.\n",
      "Proof: As proved in Theorem 1, systems (eA;eB)and\n",
      "(A;B)share the same controllability characteristics. Here, we\n",
      "focus on (eA;eB), and the main idea is to characterize all the\n",
      "uncontrollable modes and prove that they are all stable.\n",
      "\u000FCase 1:\u000B1\u0000\u000B2\u000B3+\u000B2\n",
      "36= 0.\n",
      "SinceeAin (18) is block diagonal, we have\n",
      "det(\u0015I\u0000eA) =nY\n",
      "i=1det(\u0015I\u0000Di) = 0; (21)\n",
      "where\u0015denotes an eigenvalue of eA. Substituting (16) into\n",
      "(21) leads to the following equation ( i= 1;2;:::;n )\n",
      "\u00152+\u0010\n",
      "\u000B2\u0000\u000B3!(n\u00001)(i\u00001)\u0011\n",
      "\u0015+\u000B1\u0010\n",
      "1\u0000!(n\u00001)(i\u00001)\u0011\n",
      "= 0:\n",
      "(22)\n",
      "Note that (22) is a second-order complex equation and it is\n",
      "non-trivial to directly get its analytical roots. Instead, we use\n",
      "this equation to analyze the properties of the eigenvalues. The\n",
      "following proof is divided into two steps.\n",
      "Step 1: We prove that DiandDj(i6=j) share no common\n",
      "eigenvalues. Assume there exists a \u0015satisfying det (\u0015I\u0000Di) =\n",
      "0and det (\u0015I\u0000Dj) = 0 ,i6=j, which means\n",
      "(\n",
      "\u00152+\u000B2\u0015+\u000B1= (\u000B3\u0015+\u000B1)!(n\u00001)(i\u00001);\n",
      "\u00152+\u000B2\u0015+\u000B1= (\u000B3\u0015+\u000B1)!(n\u00001)(j\u00001):\n",
      "Since!(n\u00001)(i\u00001)6=!(n\u00001)(j\u00001), we obtain \u000B3\u0015+\u000B1= 0\n",
      "and\u00152+\u000B2\u0015+\u000B1= 0, leading to\n",
      "\u000B1\u0000\u000B2\u000B3+\u000B2\n",
      "3= 0; \u0015=\u000B3\u0000\u000B2;\n",
      "which contradicts the condition that \u000B1\u0000\u000B2\u000B3+\u000B2\n",
      "36= 0.\n",
      "Therefore,DiandDj(j6=i)have different eigenvalues.\n",
      "Step 2: We prove that all the system modes corresponding\n",
      "to non-zero eigenvalues are controllable. Denote \u0015k6= 0as the\n",
      "eigenvalue of Dkand\u001Aas its corresponding left eigenvector.\n",
      "According to Lemma 4, we need to show \u001ATeB6= 0.Upon denoting \u001A=\u0002\n",
      "\u001AT\n",
      "1;\u001AT\n",
      "2;:::;\u001AT\n",
      "n\u0003Twhere\u001Ai=\u0002\u001Ai1;\u001Ai2\u0003T2R2\u00021;i= 1;2;:::;n , the condition \u001ATeA=\n",
      "\u0015k\u001ATleads to\n",
      "\u001AT\n",
      "iDi=\u0015k\u001AT\n",
      "i; i= 1;2;:::;n: (23)\n",
      "Since\u0015kis not an eigenvalue of Di; i6=k, we obtain \u001Ai=\n",
      "0; i6=k. Hence,\u001ATeB=\u001AT\n",
      "kB1=\u001Ak2. Assume\u001Ak2= 0, then\n",
      "substituting (16) into (23) yields\n",
      "\u0002\n",
      "\u001Ak10\u0003\u00140\u00001 +!(n\u00001)(k\u00001)\n",
      "\u000B1\u0000\u000B2+\u000B3!(n\u00001)(k\u00001)\u0015\n",
      "=\u0015k\u0002\n",
      "\u001Ak10\u0003\n",
      ":\n",
      "(24)\n",
      "The only solution to (24) is \u001Ak1= 0 , indicating that\n",
      "the left eigenvector \u001A= 0, which is false. Accordingly, the\n",
      "assumption that \u001Ak2= 0 does not hold. Therefore, we have\n",
      "\u001ATeB=\u001Ak26= 0, meaning that the mode corresponding to \u0015kis\n",
      "controllable. In other words, the system modes corresponding\n",
      "to nonzero eigenvalues are all controllable. Because the only\n",
      "zero eigenvalue \u0015= 0 appears in det (\u0015I\u0000D1) = 0 and\n",
      "the corresponding mode is uncontrollable, we conclude that if\n",
      "\u000B1\u0000\u000B2\u000B3+\u000B2\n",
      "36= 0, there are 2n\u00001controllable modes in\n",
      "the system (eA;eB), meaning that rank (Qc) = 2n\u00001.\n",
      "\u000FCase 2:\u000B1\u0000\u000B2\u000B3+\u000B2\n",
      "3= 0.\n",
      "Substituting this condition into (22) yields\n",
      "(\u0015+\u000B2\u0000\u000B3)\u0010\n",
      "\u0015+\u000B3\u0000\u000B3!(n\u00001)(i\u00001)\u0011\n",
      "= 0; i= 1;2;:::;n;\n",
      "which gives the eigenvalues of Dias follows\n",
      "\u0015i1=\u000B3\u0000\u000B2; \u0015i2=\u000B3\u0010\n",
      "!(n\u00001)(i\u00001)\u00001\u0011\n",
      ":\n",
      "The rest proof is organized into two steps.\n",
      "Step 1: we prove that there are n\u00001uncontrollable modes\n",
      "corresponding to \u000B3\u0000\u000B2. It is easy to see that \u000B3\u0000\u000B2is the\n",
      "common eigenvalue for each block Di; i= 1;2;:::;n ,i.e.,\n",
      "the algebraic multiplicity of \u000B3\u0000\u000B2isn. We consider its left\n",
      "eigenvector \u001A=\u0002\n",
      "\u001AT\n",
      "1;\u001AT\n",
      "2;:::;\u001AT\n",
      "n\u0003T. Similar to (23), we obtain\n",
      "\u001AT\n",
      "iDi= (\u000B3\u0000\u000B2)\u001AT\n",
      "i; i= 1;2;:::;n:\n",
      "Expanding this equation leads to\n",
      "\u0002\n",
      "\u001Ai1\u001Ai2\u0003\u00140\u00001 +!(n\u00001)(i\u00001)\n",
      "\u000B1\u0000\u000B2+\u000B3!(n\u00001)(i\u00001)\u0015\n",
      "= (\u000B3\u0000\u000B2)\u0002\n",
      "\u001Ai1\u001Ai2\u0003\n",
      ";\n",
      "from which we have \u001Ai1=\u0000\u000B3\u001Ai2; i= 1;2;:::;n: There-\n",
      "fore, we can choose nlinearly independent left eigenvectors\n",
      "corresponding to \u000B3\u0000\u000B2as\n",
      "\u001A(1)=\u0002\u0000\u000B3;1;0;0;0;0;:::; 0;0\u0003\n",
      ";\n",
      "\u001A(2)=\u0002\n",
      "\u0000\u000B3;1;\u000B3;\u00001;0;0;:::; 0;0\u0003\n",
      ";\n",
      "\u001A(3)=\u0002\u0000\u000B3;1;0;0;\u000B3;\u00001;:::; 0;0\u0003\n",
      ";\n",
      "...\n",
      "\u001A(n)=\u0002\u0000\u000B3;1;0;0;0;0:::;\u000B 3;\u00001\u0003\n",
      ":(25)\n",
      "From these left eigenvectors, it is easy to verify that\u0000\n",
      "\u001A(1)\u0001TeB6= 0 and\u0000\n",
      "\u001A(i)\u0001TeB= 0; i= 2;3;:::;n , meaning\n",
      "that for\u000B3\u0000\u000B2, there aren\u00001uncontrollable modes.\n",
      "Step 2: we consider the rest of eigenvalues, i.e.\n",
      "\u0015i2=\u000B3\u0010\n",
      "!(n\u00001)(i\u00001)\u00001\u0011\n",
      "; i= 1;2;:::;n:7\n",
      "The zero eigenvalue \u001512= 0 still corresponds to an uncon-\n",
      "trollable mode, as shown in (19). We prove that the modes\n",
      "associated with \u0015i2=\u000B3\u0000\n",
      "!(n\u00001)(i\u00001)\u00001\u0001\n",
      "; i= 2;3;:::;n\n",
      "are controllable. The proof is similar to the case of \u000B1\u0000\u000B2\u000B3+\n",
      "\u000B2\n",
      "36= 0. For\u0015k2=\u000B3\u0000\n",
      "!(n\u00001)(k\u00001)\u00001\u0001\n",
      ";(k6= 1) , denote\n",
      "its left eigenvector as\n",
      "\u001A=\u0002\n",
      "\u001AT\n",
      "1;\u001AT\n",
      "2;:::;\u001AT\n",
      "n\u0003T;\n",
      "where\u001Ai=\u0002\u001Ai1;\u001Ai2\u0003T2R2\u00021;i= 1;2;:::;n . Then we have\n",
      "\u001Ai= 0; i6=k, since\u0015k2is not an eigenvalue of other blocks\n",
      "Di; i6=k. For\u001Ak=\u0002\u001Ak1;\u001Ak2\u0003T, we have\u001Ak26= 0, which is\n",
      "similar to the argument in (24). Therefore, \u001ATeB6= 0, meaning\n",
      "that the mode corresponding to \u0015k2(k6= 1) is controllable.\n",
      "In summary, the eigenvalue \u0015=\u000B3\u0000\u000B2is associ-\n",
      "ated withn\u00001uncontrollable modes and one controllable\n",
      "mode. Since \u0015=\u000B3\u0000\u000B2<0, the uncontrollable modes\n",
      "are all stable. The n\u00001modes associated with \u0015i2=\n",
      "\u000B3\u0000\n",
      "!(n\u00001)(i\u00001)\u00001\u0001\n",
      "; i= 2;3;:::;n are controllable, and\n",
      "the zero eigenvalue corresponds to an uncontrollable mode.\n",
      "In total, there are ncontrollable modes in the system (eA;eB),\n",
      "meaning that rank (Qc) =n. Finally, the system (A;B)is\n",
      "stabilizable since all its uncontrollable mode are stable.\n",
      "Theorem 2 shows that the mixed trafﬁc system (10) always\n",
      "has one uncontrollable mode corresponding to a zero eigen-\n",
      "value, and the rest of modes are either controllable or stable.\n",
      "This result has no requirement on the car-following behavior of\n",
      "other human-driven vehicles or the scale nof the mixed trafﬁc\n",
      "system. By choosing an appropriate control input, one single\n",
      "autonomous vehicle can always stabilize the global trafﬁc ﬂow\n",
      "at an equilibrium trafﬁc velocity.\n",
      "IV. O PTIMAL CONTROL AND REACHABILITY ANALYSIS\n",
      "We have shown that a mixed trafﬁc system with one single\n",
      "autonomous vehicle is always stabilizable. In this section,\n",
      "we proceed to design an optimal control strategy to reject\n",
      "perturbations in the mixed trafﬁc system using standard control\n",
      "theory [27]. Moreover, we discuss the reachability of the\n",
      "equilibrium trafﬁc state and show that the autonomous vehicle\n",
      "can increase the trafﬁc equilibrium velocity.\n",
      "A. Optimal Control Formulation and its Solution\n",
      "To reﬂect trafﬁc perturbations, we assume that there exists a\n",
      "disturbance signal wi(t)in each vehicle’s acceleration signal,\n",
      "i.e.,_~vi=\u000B1~si(t)\u0000\u000B2~vi(t)+\u000B3~vi\u00001(t)+wi(t):The linearized\n",
      "dynamics of HDVs in (10) become\n",
      "_xi(t) =A1xi(t) +A2xi\u00001(t) +H1wi(t);\n",
      "withH1=\u00020;1\u0003T.\n",
      "Then, we design an optimal control input u(t) =\u0000Kx(t)\n",
      "to minimize the inﬂuence of disturbances wi(t)on the traf-\n",
      "ﬁc system, where K2R1\u00022ndenotes the feedback gain.\n",
      "Mathematically, this can be formulated into the following\n",
      "optimization problem\n",
      "min\n",
      "KkGzwk2\n",
      "subject to u=\u0000Kx;(26)whereGzwdenotes the transfer function from disturbance\n",
      "signalw(t) =\u0002w1(t);:::;wn(t)\u0003\n",
      "to the performance state\n",
      "uu(t)\u0003T;:::;\n",
      "u>0, andk\u0001kdenoteshts \n",
      "theH2norm of a transfer function that captures the inﬂuence\n",
      "of disturbances. Note that the performance state can also be\n",
      "written into\n",
      "z(t) =\u0014\n",
      "Q1\n",
      "2\n",
      "0\u0015\n",
      "x(t) +\u00140\n",
      "R1\n",
      "2\u0015\n",
      "u(t); (27)\n",
      "whereQ1\n",
      "v)andR1\n",
      "udenote\n",
      "the square roots of state and control performance weights,\n",
      "respectively.\n",
      "The optimization problem (26) is in the standard form of the\n",
      "H2optimal controller synthesis [27]. Here, we brieﬂy present\n",
      "the steps to obtain a convex formulation for (26).\n",
      "Lemma 5 (H2norm of a transfer function [27]): Given a\n",
      "stable linear system _x(t) =Ax(t) +Hw(t);z(t) =Cx(t),\n",
      "theH2norm of the transfer function from disturbance w(t)\n",
      "to performance signal z(t)can be computed by\n",
      "kGzwk2= inf\n",
      "X\u001F0fTrace\u0000\n",
      "CXCT\u0001\n",
      "jAX+XAT+HHT\u00160g;\n",
      "where Trace (\u0001)denotes the trace of a symmetric matrix.\n",
      "When applying state-feedback u=\u0000Kx, the dynamics of\n",
      "the closed-loop trafﬁc system become\n",
      "_x(t) = (A\u0000BK)x(t) +Hw(t);\n",
      "z(t) =\u0014Q1\n",
      "2\n",
      "\u0000R1\n",
      "2K\u0015\n",
      "x(t):(28)\n",
      "Using Lemma 5 and a standard change of variables Z=KX,\n",
      "the optimal control problem (26) can be equivalently reformu-\n",
      "lated as\n",
      "min\n",
      "X;ZTrace (QX) +Trace\u0000\n",
      "RZX\u00001ZT\u0001\n",
      "subject to (AX\u0000BZ) + (AX\u0000BZ)T+HHT\u00160;\n",
      "X\u001F0:\n",
      "By introducing Y\u0017ZX\u00001ZTand using the Schur com-\n",
      "plement, a convex reformulation to (26) is derived as follows.\n",
      "min\n",
      "X;Y;ZTrace (QX) +Trace (RY)\n",
      "subject to (AX\u0000BZ) + (AX\u0000BZ)T+HHT\u00160;\u0014Y Z\n",
      "ZTX\u0015\n",
      "\u00170;X\u001F0:\n",
      "(29)\n",
      "Problem (29) is convex and ready to be solved using general\n",
      "conic solvers, e.g., Mosek [33], and the optimal controller is\n",
      "recovered as K=ZX\u00001.\n",
      "Remark 1 (Active response to trafﬁc perturbations): Some\n",
      "traditional strategies for autonomous vehicles, e.g., CACC\n",
      "[13], [14], mainly focus on the performance of the autonomous\n",
      "vehicles themselves, corresponding to a local-level considera-\n",
      "tion, and they typically respond to external perturbations in a\n",
      "passive way. Although they can improve trafﬁc stability in\n",
      "mixed trafﬁc ﬂow [16], [17], there always exists a certain\n",
      "requirement on the penetration rate of autonomous vehicles.8\n",
      "Instead, our formulation directly considers the global trafﬁc\n",
      "behavior, i.e., the state and behavior of all the involved vehi-\n",
      "cles, and aims at minimizing the inﬂuence of disturbances on\n",
      "the entire trafﬁc system via controlling autonomous vehicles.\n",
      "In this way, the resulting system-level strategy enables au-\n",
      "tonomous vehicles to respond to trafﬁc perturbations actively;\n",
      "see Fig. 1 for an illustration.\n",
      "Remark 2 (Parameter selection of controllers): There al-\n",
      "ready exist several control strategies for autonomous vehicles\n",
      "to stabilize trafﬁc ﬂow, e.g., FollowerStopper and PI with\n",
      "Saturation in [22]. We note that there are many parameters that\n",
      "need to be pre-determined in these strategies. Different choices\n",
      "of parameter values may lead to different performance, which\n",
      "are not completely predictable. Instead, only three parameters\n",
      "need to be designed in (26), i.e., the weight coefﬁcients in\n",
      "u. Moreover, we can adjust\n",
      "their values to achieve different and predictable results. For\n",
      "vtypically allowsa larger value to \n",
      "to stabilize the trafﬁc in a shorter time, and setting a larger\n",
      "unormally helps to keep a lower control energy for\n",
      "the autonomous vehicle.\n",
      "Remark 3 (Feasibility of the proposed strategy): Prob-\n",
      "lem (29) can be formulated into a standard semideﬁnite\n",
      "program (SDP), for which there exist efﬁcient algorithms to\n",
      "get a solution of arbitral accuracy in polynomial time [34].\n",
      "In particular, the well-established interior-point method has\n",
      "a computational complexity of O(max(m;n)mn2:5), where\n",
      "nis the dimension of the positive semideﬁnite constraint\n",
      "andmis the number of equality constraints in a standard\n",
      "SDP [34]. In this paper, we use the conic solver Mosek [33]\n",
      "to solve the resulting SDP from (29). In addition, computing\n",
      "the optimal control strategy from (29) requires explicit car-\n",
      "following models of HDVs; see (1). Lyapunov-type meth-\n",
      "ods [35] and data-driven methods [36] have been proposed\n",
      "for practical estimation of car-following behaviors based on\n",
      "vehicle trajectories. It would be interesting for future work to\n",
      "incorporate model identiﬁcation in the design of robust optimal\n",
      "control strategies.\n",
      "B. Reachability and Maximum Trafﬁc Velocity\n",
      "We have shown that the mixed trafﬁc system is always\n",
      "s,abilizable and upon choosing the weight coefﬁcients \n",
      "u, we can solve (29) to obtain an optimal control\n",
      "strategyu(t) =\u0000Kx(t)to reject the inﬂuence of disturbances.\n",
      "Considering the deﬁnition of state x(t)and denoting K=\u0002k1;1;k1;2;k2;1;k2;2;;:::;kn;1;kn;2\u0003\n",
      "2R1\u00022n, the optimal\n",
      "control strategy is implemented as\n",
      "u(t) =\u0000(k1;1(s1(t)\u0000s\u0003\n",
      "c) +k1;2(v1(t)\u0000v\u0003))\n",
      "\u0000nX\n",
      "i=2(ki;1(si(t)\u0000s\u0003) +ki;2(vi(t)\u0000v\u0003)):(30)\n",
      "Recall that (s\u0003;v\u0003)is the trafﬁc equilibrium state of HDVs\n",
      "satisfying (2), and s\u0003\n",
      "c>0is the desired spacing for the\n",
      "autonomous vehicle that is free to choose. We observe that an\n",
      "improper choice of s\u0003\n",
      "cmay cause the mixed trafﬁc system to\n",
      "fail to reach the desired velocity v\u0003due to the uncontrollable\n",
      "mode (19). In fact, we can further predict the system ﬁnalstate, which sheds some insight on the reachability of the\n",
      "equilibrium trafﬁc state.\n",
      "The result of reachability is stated as follows.\n",
      "Theorem 3: Consider the mixed trafﬁc system in a ring\n",
      "road with one A V and n\u00001HDVs given by (10). Suppose a\n",
      "stabilizing feedback gain is found by (26) and the matrix (34)\n",
      "is non-singular. Then the trafﬁc system is stabilized at v\u0003if\n",
      "and only if the desired spacing s\u0003\n",
      "cof the A V satisﬁes\n",
      "s\u0003\n",
      "c=L\u0000(n\u00001)s\u0003; (31)\n",
      "withs\u0003given by the equilibrium equation (2).\n",
      "Proof: With a stabilizing controller for the autonomous\n",
      "vehicle, the mixed trafﬁc system (10) is stable and the state\n",
      "x(t)will approach an equilibrium point, where _x(t) = 0 . We\n",
      "analyze the dynamics of each vehicle in (3) and (9) separately,\n",
      "leading to\n",
      "~s1(tf) =se;~vi(tf) =ve;~si(tf) =\u000B2\u0000\u000B3\n",
      "\u000B1ve; i= 2;3;:::;n;\n",
      "wherese;veare constant values, and tfis the time when the\n",
      "system reaches its equilibrium point. Considering the desired\n",
      "state in the controller xdes=\u0002s\u0003\n",
      "c;v\u0003;s\u0003;v\u0003;:::;s\u0003;v\u0003\u0003T, the\n",
      "ﬁnal state of the system (10) must be in the following form\n",
      "xf=\u0002sf,A V;vf;sf,HDV;vf;:::;s f,HDV;vf\u0003T; (32)\n",
      "wheresf,A V=s\u0003\n",
      "c+se,sf,HDV =s\u0003+\u000B2\u0000\u000B3\n",
      "\u000B1ve,vf=v\u0003+ve.\n",
      "We next calculate the exact value of seandve. In the ﬁnal\n",
      "state, all the vehicles have zero acceleration, indicating that\n",
      "the control input u(t)must be zero, i.e.,u(t) =\u0000Kx(t) = 0 .\n",
      "Besides, according to the controllability analysis, we know\n",
      "that there exists an uncontrollable mode (s1(t)\u0000s\u0003\n",
      "c) +Pn\n",
      "i=2(si(t)\u0000s\u0003)remaining constant; see (19). Combining\n",
      "these two conditions leads to the following linear equations\n",
      "(\u0010\n",
      "\u000B2\u0000\u000B3\n",
      "\u000B1\u0006n\n",
      "i=2ki;1+ \u0006n\n",
      "i=1ki;2\u0011\n",
      "ve+k1;1se= 0;\n",
      "(n\u00001)\u000B2\u0000\u000B3\n",
      "\u000B1ve+se=L\u0000(n\u00001)s\u0003\u0000s\u0003\n",
      "c;(33)\n",
      "and its solution offers the exact value of seandve,i.e.,\n",
      "\u0014se\n",
      "ve\u0015\n",
      "=M\u00001\u00140\n",
      "L\u0000(n\u00001)s\u0003\u0000s\u0003\n",
      "c\u0015\n",
      ";\n",
      "whereMis a non-singular matrix as\n",
      "M=\u0014\u000B2\u0000\u000B3\n",
      "\u000B1\u0006n\n",
      "i=2ki;1+ \u0006n\n",
      "i=1ki;2k1;1\n",
      "(n\u00001)\u000B2\u0000\u000B3\n",
      "\u000B11\u0015\n",
      ": (34)\n",
      "To reach the desired equilibrium state (s\u0003;v\u0003), we should\n",
      "havese= 0 andve= 0, which is equivalent to L\u0000(n\u0000\n",
      "1)s\u0003\u0000s\u0003\n",
      "c= 0:This completes our proof.\n",
      "Since the mixed trafﬁc system in (10) is stabilizable, it can\n",
      "be guided to reach any equilibrium state with trafﬁc speed v\u0003\n",
      "via controlling the autonomous vehicle properly. In practice,\n",
      "however, the spacing of the autonomous vehicle cannot be\n",
      "negative, i.e.,s\u0003\n",
      "c>0, which is equivalent to\n",
      "s\u0003\n",
      "max<L\n",
      "n\u00001: (35)\n",
      "Recall that (s\u0003;v\u0003)should satisfy the HDV equilibrium equa-\n",
      "tionF(s\u0003;0;v\u0003), andv\u0003usually increases as s\u0003grows up9\n",
      "according to the real driving behavior, as illustrated in Fig.2 for\n",
      "the OVM model. Therefore, the requirement of the equilibrium\n",
      "spacing in (35) sets up a maximum equilibrium trafﬁc velocity\n",
      "v\u0003\n",
      "max. This leads to the following result.\n",
      "Corollary 1 (Range of reachable trafﬁc velocity): There\n",
      "exists a reachable range for the trafﬁc velocity in the mixed\n",
      "trafﬁc system (10):\n",
      "06v\u0003<v\u0003\n",
      "max; (36)\n",
      "wherev\u0003\n",
      "max satisﬁes\n",
      "F\u0012L\n",
      "n\u00001;0;v\u0003\n",
      "max\u0013\n",
      "= 0:\n",
      "This result reveals the upper bound of reachable trafﬁc ve-\n",
      "locity, indicating that mixed trafﬁc ﬂow with one autonomous\n",
      "vehicle can be steered exactly towards a velocity within the\n",
      "range of (0;v\u0003\n",
      "max). Note that v\u0003\n",
      "max is higher than the equi-\n",
      "librium trafﬁc speed with HDVs only, where the equilibrium\n",
      "spacing iss\u0003=L=n. A physical interpretation is that the\n",
      "autonomous vehicle can follow its preceding vehicle at a\n",
      "shorter distance and leave more space for its following HDVs,\n",
      "which in turn triggers the HDVs to travel at a higher speed in\n",
      "the equilibrium; see Fig.4 for illustration.\n",
      "Remark 4: In the case of vehicle platoons where all involved\n",
      "vehicles have autonomous capabilities, the vehicles can be\n",
      "controlled to reach the same desired velocity with separate\n",
      "desired spacings [13]–[15]. In a mixed trafﬁc system, although\n",
      "only the autonomous vehicles are under direct control, all\n",
      "the other HDVs can be inﬂuenced indirectly. One distinction\n",
      "is that the desired state (s\u0003;v\u0003)for HDVs should satisfy\n",
      "their corresponding car-following behaviors, while the desired\n",
      "state (s\u0003\n",
      "c;v\u0003)for the autonomous vehicle can be designed\n",
      "separately.\n",
      "V. T RAFFIC SYSTEMS WITH MULTIPLE AUTONOMOUS\n",
      "VEHICLES\n",
      "The mixed trafﬁc system with a single autonomous vehicle\n",
      "is stabilizable, which is independent of the number of vehicles\n",
      "n. Also, an optimal control strategy u(t)can be obtained by\n",
      "solving an optimization problem. However, it might be not\n",
      "practical to control a mixed trafﬁc system consisting of many\n",
      "HDVs and a single autonomous vehicle. In this section, we\n",
      "extend our previous analysis to a mixed trafﬁc system with\n",
      "multiple autonomous vehicles.\n",
      "A. Theoretical Framework\n",
      "Assume that there are nvehicles in the trafﬁc ﬂow with k\n",
      "autonomous vehicles (k<n ). The indices of the autonomous\n",
      "vehicles are i1,i2, . . . ,ik, for which we deﬁne a set SA V=\n",
      "fi1;i2;:::;ikg. The error state of an HDV indexed as i(i =2\n",
      "SA V) is still deﬁned as ~si(t) =si(t)\u0000s\u0003;~vi(t) =vi(t)\u0000v\u0003,\n",
      "where (s\u0003;v\u0003) satisﬁes (2) and its linearized model remains\n",
      "the same as (3).\n",
      "For an autonomous vehicle indexed as ir(r= 1;2:::;k ),\n",
      "the acceleration signal is directly used as its control input\n",
      "uir(t), and its car-following model is\n",
      "(_~sir(t) = ~vir\u00001(t)\u0000~vir(t);\n",
      "_~vir(t) =uir(t);(37)\n",
      "Traffic Flow  \n",
      "DirectionVehicle 1\n",
      "Vehicle 𝑛𝑛\n",
      " Vehicle 3…\n",
      "…\n",
      "…\n",
      "…\n",
      "Vehicle 2\n",
      "Vehicle 𝑛𝑛 Vehicle 3Vehicle 1\n",
      "Vehicle 2\n",
      "Traffic Flow\n",
      "Direction(a)\n",
      "Traffic Flow\n",
      "DirectionVehicle 1\n",
      "Vehicle 𝑛𝑛\n",
      " Vehicle 3…\n",
      "…\n",
      "…\n",
      "…\n",
      "Vehicle 2\n",
      "Vehicle 𝑛𝑛 Vehicle 3Vehicle 1\n",
      "Vehicle 2\n",
      "Traffic Flow  \n",
      "Direction\n",
      "(b)\n",
      "Fig. 4. Illustration of the scenario where the autonomous vehicle increases the\n",
      "trafﬁc speed. (a) When all vehicles are human-driven, the spacing between\n",
      "two vehicles is equal for homogeneous car-following dynamics. (b) In the\n",
      "case of mixed trafﬁc systems, the autonomous vehicle can be controlled to\n",
      "follow its preceding vehicle in a shorter distance, and the other HDVs have\n",
      "a larger spacing at the equilibrium state. According to F(s\u0003;0;v\u0003) = 0 , the\n",
      "equilibrium velocity v\u0003increases as s\u0003grows up. Hence, the entire trafﬁc\n",
      "ﬂow speed can be increased via controlling the autonomous vehicle.\n",
      "where ~sir(t) =sir(t)\u0000s\u0003\n",
      "ir;c;~vir(t) =vir(t)\u0000v\u0003withs\u0003\n",
      "ir;c\n",
      "being a tunable desired spacing for the autonomous vehicle at\n",
      "velocityv\u0003.\n",
      "To derive the global dynamics, we lump the error states of\n",
      "all the vehicles as the mixed trafﬁc system state,\n",
      "x(t) =\u0002~s1(t);~v1(t);:::; ~sn(t);~vn(t)\u0003T;\n",
      "and lump all the control inputs as\n",
      "u(t) =\u0002\n",
      "ui1(t);ui2(t);:::;uik(t)\u0003T:\n",
      "Then the state-space model of the entire mixed trafﬁc system\n",
      "can be given by\n",
      "_x(t) =Akx(t) +Bku(t); (38)\n",
      "where\n",
      "Ak=2\n",
      "66666664A11 0::: ::: 0A12\n",
      "A22A21 0::: ::: 0\n",
      "0A32A31 0::: 0\n",
      "..................\n",
      "0::: 0A(n\u00001)2A(n\u00001)1 0\n",
      "0::: ::: 0An2An13\n",
      "77777775;\n",
      "Bk=\u0002P1;P2;:::;Pk\u0003\n",
      ":\n",
      "In the system matrix Ak, we have\n",
      "(\n",
      "Ar2=C2;Ar1=C1;ifr2SA V;\n",
      "Ar2=A2;Ar1=A1;ifr =2SA V;\n",
      "and the other blocks are zero, where A1,A2,C1andC2are\n",
      "the same as that in (11). In Bk, each column Pris a2n\u00021\n",
      "vector, in which only the (2ir)-th entry is one and the others\n",
      "are zero.10\n",
      "B. Controllability and Stabilizability\n",
      "When there exist multiple autonomous vehicles, we observe\n",
      "that the controllability and stabilizability of the mixed trafﬁc\n",
      "system remain unchanged compared to the case discussed in\n",
      "Section III, where there is only one autonomous vehicle. This\n",
      "result is summarized as follows.\n",
      "Theorem 4: Consider a mixed trafﬁc system with multiple\n",
      "autonomous vehicles in (38). We have\n",
      "1) The mixed trafﬁc system (38) is not completely control-\n",
      "lable, and there still exists an uncontrollable mode.\n",
      "2) The mixed trafﬁc system (38) is stabilizable.\n",
      "Proof: To analyze the system controllability, we ﬁrst\n",
      "deﬁne a virtual control input as\n",
      "^uk(t) =u(t)\u0000\u0002\u0016ui1;\u0016ui2:::;\u0016uik\u0003T;\n",
      "with \u0016uir=\u000B1~sir(t)\u0000\u000B2~vir(t) +\u000B3~vir\u00001(t),ir2SA V.\n",
      "Then (38) becomes\n",
      "_x(t) =^Ax(t) +Bk^uk(t);\n",
      "with ^Adeﬁned by (14). Using F\u0003\n",
      "n\n",
      "I2as the transformation\n",
      "matrix, (^A;Bk)can be transformed into (eA;eBk), given by\n",
      "_~x=eA~x(t) +eBk^uk(t) (39)\n",
      "witheA=diag(D1;D2;:::;Dn)being the same as (15) and\n",
      "eBkdeﬁned as\n",
      "eBk= (F\u0003\n",
      "n\n",
      "I2)\u00001Bk=h\n",
      "eP1;eP2;:::;ePki\n",
      ";\n",
      "whereePr=1pn\u0002\n",
      "0;1;0;\u0016!ir\u00001;:::; 0;\u0016!(n\u00001)(ir\u00001)\u0003T;r=\n",
      "1;:::;k . After the transformation, the new state variable ~x\n",
      "is the same as (17).\n",
      "Note that the dynamics (39) shall be reduced to the case\n",
      "with a single autonomous vehicle (18) when k= 1 andi1=\n",
      "1. Upon denoting ~x(t) =\u0002~x11;~x12;~x21;~x22;:::; ~xn1;~xn2\u0003T,\n",
      "(eA;eBk)can be decoupled into nindependent subsystems ( q=\n",
      "1;2;:::;n )\n",
      "d\n",
      "dt\u0014\n",
      "~xq1\n",
      "~xq2\u0015\n",
      "=Di\u0014\n",
      "~xq1\n",
      "~xq2\u0015\n",
      "+Fq^u(t);\n",
      "where\n",
      "Fq=1pn\u00140 0 \u0001\u0001\u0001 0\n",
      "\u0016!(q\u00001)(i1\u00001)\u0016!(q\u00001)(i2\u00001)\u0001\u0001\u0001 \u0016!(q\u00001)(ik\u00001)\u0015\n",
      ":\n",
      "It is not difﬁcult to see that _~x11= 0, which means that ~x11is\n",
      "an uncontrollable mode. Thus, the mixed trafﬁc system (38) is\n",
      "not completely controllable. Note that ~x11corresponds to the\n",
      "zero eigenvalue and remains constant. Similar to the analysis in\n",
      "Section III-A, the algebraic multiplicity of the zero eigenvalue\n",
      "is one and hence the uncontrollable mode is stable.\n",
      "As has been shown in Section III, system ( eA;eB) in (18) is\n",
      "stabilizable. Note that the ﬁrst column in eBk,i.e.,eP1, is equal\n",
      "toeB, which indicates the stabilizability of system ( eA;eP1).\n",
      "Then it is easy to observe that system ( eA;eBk) is also stabiliz-\n",
      "able. According to Lemmas 2 and 3, we can conclude that the\n",
      "mixed trafﬁc system with multiple autonomous vehicles given\n",
      "by (38) is stabilizable.The speciﬁc expression of the uncontrollable mode is\n",
      "~x11=P\n",
      "i2SA V\u0000\n",
      "si(t)\u0000s\u0003\n",
      "i;c\u0001\n",
      "+P\n",
      "i2f1;2;:::;ngnSA V(si(t)\u0000s\u0003)\n",
      "pn;\n",
      "which remains unchanged during the system evolution. The\n",
      "physical interpretation is the same as the case where there\n",
      "is one single autonomous vehicle: the sum of each vehicle’s\n",
      "spacing should remain constant due to the ring road structure.\n",
      "C. Optimal Control and Reachability Analysis\n",
      "Our controller formulation proposed in Section IV-A can\n",
      "be easily applied to the mixed trafﬁc system with multiple\n",
      "autonomous vehicles in (38). Deﬁne the feedback controller\n",
      "asu(t) =\u0000Kx(t), where\n",
      "K=\u0002\n",
      "KT\n",
      "1;KT\n",
      "2;:::;KT\n",
      "k\u0003T; (40)\n",
      "withKr2R1\u00022ndenoting the feedback gain for the au-\n",
      "tonomous vehicle indexed as ir,i.e.,uir(t) =\u0000Krx(t).\n",
      "Then following the process in Section IV-A, we can obtain an\n",
      "optimal control strategy. We remark that the speciﬁc feedback\n",
      "gainKrfor each autonomous vehicle may differ from each\n",
      "other depending on their positions in the trafﬁc system. The\n",
      "resulting controller is a cooperation strategy for multiple A Vs\n",
      "to achieve an optimal performance of the entire trafﬁc system.\n",
      "The reachability analysis is as follows.\n",
      "Theorem 5: Consider the mixed trafﬁc system in a ring road\n",
      "with multiple A Vs in (38). Suppose a stabilizing feedback gain\n",
      "(40) is found by (26) and the coefﬁcient matrix of (42) is non-\n",
      "singular. Then the trafﬁc system can be stabilized at velocity\n",
      "v\u0003, if and only if the sum of the desired spacing s\u0003\n",
      "i;c(i2SA V)\n",
      "of each A V satisﬁes\n",
      "X\n",
      "i2SA Vs\u0003\n",
      "i;c=L\u0000(n\u0000k)s\u0003; (41)\n",
      "withs\u0003given by the equilibrium equation (2).\n",
      "Proof: Denote (r= 1;2;:::;n )\n",
      "Kr=h\n",
      "k(r)\n",
      "1;1;k(r)\n",
      "1;2;k(r)\n",
      "2;1;k(r)\n",
      "2;2;;:::;k(r)\n",
      "n;1;k(r)\n",
      "n;2i\n",
      ":\n",
      "Similar to the reachability analysis in Section IV, the ﬁnal\n",
      "state of stable system in (38) can be obtained via\n",
      "8\n",
      ">><\n",
      ">>:~vi(tf) =ve; i2f1;2;:::;ng;\n",
      "~si(tf) =\u000B2\u0000\u000B3\n",
      "\u000B1ve; i2f1;2;:::;ngnSA V;\n",
      "~si(tf) =se;i; i2SA V:\n",
      "whereveandse;i; i2SA Vshould satisfy\n",
      "8\n",
      ">>>><\n",
      ">>>>:\u0011(1)ve+P\n",
      "i2SA Vk(1)\n",
      "i;1se;i= 0;\n",
      "...\n",
      "\u0011(k)ve+P\n",
      "i2SA Vk(k)\n",
      "i;1se;i= 0;\n",
      "(n\u0000k)\u000B2\u0000\u000B3\n",
      "\u000B1ve+P\n",
      "i2SA Vse;i=Lk;(42)\n",
      "with (r= 1;2;:::;n )\n",
      "\u0011(r)=\u000B2\u0000\u000B3\n",
      "\u000B1X\n",
      "i2f1;2;:::;ngnSA Vk(r)\n",
      "i;1+X\n",
      "i2f1;2;:::;ngk(r)\n",
      "i;2;\n",
      "Lk=L\u0000(n\u0000k)s\u0003\u0000X\n",
      "i2SA Vs\u0003\n",
      "i;c:11\n",
      "(a)\n",
      " (b)\n",
      " (c)\n",
      "Fig. 5. Stabilizing trafﬁc ﬂow and increasing trafﬁc speed. (a) The trafﬁc system with human-driven vehicles only is unstable when \u000B= 0:6;\f= 0:9in the\n",
      "OVM model. (b) The mixed trafﬁc system becomes stable after introducing an autonomous vehicle with an appropriate control strategy. (c) The trafﬁc ﬂow\n",
      "can be guided to a higher stable velocity (6% improvement) via controlling the autonomous vehicle.\n",
      "The condition that the trafﬁc ﬂow reaches the desired\n",
      "equilibrium velocity v\u0003is equivalent to ve= 0; s e;i=\n",
      "0;i2SA V. The solution to (42) is all zeros, i.e.,ve= 0\n",
      "andse;i= 0; i2SA V, if and only if the constant vector is\n",
      "zero, i.e.,Lk= 0, which leads to (41).\n",
      "Since the spacing of each autonomous vehicle cannot be\n",
      "negative, i.e.,s\u0003\n",
      "i;c>0(i2SA V), we haveP\n",
      "i2SA Vs\u0003\n",
      "i;c=\n",
      "L\u0000(n\u0000k)s\u0003>0:In this case, the maximum spacing for\n",
      "each HDV in the equilibrium can be increased to\n",
      "s\u0003\n",
      "max;k<L\n",
      "n\u0000k;\n",
      "which sets up a new maximum equilibrium trafﬁc velocity\n",
      "(v\u0003)max;k.\n",
      "Corollary 2: There exists a reachable range for the trafﬁc\n",
      "velocity in the mixed trafﬁc system with kautonomous vehi-\n",
      "cles given by (38), i.e.,06v\u0003<v\u0003\n",
      "max;k;where\n",
      "F\u0012L\n",
      "n\u0000k;0;v\u0003\n",
      "max;k\u0013\n",
      "= 0:\n",
      "This result generalizes the statement in Corollary 1, and it\n",
      "can be observed clearly that a larger proportion of autonomous\n",
      "vehicles leads to a higher reachable trafﬁc velocity.\n",
      "VI. N UMERICAL EXPERIMENTS\n",
      "Our theoretical results are obtained using a linearized model\n",
      "of the mixed trafﬁc system. We evaluate their effectiveness\n",
      "in the presence of nonlinearities arising in the car-following\n",
      "dynamics. In this section, we conduct multiple simulation ex-\n",
      "periments to validate our results based on a realistic nonlinear\n",
      "OVM model, as shown in (4). All the experiments are carried\n",
      "out in MATLAB.\n",
      "A. Experimental Setup\n",
      "Similarly to [37], we set the parameters in the OVM model\n",
      "(4) as follows: \u000B= 0:6,\f= 0:9,sgo= 35 ,vmax= 30 ,sst=\n",
      "5. One can verify that this set of values violates the stability\n",
      "condition (13), which means that a ring-road trafﬁc system\n",
      "with such HDVs only is unstable and stop-and-go waves may\n",
      "happen in case of any perturbations.\n",
      "For the parameters in the performance output (27), we\n",
      "u= 1. Based on the approachin Section IV, an optimal linear feedback gain Kfor the\n",
      "autonomous vehicle is obtained using Mosek [33]. To avoid\n",
      "crashes, we also assume that all the vehicles are equipped with\n",
      "a standard automatic emergency braking system\n",
      "_v(t) =amin;ifv2\n",
      "i(t)\u0000v2\n",
      "i\u00001(t)\n",
      "2si(t)\u0015jaminj;\n",
      "where the maximum deceleration rate of each vehicle is set to\n",
      "amin=\u00005m=s2.\n",
      "B. Stabilizing Trafﬁc Flow and Increasing Trafﬁc Velocity\n",
      "Our ﬁrst experiment aims to show that a typical nonlinear\n",
      "mixed trafﬁc ﬂow can be stabilized by one single autonomous\n",
      "vehicle, as proved in Theorem 2 after linearization. We con-\n",
      "sider the case where n= 20 andL= 400 . Each vehicle\n",
      "has a weak perturbation around its equilibrium state at initial\n",
      "time, in the sense that the position and the velocity of the\n",
      "i-th vehicle are iL=n +\u000Es, andvini+\u000Ev, whereviniis the\n",
      "equilibrium velocity corresponding to the equilibrium spacing\n",
      "L=n,\u000Es\u0018U[\u00004;4]and\u000Ev\u0018U[\u00002;2]withU[a;b]denoting\n",
      "a uniform distribution between aandb.\n",
      "When all the vehicles are under human control, it is clearly\n",
      "observed in Fig.5(a) that the initial perturbations inside the\n",
      "trafﬁc ﬂow are ampliﬁed gradually, and each vehicle’s velocity\n",
      "keeps ﬂuctuating, ﬁnally inducing a stop-and-go wave. In\n",
      "contrast, if there is one autonomous vehicle using the proposed\n",
      "control method, the trafﬁc ﬂow can be stabilized to the\n",
      "original average velocity 15m=s within a short time (Fig.5(b)).\n",
      "Moreover, by adjusting the equilibrium velocity v\u0003(as stated\n",
      "in Section IV-B) and the corresponding equilibrium spacing\n",
      "s\u0003ands\u0003\n",
      "caccording to (2) and (31) respectively, the A V can\n",
      "steer the entire trafﬁc ﬂow towards a higher velocity, from\n",
      "15m=s to16m=s; see Fig.5(c). In this case we observed 6%\n",
      "improvement of trafﬁc velocity when there exist only 5% A Vs\n",
      "(one out of 20) in the mixed trafﬁc system.\n",
      "C. Smoothing Trafﬁc Flow via Multiple Autonomous Vehicles\n",
      "Fig.1 and Fig.5 have demonstrated the ability of a single\n",
      "autonomous vehicle to smooth the trafﬁc ﬂow where there\n",
      "exist certain perturbations. We proceed to conduct numerical\n",
      "experiments for the scenario where the trafﬁc system has two\n",
      "autonomous vehicles. We consider different values of nand12\n",
      "(a)\n",
      " (b)\n",
      "Fig. 6. Simulation results at different system scales. We ran 2000 random\n",
      "s= 0:03,ons for each value of n. The parameters are as follows: \n",
      "u= 1. (a) The control energyR1\n",
      "0uTudt needed to stabilize\n",
      "the trafﬁc ﬂow for each autonomous vehicle. (b) The time required to stabilize\n",
      "the trafﬁc system.\n",
      "letL= 20n. The experimental setup at initial time is the same\n",
      "as that in the previous experiment. The results are shown in\n",
      "Fig.6. It is clear that both the settling time and the control\n",
      "energy of each autonomous vehicle decrease by a factor of\n",
      "two approximately, when there are two autonomous vehicles\n",
      "in the trafﬁc system uniformly. Based on the results, we may\n",
      "estimate the market penetration rate of autonomous vehicles\n",
      "to control trafﬁc ﬂow effectively when adopting the optimal\n",
      "control strategy. In the scenario of Fig.6, if one wants to reject\n",
      "the inﬂuence of the perturbation on trafﬁc ﬂow within 30\n",
      "seconds, a single autonomous vehicle can control the trafﬁc\n",
      "ﬂow consisting of around 20 HDVs. This number agrees with\n",
      "the results from real-world experiments [22].\n",
      "D. Dampening Trafﬁc Waves and Comparison with Existing\n",
      "Strategies\n",
      "As our last experiment, we consider a scenario with the\n",
      "presence of infrastructure bottlenecks or lane changing [22],\n",
      "where one vehicle has a rapid deceleration representing a\n",
      "strong perturbation. In the beginning, the trafﬁc ﬂow is at\n",
      "the equilibrium state with the velocity 15m=s. And then\n",
      "att= 20s, thei-th vehicle decelerates to 5m=s in two\n",
      "seconds. We observe that if all the vehicles are human-driven,\n",
      "the perturbation may grow stronger during the propagation\n",
      "process (Fig.7(a)), while the autonomous vehicle with an\n",
      "optimal control strategy can respond actively to attenuate the\n",
      "perturbation and stabilize the trafﬁc ﬂow (Fig.7(b)). Here we\n",
      "only show the case where the 6th vehicle is under the strong\n",
      "perturbation. Indeed, the experiment results conﬁrm that our\n",
      "strategy allows one autonomous vehicle to dampen strong\n",
      "trafﬁc waves wherever they come from.\n",
      "Next, we compare our proposed strategy with existing ones.\n",
      "As shown in Fig.1, our strategy allows the autonomous vehicle\n",
      "to mitigate undesired perturbations in an active way instead\n",
      "of responding passively as CACC-type controllers. Here, we\n",
      "proceed to make comparisons with two heuristic controllers\n",
      "that aim at dampening trafﬁc waves: FollowerStopper and\n",
      "PI with Saturation [22]. Note that the FollowerStopper and\n",
      "PI with Saturation use a command velocity vcmd as the\n",
      "control input, and we add a proportional controller, i.e.,\n",
      "u(t) =kp(vcmd(t)\u0000v(t)), withkp= 0:6, to serve as a\n",
      "lower-level controller. In all tested scenarios, the perturbation\n",
      "was successfully dampened using the three methods. However,\n",
      "0 20 40 60 80\n",
      "t[s]0102030Velocity [ m/s]OVM\n",
      "Average velocity\n",
      "(a)\n",
      "0 20 40 60 80\n",
      "t[s]0102030Velocity [ m/s]OVM\n",
      "Autonomous vehicle\n",
      "Average velocity\n",
      "(b)\n",
      "Fig. 7. Numerical results for the scenario with a rapid and strong perturbation\n",
      "in the 6th vehicle. (a) The trafﬁc system consists of HDVs only. (b) The\n",
      "mixed trafﬁc system has an autonomous vehicle that adopts the optimal control\n",
      "strategy. In each panel, the right ﬁgure shows the vehicles’ trajectories, where\n",
      "the red zone represents the trafﬁc wave; the left ﬁgure shows the vehicles’\n",
      "velocities, where the red line denotes the perturbation and the black line is\n",
      "the average velocity of all vehicles.\n",
      "2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20\n",
      "Position of the perturbation (perturbed vehicle ID)304050607080Maximum spacing [ m]Optimal control strategy\n",
      "FollowerStopper\n",
      "PI with Saturation\n",
      "Fig. 8. Comparison between three strategies of the maximum spacing of the\n",
      "autonomous vehicle, i.e.,max ts1(t), during the experiment with a rapid and\n",
      "strong perturbation.\n",
      "since FollowerStopper and PI with Saturation are essentially\n",
      "slow-in fast-out strategies, they tend to leave a long gap from\n",
      "the preceding vehicle, which may cause vehicles from adjacent\n",
      "lanes to cut in. In contrast, our optimal strategy avoids this\n",
      "problem and keeps the spacing within a moderate range. As\n",
      "shown in Fig.8, this ﬁnding holds irrespectively of the position\n",
      "of the perturbation, and hence conﬁrms the advantage of our\n",
      "strategy.\n",
      "Finally, we consider the comparison of fuel consumption for\n",
      "the three control methods. It has been demonstrated in [22]\n",
      "that applying FollowerStopper or PI with Saturation to one\n",
      "autonomous vehicle can result in a 40% reduction of the total\n",
      "fuel consumption of the entire trafﬁc ﬂow. Here we are inter-\n",
      "ested in whether our strategy can achieve further improvement.\n",
      "An instantaneous fuel consumption model in [38] is utilized\n",
      "to estimate the fuel consumption rate fi(mL=s ) of thei-th\n",
      "vehicle, which is given by\n",
      "fi=(\n",
      "0:444 + 0:090Rivi+ [0:054a2\n",
      "ivi]ai>0;ifRi>0;\n",
      "0:444; ifRi\u00140;13\n",
      "Fig. 9. Comparison between three strategies of the total fuel consumption of\n",
      "the entire trafﬁc ﬂow, i.e.,FC in (43), during the experiment with a rapid\n",
      "and strong perturbation.\n",
      "whereRi= 0:333+0:00108v2\n",
      "i+1:200ai. Then, the total fuel\n",
      "consumption of the entire trafﬁc ﬂow FC is calculated as\n",
      "FC=NX\n",
      "i=1\u0012Ztf\n",
      "t=0fidt\u0013\n",
      "; (43)\n",
      "wheretf= 100sdenotes the end time of the simulation.\n",
      "The simulation setup is the same as that in Fig.7, and the\n",
      "results are shown in Fig.9. It is observed that our proposed\n",
      "strategy achieves evidently lower fuel consumption than Fol-\n",
      "lowerStopper and PI with Saturation when the perturbation\n",
      "happens within the range from the 1st to the 10th vehicle. This\n",
      "result validates the great potential of our strategy in improving\n",
      "fuel economy. We note that, when the perturbation happens\n",
      "within the range from the 11th to the 20th vehicle, which is\n",
      "ahead of the autonomous vehicle in a small distance, all of the\n",
      "three strategies require the autonomous vehicle to brake hard\n",
      "to guarantee safety. In these cases, the three control strategies\n",
      "have similar performance in terms of fuel consumption.\n",
      "VII. C ONCLUSION\n",
      "Unlike the traditional control methods that regulate trafﬁc\n",
      "ﬂow externally at ﬁxed positions, autonomous vehicles can\n",
      "be used as mobile actuators to control trafﬁc ﬂow internally.\n",
      "In this paper, we have introduced a comprehensive theoretical\n",
      "analysis to address the potential of autonomous vehicles on\n",
      "smoothing mixed trafﬁc ﬂow. Speciﬁcally, we have analyzed\n",
      "the controllability, stabilizability, and reachability of mixed\n",
      "trafﬁc systems. Also, an optimal control strategy has been\n",
      "introduced to actively smooth mixed trafﬁc ﬂow.\n",
      "A few other topics are worth further investigations. First,\n",
      "we have assumed autonomous vehicles have access to the\n",
      "global trafﬁc state, i.e., the information of all other human-\n",
      "driven vehicles. Due to the limit of communication ranges,\n",
      "autonomous vehicles may be only able to obtain the infor-\n",
      "mation of its neighboring vehicles. It is interesting to design\n",
      "a localized optimal controller, and this leads to the notion\n",
      "of structured controller synthesis [39], [40]. Second, we have\n",
      "assumed homogeneous dynamics for human-driven vehicles,\n",
      "and potential time delays are ignored. One interesting direction\n",
      "is to consider heterogeneity and time delay in controlling\n",
      "mixed trafﬁc systems. We note that some recent work has\n",
      "considered the effect of heterogeneity and time delays at thelevel of platoon control [37], [41], [42], which may offer some\n",
      "insights for controller design in mixed trafﬁc systems. Finally,\n",
      "our current analysis focuses on the single-lane ring road\n",
      "setting, and it would be interesting to extend our analysis to\n",
      "the scenarios with multiple lanes and lane-changing behavior.\n",
      "APPENDIX A\n",
      "DIAGONALIZATION OF BLOCK CIRCULANT MATRICES\n",
      "Deﬁne!=e2\u0019j\n",
      "n, wherej=p\u00001denotes the imaginary\n",
      "unit, and the Fourier matrix Fnis deﬁned as [31], [32]\n",
      "F\u0003\n",
      "n=1pn2\n",
      "6666641 1 1 ::: 1\n",
      "1! !2::: !n\u00001\n",
      "1!2!4::: !2(n\u00001)\n",
      "............\n",
      "1!n\u00001!2(n\u00001)::: !(n\u00001)(n\u00001)3\n",
      "777775;(44)\n",
      "whereF\u0003\n",
      "ndenotes the conjugate transpose matrix of Fn. By\n",
      "the deﬁnition of Fourier matrix, we know that FnandF\u0003\n",
      "nare\n",
      "symmetric, i.e.,F\u0003\n",
      "n= (F\u0003\n",
      "n)T,Fn=FT\n",
      "n, and thatFnis a\n",
      "unitary matrix, i.e.,FnF\u0003\n",
      "n=In, whereIndenotes the n\u0002n\n",
      "identity matrix.\n",
      "GivenM1;M2;:::;Mn2Rm\u0002m, a block circulant matrix\n",
      "is of the following form\n",
      "M=2\n",
      "6664A1A2::: An\n",
      "AnA1::: An\u00001\n",
      ".........\n",
      "A2A3::: A 13\n",
      "77752Rmn\u0002mn: (45)\n",
      "As shown in [31], [32], a block circulant matrix given by (45)\n",
      "can be diagonalized as follows\n",
      "diag(D1;D2;:::;Dn) = (F\u0003\n",
      "n\n",
      "Im)\u00001^A(F\u0003\n",
      "n\n",
      "Im);\n",
      "where2\n",
      "6664D1\n",
      "D2\n",
      "...\n",
      "Dn3\n",
      "7775= (pnF\u0003\n",
      "n\n",
      "Im)2\n",
      "6664M1\n",
      "M2\n",
      "...\n",
      "Mn3\n",
      "7775:\n",
      "APPENDIX B\n",
      "PROOF OF THE STABILITY CONDITION (12)\n",
      "When all the vehicles are controlled by human drivers, the\n",
      "system dynamics is given by\n",
      "_x=^Ax; (46)\n",
      "where ^Ais the same as (14). To analyze the stability of\n",
      "matrix ^A, it is necessary and sufﬁcient to study its eigenvalues’\n",
      "distribution. Since ^Ais a block circulant matrix, it can be\n",
      "diagonalized to simplify the eigenvalue calculation. As shown\n",
      "in Appendix A, ^Acan be diagonalized into\n",
      "^A= (F\u0003\n",
      "n\n",
      "I2)\u0001diag(D1;D2;:::;Dn)\u0001(Fn\n",
      "I2);\n",
      "whereDi=A1+A2!(n\u00001)(i\u00001);i= 1;2;:::;n . Since\n",
      "det(\u0015I\u0000A) =det(\u0015I\u0000diag(D1;D2;:::;Dn))\n",
      "=nY\n",
      "i=1det(\u0015I\u0000Di);(47)14\n",
      "then the eigenvalues \u0015of^Acan be calculated by\n",
      "\u00152+\u0010\n",
      "\u000B2\u0000\u000B3!(n\u00001)(i\u00001)\u0011\n",
      "\u0015+\u000B1\u0010\n",
      "1\u0000!(n\u00001)(i\u00001)\u0011\n",
      "= 0;\n",
      "(48)\n",
      "wherei= 1;2;:::;n . Note that (48) is a second-order com-\n",
      "plex equation, which makes it non-trivial to get the analytical\n",
      "roots. Instead, we transform this equation to continue our\n",
      "analysis. Substituting the expression of !into (48) leads to\n",
      "ei\u00001\n",
      "n\u00012\u0019j=\u000B1+\u000B3\u0015\n",
      "\u000B1+\u000B2\u0015+\u00152=H(\u0015); i= 1;2;:::;n; (49)\n",
      "which means that the eigenvalues of ^Acorrespond to the\n",
      "solutions of (49). Note that ei\u00001\n",
      "n\u00012\u0019jis thei-th complex root\n",
      "ofzn= 1, indicating that for all the eigenvalues \u0015ofA, the\n",
      "values ofH(\u0015)constitutenunit roots. As nchanges,H(\u0015)\n",
      "corresponds to different unit roots. Therefore, if all the roots\n",
      "ofjH(\u0015)j= 1 have negative real parts, then the solutions of\n",
      "equation (49), i.e., the eigenvalues of matrix ^A, have negative\n",
      "real parts. We conclude that the condition that all the roots of\n",
      "jH(\u0015)j= 1 have negative real parts is sufﬁcient to guarantee\n",
      "that ^Ais stable. Note that this condition becomes sufﬁcient\n",
      "and necessary for the case where the system is stable for any\n",
      "n. This is because that H(\u0015)can be any unit root e\u0012j, for\n",
      "\u00122[0;2\u0019).\n",
      "The rest of analysis is the same as [21]. Since all rational\n",
      "functions are meromorphic, H(\u0015)is a meromorphic function.\n",
      "Because\u000B1and\u000B2are positive real numbers, the poles of\n",
      "H(\u0015)are in the left half plane, indicating that H(\u0015)is holo-\n",
      "morphic in the right half plane. Meanwhile, jH(\u0015)j!0when\n",
      "Re(\u0015)!1 . According to Maximum Modulus Principle [43],\n",
      "the extreme value of jH(\u0015)jin the right half plane can only\n",
      "be obtained on the imaginary axis. To avoid eigenvalues with\n",
      "positive real parts, jH(\u0015)jshould not be more than 1on the\n",
      "imaginary axis. Therefore, that the roots of jH(\u0015)j= 1 have\n",
      "negative real part is equivalent to jH(jv)j\u00141;8v2R:This\n",
      "inequality leads to the stability criterion \u000B2\n",
      "2\u0000\u000B2\n",
      "3\u00002\u000B1\u00150:\n",
      "ACKNOWLEDGMENT\n",
      "The authors thank Prof. Antonis Papachristodoulou,\n",
      "Prof. Jianqiang Wang, Dr. Qing Xu, Mr. Licio Romao,\n",
      "Mr. Suhao Yan and Mr. Chaoyi Chen for comments and dis-\n",
      "cussions. We would also like to thank Dr. Ross Drummond at\n",
      "the University of Oxford for providing constructive feedback.\n",
      "REFERENCES\n",
      "[1] M. Batty, “The size, scale, and shape of cities,” science , vol. 319, no.\n",
      "5864, pp. 769–771, 2008.\n",
      "[2] J. I. Levy, J. J. Buonocore, and K. V on Stackelberg, “Evaluation of the\n",
      "public health impacts of trafﬁc congestion: a health risk assessment,”\n",
      "Environmental health , vol. 9, no. 1, p. 65, 2010.\n",
      "[3] D. Helbing, “Trafﬁc and related self-driven many-particle systems,”\n",
      "Reviews of modern physics , vol. 73, no. 4, p. 1067, 2001.\n",
      "[4] G. Orosz and et al., “Trafﬁc jams: dynamics and control,” 2010.\n",
      "[5] S. Smulders, “Control of freeway trafﬁc ﬂow by variable speed signs,”\n",
      "Trans. Research Part B: Methodological , vol. 24, pp. 111–132, 1990.\n",
      "[6] M. Papageorgiou, E. Kosmatopoulos, and I. Papamichail, “Effects of\n",
      "variable speed limits on motorway trafﬁc ﬂow,” Transportation Research\n",
      "Record , no. 2047, pp. 37–48, 2008.\n",
      "[7] Y . Sugiyama, M. Fukui, and et al, “Trafﬁc jams without bottlenecks-\n",
      "experimental evidence for the physical mechanism of the formation of\n",
      "a jam,” New journal of physics , vol. 10, no. 3, p. 033001, 2008.[8] D. J. Fagnant and K. Kockelman, “Preparing a nation for autonomous\n",
      "vehicles: opportunities, barriers and policy recommendations,” Trans-\n",
      "portation Research Part A: Policy and Practice , pp. 167–181, 2015.\n",
      "[9] J. Contreras-Castillo, S. Zeadally, and J. A. Guerrero-Iba ˜nez, “Internet of\n",
      "vehicles: Architecture, protocols, and security,” IEEE internet of things\n",
      "Journal , vol. 5, no. 5, pp. 3701–3709, 2017.\n",
      "[10] C. Chen, L. Liu, T. Qiu, and et al., “Drivers intention identiﬁcation and\n",
      "risk evaluation at intersections in the internet of vehicles,” IEEE Internet\n",
      "of Things Journal , vol. 5, no. 3, pp. 1575–1587, 2018.\n",
      "[11] S. E. Shladover, C. A. Desoer, J. K. Hedrick, and et al., “Automated\n",
      "vehicle control developments in the path program,” IEEE Transactions\n",
      "on vehicular technology , vol. 40, no. 1, pp. 114–130, 1991.\n",
      "[12] S. E. Li, Y . Zheng, K. Li, Y . Wu, J. K. Hedrick, F. Gao, and\n",
      "H. Zhang, “Dynamical modeling and distributed control of connected\n",
      "and automated vehicles: Challenges and opportunities,” IEEE Intelligent\n",
      "Transportation Systems Magazine , vol. 9, no. 3, pp. 46–58, 2017.\n",
      "[13] G. J. Naus, R. P. Vugts, J. Ploeg, M. J. van de Molengraft, and\n",
      "M. Steinbuch, “String-stable cacc design and experimental validation:\n",
      "A frequency-domain approach,” IEEE Transactions on vehicular tech-\n",
      "nology , vol. 59, no. 9, pp. 4268–4279, 2010.\n",
      "[14] V . Milan ´es, S. E. Shladover, J. Spring, and et al., “Cooperative adaptive\n",
      "cruise control in real trafﬁc situations.” IEEE Trans. Intelligent Trans-\n",
      "portation Systems , vol. 15, no. 1, pp. 296–305, 2014.\n",
      "[15] Y . Zheng, S. E. Li, K. Li, F. Borrelli, and J. K. Hedrick, “Dis-\n",
      "tributed model predictive control for heterogeneous vehicle platoons\n",
      "under unidirectional topologies,” IEEE Transactions on Control Systems\n",
      "Technology , vol. 25, no. 3, pp. 899–910, 2017.\n",
      "[16] B. Van Arem, C. J. Van Driel, and R. Visser, “The impact of cooperative\n",
      "adaptive cruise control on trafﬁc-ﬂow characteristics,” IEEE Transac-\n",
      "tions on Intelligent Transportation Systems , vol. 7, pp. 429–436, 2006.\n",
      "[17] S. E. Shladover, D. Su, and X.-Y . Lu, “Impacts of cooperative adaptive\n",
      "cruise control on freeway trafﬁc ﬂow,” Transportation Research Record ,\n",
      "vol. 2324, no. 1, pp. 63–70, 2012.\n",
      "[18] H. Liu, X. D. Kan, S. E. Shladover, X.-Y . Lu, and R. E. Ferlis,\n",
      "“Modeling impacts of cooperative adaptive cruise control on mixed\n",
      "trafﬁc ﬂow in multi-lane freeway facilities,” Transportation Research\n",
      "Part C: Emerging Technologies , vol. 95, pp. 261–279, 2018.\n",
      "[19] G. Orosz, “Connected cruise control: modelling, delay effects, and\n",
      "nonlinear behaviour,” Vehicle System Dynamics , vol. 54, no. 8, pp. 1147–\n",
      "1176, 2016.\n",
      "[20] I. G. Jin and G. Orosz, “Connected cruise control among human-driven\n",
      "vehicles: Experiment-based parameter estimation and optimal control de-\n",
      "sign,” Transportation Research Part C: Emerging Technologies , vol. 95,\n",
      "pp. 445–459, 2018.\n",
      "[21] S. Cui, B. Seibold, R. Stern, and D. B. Work, “Stabilizing trafﬁc ﬂow via\n",
      "a single autonomous vehicle: Possibilities and limitations,” in Intelligent\n",
      "Vehicles Symposium (IV), 2017 IEEE . IEEE, 2017, pp. 1336–1341.\n",
      "[22] R. E. Stern, S. Cui, M. L. Delle Monache, R. Bhadani, M. Bunting,\n",
      "M. Churchill, N. Hamilton, H. Pohlmann, F. Wu, B. Piccoli et al. , “Dis-\n",
      "sipation of stop-and-go waves via control of autonomous vehicles: Field\n",
      "experiments,” Transportation Research Part C: Emerging Technologies ,\n",
      "vol. 89, pp. 205–221, 2018.\n",
      "[23] R. Nishi, A. Tomoeda, K. Shimura, and K. Nishinari, “Theory of jam-\n",
      "absorption driving,” Transportation Research Part B: Methodological ,\n",
      "vol. 50, pp. 116–129, 2013.\n",
      "[24] C. Wu, A. M. Bayen, and A. Mehta, “Stabilizing trafﬁc with autonomous\n",
      "vehicles,” in 2018 IEEE International Conference on Robotics and\n",
      "Automation (ICRA) . IEEE, 2018, pp. 1–7.\n",
      "[25] C. Wu, A. Kreidieh, K. Parvate, E. Vinitsky, and A. M. Bayen, “Flow:\n",
      "Architecture and benchmarking for reinforcement learning in trafﬁc\n",
      "control,” arXiv preprint arXiv:1710.05465 , 2017.\n",
      "[26] C. Wu, A. Kreidieh, and et al., “Emergent behaviors in mixed-autonomy\n",
      "trafﬁc,” in Conference on Robot Learning , 2017, pp. 398–407.\n",
      "[27] S. Skogestad and I. Postlethwaite, Multivariable feedback control:\n",
      "analysis and design . Wiley New York, 2007, vol. 2.\n",
      "[28] R. E. Wilson and J. A. Ward, “Car-following models: ﬁfty years of linear\n",
      "stability analysis–a mathematical perspective,” Transportation Planning\n",
      "and Technology , vol. 34, no. 1, pp. 3–18, 2011.\n",
      "[29] M. Bando, K. Hasebe, A. Nakayama, A. Shibata, and Y . Sugiyama,\n",
      "“Dynamical model of trafﬁc congestion and numerical simulation,”\n",
      "Physical review E , vol. 51, no. 2, p. 1035, 1995.\n",
      "[30] R. E. Kalman, “Mathematical description of linear dynamical systems,”\n",
      "Journal of the Society for Industrial and Applied Mathematics, Series\n",
      "A: Control , vol. 1, no. 2, pp. 152–192, 1963.\n",
      "[31] J. A. Marshall, M. E. Broucke, and B. A. Francis, “Formations of\n",
      "vehicles in cyclic pursuit,” IEEE Transactions on automatic control ,\n",
      "vol. 49, no. 11, pp. 1963–1974, 2004.15\n",
      "[32] B. J. Olson, S. W. Shaw, C. Shi, C. Pierre, and R. G. Parker, “Circulant\n",
      "matrices and their application to vibration analysis,” Applied Mechanics\n",
      "Reviews , vol. 66, no. 4, p. 040803, 2014.\n",
      "[33] A. Mosek, “The mosek optimization software,” Online at http://www.\n",
      "mosek. com , vol. 54, no. 2-1, p. 5, 2010.\n",
      "[34] A. Ben-Tal and A. Nemirovski, Lectures on modern convex optimization:\n",
      "analysis, algorithms, and engineering applications . Siam, 2001, vol. 2.\n",
      "[35] O. Gomez, Y . Orlov, and I. V . Kolmanovsky, “On-line identiﬁcation\n",
      "of siso linear time-invariant delay systems from output measurements,”\n",
      "Automatica , vol. 43, no. 12, pp. 2060–2069, 2007.\n",
      "[36] Q. Lin, Y . Zhang, S. Verwer, and J. Wang, “Moha: a multi-mode\n",
      "hybrid automaton model for learning car-following behaviors,” IEEE\n",
      "Transactions on Intelligent Transportation Systems , vol. 20, no. 2, pp.\n",
      "790–796, 2018.\n",
      "[37] I. G. Jin and G. Orosz, “Optimal control of connected vehicle systems\n",
      "with communication delay and driver reaction time,” IEEE Transactions\n",
      "on Intelligent Transportation Systems , no. 8, pp. 2056–2070, 2017.\n",
      "[38] D. P. Bowyer, R. Ak ccelik, and D. Biggs, Guide to fuel consumption\n",
      "analyses for urban trafﬁc management , 1985, no. 32.\n",
      "[39] Y . Zheng, R. P. Mason, and A. Papachristodoulou, “Scalable design of\n",
      "structured controllers using chordal decomposition,” IEEE Transactions\n",
      "on Automatic Control , vol. 63, no. 3, pp. 752–767, 2018.\n",
      "[40] M. R. Jovanovi ´c and N. K. Dhingra, “Controller architectures: Tradeoffs\n",
      "between performance and structure,” European Journal of Control ,\n",
      "vol. 30, pp. 76–91, 2016.\n",
      "[41] M. Di Bernardo, A. Salvi, and S. Santini, “Distributed consensus strategy\n",
      "for platooning of vehicles in the presence of time-varying heterogeneous\n",
      "communication delays,” IEEE Transactions on Intelligent Transportation\n",
      "Systems , vol. 16, no. 1, pp. 102–112, 2015.\n",
      "[42] F. Gao, S. E. Li, Y . Zheng, and D. Kum, “Robust control of hetero-\n",
      "geneous vehicular platoon with uncertain dynamics and communication\n",
      "delay,” IET Intelligent Transport Systems , vol. 10, pp. 503–513, 2016.\n",
      "[43] R. B. Burckel, An introduction to classical complex analysis . Academic\n",
      "Press, 1980, vol. 1.Towards Fully Intelligent Transportation through\n",
      "Infrastructure-Vehicle Cooperative Autonomous\n",
      "Driving: Challenges and Opportunities\n",
      "Shaoshan Liu\u0003, Bo Yu\u0003, Jie Tangyx, Qi Zhuz\n",
      "\u0003PerceptIn, U.S.A.\n",
      "ySouth China University of Technology, China\n",
      "zNorthwestern University, U.S.A.\n",
      "xcorresponding author cstangjie@scut.edu.cn\n",
      "Abstract —The infrastructure-vehicle cooperative autonomous\n",
      "driving approach depends on the cooperation between intelligent\n",
      "roads and intelligent vehicles. This approach is not only safer but\n",
      "also more economical compared to the traditional on-vehicle-only\n",
      "autonomous driving approach. In this paper, we introduce our\n",
      "real-world deployment experiences of cooperative autonomous\n",
      "driving, and delve into the details of new challenges and oppor-\n",
      "tunities. Speciﬁcally, based on our progress towards commercial\n",
      "deployment, we follow a three-stage development roadmap of\n",
      "the cooperative autonomous driving approach:infrastructure-\n",
      "augmented autonomous driving (IAAD), infrastructure-guided\n",
      "autonomous driving (IGAD), and infrastructure-planned au-\n",
      "tonomous driving (IPAD).\n",
      "I. I NTRODUCTION\n",
      "In the past few years, we have developed technologies\n",
      "with both the on-vehicle only autonomous driving approach\n",
      "as well as the infrastructure-vehicle cooperative autonomous\n",
      "driving approach. The cooperative autonomous driving ap-\n",
      "proach depends on the cooperation between intelligent roads\n",
      "and intelligent vehicles. Speciﬁcally, our commercial coopera-\n",
      "tive autonomous driving system consists of roadside-deployed\n",
      "intelligent systems, dubbed Systems-on-Road (SoRs), and\n",
      "on-vehicle autonomous driving systems, dubbed System-on-\n",
      "Vehicle (SoV), such as the one presented in [1]. Through\n",
      "our real-world deployment experiences, we ﬁnd that the\n",
      "cooperative driving approach is safer, more efﬁcient, and\n",
      "more economical compared to the traditional on-vehicle-only\n",
      "autonomous driving approach.\n",
      "A. Safety\n",
      "According to the U.S. Centers of Disease Control and\n",
      "Prevention [2], 1.35 million people die in road crashes each\n",
      "year, and an additional 20 million suffer non-fatal injuries,\n",
      "often resulting in long-term disabilities. Regarding why trafﬁc\n",
      "accidents happen, human drivers have a crash rate of 4.2 ac-\n",
      "cidents per million miles (PMM), and the current autonomous\n",
      "vehicle crash rate is 3.2 crashes PMM [3]. While autonomous\n",
      "vehicles deliver a signiﬁcant safety improvement compared to\n",
      "the human counterpart, there are corner cases, such as blind\n",
      "spots, that neither human drivers nor autonomous vehicles can\n",
      "handle without the help of intelligent infrastructures. On theother hand, the cooperation between SoVs and SoRs provides\n",
      "a comprehensive global view of the trafﬁc condition, thus\n",
      "not only eliminating blind spots but also greatly extending\n",
      "SoVs perception distance to provide more reaction time for\n",
      "autonomous vehicles. At our deployment site, with blind-\n",
      "spot elimination and extended perception from SoRs, we have\n",
      "observed that the autonomous vehicle disengagement rate\n",
      "has been dropped by more than 90% . Eventually, we aim\n",
      "to drop the vehicle crash rate to zero through cooperative\n",
      "autonomous driving.\n",
      "B. Efﬁciency\n",
      "Trafﬁc inefﬁciency, such as congestion, imposes very high\n",
      "costs on our society. For instance, for trucking industry alone,\n",
      "the American Transportation Research Institute estimates that\n",
      "congestion costs the U.S. $74.1 billion annually, of which\n",
      "$66.1 billion occurs in urban areas [4]. In addition, there are\n",
      "other costs such as pollution and accidents, all of which cost\n",
      "each city billions of dollars every year. Using intelligent SoRs,\n",
      "we can obtain a comprehensive and ﬁne-grained information\n",
      "of the trafﬁc condition. For instance, at our deployment site,\n",
      "utilizing per-vehicle tracking data generated by our deployed\n",
      "SoRs, we are able to improve trafﬁc efﬁciency by 40%\n",
      "through intelligent trafﬁc light control.\n",
      "C. Cost\n",
      "There is an estimated 1.2 billion vehicles on world’s roads\n",
      "today and this is expected to grow to 2 billion by 2035. On\n",
      "the other hand, in the U.S. the road capacity is designed to\n",
      "process 1,900 vehicles per hour per lane, and there are only\n",
      "about 4 million miles of public road in the U.S. [5]. If we were\n",
      "to convert all cars in the world into autonomous vehicles, it\n",
      "would incur an enormous social cost, as autonomous vehicles\n",
      "are still very expensive to build [6]. A better solution is to\n",
      "invest in the road infrastructure and making it intelligent.\n",
      "Gradually, as SoRs become more powerful, we can migrate\n",
      "more workloads from the SoVs to the SoRs, hence greatly\n",
      "reducing the hardware and energy costs of autonomous vehicle\n",
      "deployments. Eventually, we aim to have autonomous vehicles\n",
      "equipped with only basic perception and control capabilities,arXiv:2103.02176v1  [cs.RO]  3 Mar 2021Fig. 1: system architecture of cooperative driving\n",
      "relying on the SoRs for proactive perception and planning\n",
      "tasks. We estimate that this will drop the cost of autonomous\n",
      "vehicles by more than 50% .\n",
      "II. I NFRASTRUCTURE -VEHICLE COOPERATIVE\n",
      "AUTONOMOUS DRIVING SYSTEM OVERVIEW\n",
      "Figure 1 presents an overview of our cooperative au-\n",
      "tonomous driving system. It consists of the SoVs, the SoRs,\n",
      "the intelligent transportation cloud system (ITCS), the en-\n",
      "gineering system, and the control center: the SoRs provide\n",
      "local perception results to the SoVs for blind spot elimination\n",
      "and extended perception to improve safety ; meanwhile the\n",
      "SoRs process incoming sensor data and send the extracted\n",
      "semantic data to the ITCS for further processing; the ITCS\n",
      "fuse all incoming semantic data to generate global perception\n",
      "and planning information, then the control center can dispatch\n",
      "global trafﬁc information, navigation plans, and control com-\n",
      "mands to the SoVs to achieve optimal trafﬁc efﬁciency .\n",
      "The engineering system consumes data collected from the\n",
      "SoRs and the SoVs and produce periodic algorithm updates\n",
      "for the SoRs, the SoVs, and the ITCS. The purpose of the\n",
      "engineering system is to maximize development productivity\n",
      "and to minimize development and testing costs . In the rest\n",
      "of this paper, we are going to review the key components\n",
      "in the cooperative autonomous driving system, as well as the\n",
      "development roadmap.\n",
      "III. D ESIGN OF THE SYSTEM -ON-ROAD (SOR)\n",
      "Our SoVs are full-ﬂedged level-4 autonomous vehicles,\n",
      "equipped with mmWave radars, cameras, LiDARs, GPS, IMU,\n",
      "and a on-board computer. The key workloads running on\n",
      "the SoVs include sensing, perception, localization, tracking,\n",
      "prediction, planning, and control. Over 80% of the computing\n",
      "power and hardware cost are dedicated to the sensing, percep-\n",
      "tion, and localization modules, making these the perfect target\n",
      "for ofﬂoading to the SoRs [7].\n",
      "On the other hand, the SoRs are designed to enrich the\n",
      "SoVs’ perception and to ofﬂoad sensing and computing from\n",
      "the SoVs. Each SoR is equipped with three cameras, threeradars, two LiDARs, and an edge computer, and a RSU for\n",
      "C-V2X communication. To enable cooperative driving, the\n",
      "SoVs need to communicate with the SoRs. Thus, each SoV\n",
      "is equipped with an C-V2X on-board unit (OBU), whereas\n",
      "each SoR is equipped with an C-V2X road-side unit (RSU),\n",
      "the RSUs and OBUs communicate directly with each other to\n",
      "facilitate the fusion of perception data from the vehicle side as\n",
      "well as the road side, effectively and efﬁciently forming a local\n",
      "perception map to aid the autonomous vehicles’ navigation,\n",
      "especially to improve safety through blind spot elimination\n",
      "and extended distance perception. In our current deployment,\n",
      "we utilize LTE-V2X for communication and will support 5G-\n",
      "V2X as more 5G base stations get deployed. The current\n",
      "communication coverage is around 300 meters with average\n",
      "latency less than 25 ms.\n",
      "The current effective SoR sensing coverage is around 250\n",
      "meters (125 meters for each direction), hence we need at least\n",
      "4 SoRs per kilometer to ensure full coverage. In each second,\n",
      "a SoR processes at least 100 MB of raw sensing data, and\n",
      "generates 100 KB of semantic data, with a 50 ms latency\n",
      "for each LiDAR and camera frame to ensure 20 updates per\n",
      "second. To sustain 20 updates per second output, the SoR\n",
      "compute system consists of an Intel i9 CPU and multiple\n",
      "Nvidia GTX 1080Ti GPUs, the peak power consumption of a\n",
      "SoR can reach 800 W.\n",
      "Besides signiﬁcant road-side investments, one problem of\n",
      "the SoR deployments is to provide an additional 3200 W power\n",
      "supply per kilometer. There are different approaches to alle-\n",
      "viate this problem: 1.) Using lightweight computing units on\n",
      "SoRs to reduce cost and power consumption through software\n",
      "optimization techniques, such as the compression-compilation\n",
      "co-design optimization [8]. Our initial results demonstrate that\n",
      "we might be able to use lightweight SoC, such as Nvidia\n",
      "Xavier, or even Qualcomm Snapdragon devices to handle road-\n",
      "side perception tasks. 2.) Using ﬁber-optic connections to link\n",
      "multiple SoRs to a local edge compute center to consolidate\n",
      "computing. Our initial results demonstrate that overall deploy-\n",
      "ment cost and power consumption can be reduced signiﬁcantly\n",
      "by consolidating and time-sharing compute resources at the\n",
      "local edge compute center. We are currently exploring both\n",
      "options, as well as the ideal combination of these approaches.\n",
      "IV. D ESIGN OF THE INTELLIGENT TRANSPORTATION\n",
      "CLOUD SYSTEM (ITCS)\n",
      "A standard autonomous driving cloud for on-vehicle-only\n",
      "autonomous driving provides distributed computing and stor-\n",
      "age infrastructure supports. On top of the computing and stor-\n",
      "age infrastructure, autonomous driving cloud provides services\n",
      "including deep learning model training for algorithm develop-\n",
      "ment, distributed simulation for new algorithm veriﬁcation,\n",
      "High-Deﬁnition (HD) map generation for localization and\n",
      "perception data aggregation, these are ofﬂine services because\n",
      "the cloud does not have to participate in real-time perception\n",
      "or planning tasks in on-vehicle autonomous driving [9].\n",
      "For cooperative autonomous driving, in addition to the\n",
      "standard autonomous driving cloud computing tasks, ITCSGraphic engine\n",
      "BridgePerception\n",
      "Localization\n",
      "Planning&Control\n",
      "Vehicle controllerSensors\n",
      "Physics engineDigit twin map Sensor model\n",
      "Vehicle modelIntelligent agentsSensory \n",
      "Data\n",
      "ControlsAD \n",
      "softwareAD \n",
      "hardware Simulator \n",
      "module Simulation \n",
      "testFig. 2: Simulation system architecture for autonomous driving.\n",
      "requires a new online cloud processing data pipeline: ﬁrst,\n",
      "each SoR or SoV will upload the semantic perception results\n",
      "to the cloud for further processing. The semantic data includes\n",
      "timestamp, object type, object shape, object location, object\n",
      "speed, object heading etc. Each SoR or SoV uploads about\n",
      "100 KB of semantic data per second. Second, ITCS fuses all\n",
      "incoming data, then merges or removes duplicate entries to\n",
      "form a global real-time perception map, which contains all\n",
      "objects’ dynamic information. Third, based on the global per-\n",
      "ception map, ITCS predicts each object’s trajectory, monitors\n",
      "each lane’s trafﬁc condition, and plans optimized routes or\n",
      "even trajectories for each autonomous vehicle. The results are\n",
      "dispatched from ITCS to each autonomous vehicle to achieve\n",
      "maximum trafﬁc efﬁciency and to guarantee trafﬁc safety.\n",
      "One problem is how to partition compute resources on the\n",
      "cloud, some options include: 1.) vertical partitioning: each\n",
      "compute unit is responsible for all tasks (semantic data fusion,\n",
      "trajectory prediction, trajectory planning) for all objects within\n",
      "an area, assuming that the global perception map has been\n",
      "partitioned into different areas. 2.) horizontal partitioning: each\n",
      "compute unit is responsible for only one task across multiple\n",
      "areas. We are currently exploring these two options with the\n",
      "objective of maximizing throughput while minimizing cloud\n",
      "resource utilization.\n",
      "V. D ESIGN OF THE ENGINEERING SYSTEM\n",
      "Simulation is the cornerstone of autonomous driving soft-\n",
      "ware development, in which autonomous driving functions\n",
      "are exercised in the virtual environment. Development and\n",
      "validation in simulated environment have been widely adopted\n",
      "by autonomous driving industry as an important complemen-\n",
      "tary to physical testing to improve development efﬁciency\n",
      "and functional safety. As physical deployment, either on\n",
      "public roads or in closed-courses (e.g. Waymo’s castle), is\n",
      "time consuming and expensive, building virtual scenarios of\n",
      "interests is commonplace to accelerate development efﬁciency.\n",
      "Simulation system design For effective testing, the sim-\n",
      "ulator needs to provide autonomous vehicles a virtual repre-\n",
      "sentative of the physical world, including static environment,\n",
      "dynamic agents (e.g. vehicles, pedestrian, cyclist), and sensing\n",
      "streams (e.g. camera, Lidar, Radar). To emulate the real\n",
      "world behaviour with high-ﬁdelity, the following modules are\n",
      "fundamental building blocks of the simulation system:\n",
      "\u000FDigital twin map that describes static environment and\n",
      "objects of interests to autonomous driving, such as lanes,trafﬁc signs and lights.\n",
      "\u000FPhysical engine that simulates objects’ physical behaviour\n",
      "and interactions with environment.\n",
      "\u000FGraphic engine that renders the scene to generate realistic\n",
      "data for emulating camera images and Lidar point clouds.\n",
      "\u000FSensor models that emulate sensing processes and data,\n",
      "such as camera and Lidar, based on facilities of graph\n",
      "and physical engine.\n",
      "\u000FVehicle model that models vehicles’ behaviour given\n",
      "control commands and physical properties of the vehicle.\n",
      "\u000FIntelligent agents that models the behaviours of other\n",
      "vehicles, cyclists, and pedestrians, and the interactions\n",
      "between agents and autonomous vehicles.\n",
      "\u000FInterfaces with autonomous driving system, which trans-\n",
      "fers simulated data and vehicle controls between simula-\n",
      "tor and autonomous driving system.\n",
      "Simulation architecture The architecture of the au-\n",
      "tonomous driving simulation system is illustrated in Fig. 2.\n",
      "The simulator models the sensing mechanism, and generates\n",
      "sensory data by simulating interactions between sensors and\n",
      "environments. Exercised by the simulated sensory data, the\n",
      "autonomous driving software generates control commands to\n",
      "drive the vehicle. As a perhaps obvious note, compared with\n",
      "physical test, the simulation test replaces real sensor and\n",
      "vehicle hardware with virtual environment.\n",
      "Modern game engines, such as Unity and Unreal Engine\n",
      "(UE), are with powerful graphic and physic engines for\n",
      "3D scene rendering, collision detection, vehicle models, etc.,\n",
      "which make them a suitable choice for building autonomous\n",
      "driving simulators. Many high ﬁdelity open source (e.g. Carla\n",
      "[10]) and commercial simulators (e.g. Nvidia Constellation)\n",
      "use game engines as the foundation for simulating sensors\n",
      "and interactions among agents. We choose UE for building\n",
      "our simulator as it is open-source. Based on UE, plug-ins are\n",
      "developed for modelling camera and Lidar sensors, 3D en-\n",
      "vironment, vehicle and pedestrian’s behaviour. Our simulator\n",
      "works in a cycle-by-cycle manner. In each cycle, the simulator\n",
      "updates each agent’s state (such as positions, velocities, etc.)\n",
      "by simulating its physical interactions with the environment;\n",
      "the graphic engine renders the 3D environment in camera’s\n",
      "ﬁeld of view, and generates images for each camera. Ray\n",
      "tracing in UE is used to emulate ToF (time of ﬂight) principal\n",
      "for each ray of Lidar.\n",
      "Cost and efﬁciency model Letnv,cp,sbe the number\n",
      "of vehicles, the testing cost (per hour per vehicle) and the\n",
      "average speed ( km=h ) of a vehicle; let ns,csandcap be\n",
      "the number of simulation server, simulation cost (per server\n",
      "per hour) and the capacity of the server, in terms of the\n",
      "number of simulation jobs. The cost and efﬁciency model\n",
      "of physical and simulation test are in Table I. Based on real\n",
      "operations, the physical test costs 180 $=hour ; the simulation\n",
      "server (4 GPUs and 32 CPUs) costs 8.5 $=hour , and can\n",
      "simultaneously run 4 simulation jobs. The cost reduction and\n",
      "efﬁciency improvement of simulation are 250x and 12x.TABLE I: Cost and efﬁciency of physical vs. simulation test.\n",
      "Physical Simualtion\n",
      "Cost (dollars per day per unit) hp\u0002nv\u0002cphs\u0002ns\u0002cs\n",
      "Efﬁciency (km per day per unit) hp\u0002s h s\u0002s\u0002cap\n",
      "VI. C OMMERCIAL DEVELOPMENT ROADMAP OF\n",
      "COOPERATIVE AUTONOMOUS DRIVING\n",
      "Based on our progress towards commercial deployment,\n",
      "we follow a three-stage commercial development roadmap\n",
      "of the infrastructure-vehicle cooperative autonomous driving\n",
      "approach as follows, with each stage focused on one key\n",
      "objective:\n",
      "\u000Fstage 1: infrastructure-augmented autonomous driving\n",
      "(IAAD), in which autonomous vehicles fuse both vehicle-\n",
      "side and infrastructure-side perception outputs to im-\n",
      "prove the safety of autonomous driving. In this stage,\n",
      "both the SoVs and the SoRs are equipped with full\n",
      "sensing and computing capability, and we aim to fuse the\n",
      "information from both the SoRs and the SoVs to improve\n",
      "safety and to achieve maximum computing and energy\n",
      "efﬁciency.\n",
      "\u000Fstage 2: infrastructure-guided autonomous driving\n",
      "(IGAD), in which autonomous vehicles can ofﬂoad all\n",
      "the proactive perception tasks to the infrastructure in\n",
      "order to reduce per-vehicle deployment costs . In this\n",
      "stage, while the SoRs are equipped with full sensing\n",
      "and computing capability, we can greatly reduce the\n",
      "on-vehicle hardware deployment (both computing and\n",
      "sensing) costs. We aim to design secure, reliable, and\n",
      "safe infrastructure supports for autonomous vehicles.\n",
      "\u000Fstage 3: infrastructure-planned autonomous driving\n",
      "(IPAD), in which the infrastructure takes care of both per-\n",
      "ception and planning, thus achieving maximum trafﬁc\n",
      "efﬁciency and cost efﬁciency . In this stage, the SoVs\n",
      "are equipped with only basic sensing and computing\n",
      "capability, and we aim to optimize global trafﬁc efﬁciency\n",
      "by centrally planning for the trajectory for each vehicle.\n",
      "VII. C HALLENGES AND OPPORTUNITIES\n",
      "In this section, we conclude by presenting the research\n",
      "challenges and opportunities in infrastructure-vehicle coop-\n",
      "erative autonomous driving, as it evolves from IAAD, to\n",
      "IGAD, and eventually reaching IPAD. To facilitate cooperative\n",
      "autonomous driving, especially to enable SoVs to interact\n",
      "with the infrastructure, we have developed an on-board fusion\n",
      "engine, we expect to expand the functionalities of the fusion\n",
      "engine as we progress towards IPAD.\n",
      "Network performance and security is the key challenge\n",
      "in the IAAD stage : as an autonomous vehicle travels at\n",
      "a high speed, for at least ten times per second, the SoV\n",
      "fuses perception results from multiple SoRs along with its\n",
      "local perception results, and feeds the combined results to the\n",
      "prediction and the planning module. There is a regular deadline\n",
      "for receiving data from the SoRs. If a deadline is missed,\n",
      "the SoV has to rely on its own sensors for perception until\n",
      "the next deadline. Hence this process is extremely sensitiveto network jitters. The fusion engine monitors the deadlines\n",
      "and decides whether to wait for information from the SoRs or\n",
      "move forward with only the SoV perception results.\n",
      "In our deployments, we have observed network jitters\n",
      "ranging from 3 ms to 100 ms, which signiﬁcantly impacts\n",
      "the ability of SoRs to augment the perception capability of\n",
      "SoVs. On the other hand, network bandwidth is not a severe\n",
      "constraint, as the data exchange between our SoVs and SoRs\n",
      "is semantic information, and the required network bandwidth\n",
      "is within 1.5 MB/s. Hence, cooperative driving demands very\n",
      "stable network connection with network jitters less than 5 ms.\n",
      "More importantly, security is the most critical challenge.\n",
      "A hacker can attack the C-V2X network, or even the SoRs\n",
      "to pass incorrect information to the SoVs, potentially leading\n",
      "to lethal results. Currently, we rely on traditional network\n",
      "security techniques to protect the C-V2X network. Besides\n",
      "network security techniques, the fusion engine checks whether\n",
      "to consume the perception results from the SoRs, in case\n",
      "there is a information conﬂict between the SoRs and the SoV ,\n",
      "currently the fusion engine always trusts the SoV .\n",
      "Reliability is the key challenge in the IGAD stage : the\n",
      "SoVs are left with only reactive perception capability, and rely\n",
      "solely on the SoRs for proactive perception. The on-board\n",
      "fusion engine has to fuse information from multiple SoRs, in\n",
      "case one SoR fails, the fusion engine can still utilize data from\n",
      "other SoRs to guide its navigation. In addition, in this stage\n",
      "we cannot solely rely on the C-V2X network, the SoV needs\n",
      "to also receive information from the regular 5G network, such\n",
      "that in case the C-V2X network fails, the fusion engine can\n",
      "switch to the regular 5G network for trafﬁc information. If\n",
      "both networks fail, the fusion engine needs to deploy a safety\n",
      "strategy, such as stopping the vehicle at the shoulder of the\n",
      "road.\n",
      "Efﬁciency is the key challenge in the IPAD stage : in the\n",
      "IPAD stage, all semantic information from the SoRs and the\n",
      "SoVs are aggregated to the ITCS to form a global perception\n",
      "map with detailed information of each vehicle, and the ITCS\n",
      "generates a global navigation plan for each autonomous vehi-\n",
      "cle. The objective is to balance the trafﬁc load on each road\n",
      "to achieve maximum trafﬁc efﬁciency. Then the SoRs perform\n",
      "local trajectory planning for each autonomous vehicle, the\n",
      "fusion engine is responsible for handling transitions between\n",
      "the SoRs, and switching to the on-board planner when the\n",
      "SoRs become unavailable.\n",
      "REFERENCES\n",
      "[1] B. Yu, W. Hu, L. Xu, J. Tang, S. Liu, and Y . Zhu, “Building the comput-\n",
      "ing system for autonomous micromobility vehicles: Design constraints\n",
      "and architectural optimizations,” in 2020 53rd Annual IEEE/ACM Inter-\n",
      "national Symposium on Microarchitecture (MICRO) . IEEE, 2020, pp.\n",
      "1067–1081.\n",
      "[2] “Road trafﬁc injuries and deaths—a global problem,” Centers for Dis-\n",
      "ease Control and Prevention and others, Tech. Rep., 2019.\n",
      "[3] M. Blanco, J. Atwood, S. M. Russell, T. Trimble, J. A. McClafferty,\n",
      "and M. A. Perez, “Automated vehicle crash rate comparison using\n",
      "naturalistic data,” Virginia Tech Transportation Institute, Tech. Rep.,\n",
      "2016.\n",
      "[4] A. Hooper, “Cost of congestion to the trucking industry: 2018 update,”\n",
      "2018.[5] N. R. Council et al. ,Assessing and managing the ecological impacts of\n",
      "paved roads . National Academies Press, 2005.\n",
      "[6] S. Liu and J.-L. Gaudiot, “Autonomous vehicles lite self-driving tech-\n",
      "nologies should start small, go slow,” IEEE Spectrum , vol. 57, no. 3,\n",
      "pp. 36–49, 2020.\n",
      "[7] S. Liu, L. Li, J. Tang, S. Wu, and J.-L. Gaudiot, “Creating autonomous\n",
      "vehicle systems,” Synthesis Lectures on Computer Science , vol. 8, no. 2,\n",
      "pp. i–216, 2020.\n",
      "[8] S. Liu, B. Ren, X. Shen, and Y . Wang, “Cocopie: Making mobile\n",
      "ai sweet as pie–compression-compilation co-design goes a long way,”\n",
      "arXiv preprint arXiv:2003.06700 , 2020.\n",
      "[9] S. Liu, J. Tang, C. Wang, Q. Wang, and J.-L. Gaudiot, “A uniﬁed cloud\n",
      "platform for autonomous driving,” Computer , vol. 50, no. 12, pp. 42–49,\n",
      "2017.\n",
      "[10] A. Dosovitskiy, G. Ros, F. Codevilla, A. Lopez, and V . Koltun,\n",
      "“CARLA: An open urban driving simulator,” in Proceedings of the 1st\n",
      "Annual Conference on Robot Learning , 2017, pp. 1–16.VISION -BASED NAVIGATION OF AUTONOMOUS VEHICLE IN ROADWAY \n",
      "ENVIRONMENTS  WITH UNEXPECTED HAZARDS  \n",
      " \n",
      "Mhafuzul Islam * \n",
      "Ph.D. Student  \n",
      "Glenn Department of Civil Engineering , Clemson University  \n",
      "351 Fluor Daniel Engineering Innovation Building, Clemson, SC 29634  \n",
      "Tel: (864) 986-5446 , Fax: (864) 656 -2670  \n",
      "Email: mdmhafi@clemson.edu  \n",
      " \n",
      " \n",
      "Mashrur Chowdhury, Ph.D., P.E., F. ASCE  \n",
      "Eugene Douglas Mays Professor of Transportation  \n",
      "Glenn Department of Civil Engineering, Clemson University  \n",
      "216 Lowry Hall, Clemson, South Carolina 29634  \n",
      "Tel: (864) 656 -3313, Fax: (864) 656 -2670  \n",
      "E-mail: mac@clemson.edu  \n",
      " \n",
      "Hongda Li  \n",
      "Ph.D. Student  \n",
      "Division of Computer Science  \n",
      "School of Computing , Clemson University  \n",
      "220 McAdams Hall, Clemson, South Carolina 29634  \n",
      "Tel: (864) 986 -2018  \n",
      "E-mail:   hongdal@clemson.edu  \n",
      " \n",
      "Hongxin Hu, Ph.D.  \n",
      "Assistant Professor  \n",
      "Division of Computer Science  \n",
      "School of Computing, Clemson University  \n",
      "217 McAdams Hall, Clemson, South Carolina 29634  \n",
      "Tel: (864) 656 -2847  \n",
      "E-mail: hongxih@clemson.edu  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "*Corresponding author  \n",
      "Abstract: 223 words + Text: 5289  + References: 1308  + 1 table: 250 = 7070 words  \n",
      "Submission date: May 16, 201 9 \n",
      " \n",
      " \n",
      "Submitted to Transportation  Research Record  - 2019 Islam,  Chowdhury,  Li, Hu   2 \n",
      " \n",
      " \n",
      " ABSTRACT  \n",
      "Vision -based navigation of autonomous vehicle s primarily depends  on the  Deep Neural Network \n",
      "(DNN)  based systems  in which the controller obtains input from sensors/detectors, such as  cameras \n",
      "and produces a vehicle control output , such as a steering wheel angle  to navigate the vehicle safely \n",
      "in a roadway traffic  environment . Typically, these DNN -based systems  of the autonomous  vehicle \n",
      "are trained  through  supervised learning ; however, r ecent studies show that a trained DNN -based \n",
      "system  can be compromised  by perturbation or adversarial input s. Similarly, this perturbation can \n",
      "be introduce d into the DNN -based systems of autonomous vehicle by unexpected roadway \n",
      "hazard s, such as debris and roadblock s. In this study, we first introduce a roadway hazardous  \n",
      "environment (both intentional and unintention al roadway hazards ) that can compromise the DNN -\n",
      "based navigational system  of an autonomous vehicle , and produc es an incorrect steering wheel \n",
      "angle, which can cause crashes resulting in fatalit y and injur y. Then , we develop a  DNN -based  \n",
      "autonomous  vehicle driving system  using  object detection and semantic segmentation to mitigate \n",
      "the adverse effect of this type of hazardous environment, which  helps the autonomous vehicle to \n",
      "navigate safely around such hazards. We find that our developed DNN -based  autonomous vehicle \n",
      "driving system  including  hazardous object detection and semantic segmentation  improve s the \n",
      "navigational ability of an autonomous  vehicle to avoid a potential hazard  by 21% compared  to the \n",
      "traditional DNN -based autonomous vehicle driving system.   \n",
      " \n",
      "Keywords:  Roadway Hazard , Autonomous Vehicle, Deep Neural Network, Driving Model \n",
      "  Islam,  Chowdhury,  Li, Hu   3 \n",
      " \n",
      " \n",
      " INTRODUCTION  \n",
      "According to the 2016 American automobile association report , 50,658 crashes occurred in the \n",
      "U.S. from  the year 2011 to 2014 due to road way hazards resulting in  9,805 injuries and 125 deaths  \n",
      "(1). The road way hazards, such as  debris , are considered to be non-fixed and unexpected object s \n",
      "on the travel or driving lane of the roadway  and include object s that have fallen from vehicles  or \n",
      "have come from construction sites or littering. Given that the autonomous vehicle is considered  as \n",
      "the future of surface transportation, its ability to detect  debris or hazard s and then navigat e safely \n",
      "around them is crucial for avoid ing potential crash es. Recently, s uch navigation al task has been \n",
      "accomplished using Deep Neural Network (DNN) . Typically, a n autonomous vehicle perceives its \n",
      "surrounding roadway environment using  sensors , and the software running in the vehicle \n",
      "determines the action to be taken based on the input from the sensors . Several types of sensors , \n",
      "such as vision -based  sensor (e.g. , Camera) , LID AR, and Radar  are currently available for th e \n",
      "perception task . Due to the cost-effectiveness of the vision -based sensor compared to the other \n",
      "types of sensors (e.g. , LIDAR  and Radar),  vision -based navigation  becomes an attractive solution \n",
      "for autonomous vehicle s (2)(3)(4). \n",
      "The recent development of DNN s, in particular , Convolutional Neural Network (CNN) (5), \n",
      "has improved vision -based navigation for autonomous vehicle s significantly . After being trained \n",
      "and tested using  a dataset collected by sensors , these CNN models are then deployed in \n",
      "autonomous vehicles to navigate  the vehicle safely. For example, during training , the CNN -based \n",
      "end-to-end driving model  maps a relationship between the driving behavior of human s using \n",
      "roadway images collected from cameras and the steerin g wheel  angle  (6)(7). Thus, the \n",
      "performance of autonomous vehicle s primarily depends on the training dataset , meaning if  a \n",
      "hazard that the CNN model is not trained  on appears on the roadway, the autonomous veh icle \n",
      "driving model may produc e an incorrect steering wheel angle  and may cause a crash.  A recent \n",
      "study shows that the autonomous vehicle navigation system may fail to navigate  safely  due to \n",
      "several  reasons , such as Radar sensor failure, camera sensor failure, and software failure  (8). This \n",
      "study addresses the situation where a well -trained driving model may fail due to unexpected \n",
      "hazards that may lead to unsafe  navigation , and then  explor es the use of object detection and \n",
      "semantic segmentation (9) for mitigating  the navigational  problem in this hazardous condition.  \n",
      "The remainder of the paper is organized  as follows . The related work section explore s the \n",
      "existing studies on autonomous vehicle navigation , state -of-art DNN -based autonomous vehicle \n",
      "driving models , and the limitations  of the tradition al DNN -based mode l. Then we introduce the \n",
      "method developed in this study for navigating an  autonomous vehicle on a roadway with \n",
      "unexpected hazards. Furthermore, w e validate our pr oposed method using three case studies : (i) a \n",
      "model trained using a  dataset that includes hazards but without considering them as separate input \n",
      "feature s; (ii) a model trained on a dataset that consider s hazards as separate  input features and uses \n",
      "a distance measurement sensor  and image segmentation ; (iii) a model trained on a dataset that \n",
      "considers hazards as separate input features and only uses image segmentation.  In the second and \n",
      "third case stud ies, we introduce a DNN -based autonomous vehicle driving system  to enhance the Islam,  Chowdhury,  Li, Hu   4 \n",
      " \n",
      " \n",
      " ability of an autonomous vehic le to navigate safely in a hazardous  environment . Then we present  \n",
      "the experimental setup employed in this study . After that , we evaluate  all the case scenarios  and \n",
      "report the results obtained through  our experiment s, and finally, we discuss the conclusion s and \n",
      "suggest the areas for future  work.  \n",
      "RELATED WORK  \n",
      "This section reviews the previous  research on hazard detection, DNN -based driving systems  used \n",
      "in an autonomous vehicle, and the techniques for and the importance of object detection and image \n",
      "segmentation  in addition to t he limitations of using DNN  in autonomous vehicle s.  \n",
      " \n",
      "DNN -based Autonomous Vehicle Driving Model  \n",
      "DNN -based autonomous  vehicle  driving systems  are rapidly evolving (7)(10). Not only softwar e \n",
      "companies such as Wa ymo (Google)  Uber, and Lyft are using the DNN -based  system s for \n",
      "autonomous  vehicle s, but many car companies such as Tesla, Volvo, BMW, and Ford  are currently \n",
      "working on DNN -based autonomous vehicle driving systems  (11). In such system s, sensors like \n",
      "camera s, LIDAR, and Radar  provide input to  DNN models , such as  Convolutional Neural Network \n",
      "(CNN) (5) or Recurrent Neural  Network (RNN) (12), which then produce outputs such as steering \n",
      "wheel angle  and velocity.  For example, the autonomous vehicle architecture developed by \n",
      "NVID IA, named DAVE -2, uses a CNN model w hich takes input from  a camera and outputs a \n",
      "steering  wheel command s for navigation  (7), while Udacity autonomou s vehicle driving \n",
      "architectures include  both CNN -based ( e.g., Autumn) and RNN -based (e.g. , Chauffeur using CNN \n",
      "and RNN ) (13). This study  used a CNN -based driving model similar to DAVE -2 as it is the \n",
      "fundament al base of DNN -based autonomous vehicle system s.  \n",
      " \n",
      "DNN -based autonomous  vehicle  driving systems , which  are intrinsically  software system s, \n",
      "can be error -prone  and cause severe consequences if they do not function as intended. Several \n",
      "studies have shown the vulnerabilities of the existing DNN  models  (14)(15)(16)(17). For example, \n",
      "DNN -based image classification can be exploited  by adding a small pertur bation to an input image \n",
      "such that the DNN model misclassif ies it as another category , a vulnerability recently confirmed \n",
      "by (18), which found that attackers can physically modify objects  using a low-cost technique to \n",
      "cause classification errors in DNN -based vision systems. Th ese perturbations  can be introduced  \n",
      "under widely varying distances, angles, and resolutions. For example, in (18) perturbations cause d \n",
      "a DNN  model  to interpret a subtly  modified physical stop sign as a speed limit of 45 mph sign. \n",
      "Similarly, the debris or roadblocks on the road can also compromise the autonomous vehicle \n",
      "driving system  by producing incorrect steering wheel angle s, potentially causing a fatal collision. \n",
      "These limitations prompted  this study to evaluate the impact of unexpected  hazardous \n",
      "environments on a DNN -based autonomous vehicle driving system .   \n",
      " \n",
      "Autonomous Vehicle Dataset  \n",
      "Data are an important part of deep learning -based  systems , and t his study  require s a dataset that \n",
      "supports  (i) end-to-end driving systems (input: image; output: steering wheel angle) , (ii) image Islam,  Chowdhury,  Li, Hu   5 \n",
      " \n",
      " \n",
      " segmentation, and (iii) hazard detection. To find an appropriate one, we explore various  existing  \n",
      "dataset s used by the a utonomous vehicle communit y. The closest dataset provided by Udacity , \n",
      "which  supports end -to-end data and image segmentation, but it does not provide the ground truth \n",
      "for hazard s in the drivable lane (13). KTTI (19) and Cityscape (20) dataset s also do not support \n",
      "hazard detection as ground truth data. The dataset  matching our requirements  the closest  is the \n",
      "Lost and Found dataset (21), which contains the image as the input , and the yaw rate (angular \n",
      "velocity) , but not the steering wheel angle  required by this study , as an output . Since existing \n",
      "dataset s do not fully meet our needs, af ter careful consideration , we have created our own dataset \n",
      "using simulation as described in  the experimental setup section.  \n",
      " \n",
      "DNN -based Object Detection and Segmentation  \n",
      "Object detection and classification are core component s of autonomous driving. By detecting and \n",
      "classifying the objects, the autonomous vehicle controller de termines safe navigation  for both path \n",
      "planning  and route planning. If an autonomous vehicle is not able to detect unexpected hazard s on \n",
      "the road , it will not be able to navigate safely,  perhaps resulting in a crash. However, d etecting \n",
      "these objects or hazard s is a challenging task . While various senso rs, such as Radar  and LID AR, \n",
      "can be used  for accurate distance and velocity measurement, these sensors are relatively costly  \n",
      "than camera sensor  (21). Considering the se limitations , vision -based sensor s, such as camera , are \n",
      "being used  on autonomous vehicle s for the navigation al task. With the recent development of \n",
      "DNN s, DNN -based object detection and semantic segmentation can be applied to detect  these \n",
      "roadway hazards , making navigation of autonomous  vehicle s safer .  \n",
      " \n",
      "Semantic  segmentation  is a technology  that has been widely used in the computer vision \n",
      "area to divide an unknown image into different parts (22), can be applied to an image containing \n",
      "unknown objects. This technology is effective in providing the scenario depicted by an image, \n",
      "allowing the DNN to capture additional information about the dataset during training. There are \n",
      "three major types of semantic segmentation technologies : Region -based  semantic  segmentation  \n",
      "(23)(24), Fully Convolutional Network ( FCN )-based  semantic segmentation  (25)(26)(27) and \n",
      "Weakly -Supervised  semantic segmentation  (28)(29)(30). The region -based semantic segmentation \n",
      "provides s egmentation based on the results of object detection , meaning it can  be developed  on \n",
      "any CNN model. The FCN -based semantic segmentation segments each pixel of the image , \n",
      "meaning it does not require extracting regions of the image and, thus, can be applied to arbitrary \n",
      "sizes of images. The weakly supervised semantic segmentation technology , which was developed  \n",
      "to reduce the labeling cost of a large  dataset  (30), achieves semantic s egmentation by exploiting \n",
      "annotated bounding boxes or image -level labels.  While r ecent studies show that segmentation -\n",
      "based navigation can improve navigational  performance (31)(32)(33), none  consider s the \n",
      "navigation of autonomous vehicle s in haza rdous environments. Thus, b y leveraging these DNN -\n",
      "based models, we can detect hazard s and then extract  their semantic information from images  \n",
      "obtained from the camera sensor of an autonomous vehicle .  The approach adopted in this study  \n",
      "uses an FCN -based model  as one such network is relatively small , yet the network yields fast Islam,  Chowdhury,  Li, Hu   6 \n",
      " \n",
      " \n",
      " result s (25). To the best of our knowledge, this is the first work that develop s a DNN -based \n",
      "autonomous vehicle driving system focusing on unexpected roadway hazardous  environments.  \n",
      "METHOD  \n",
      "In this section , we describe our approach for  develop ing a safer autonomous vehicle driving  system  \n",
      "in a hazardous environment . This study use s DNN -based  object detection and segmentation  to \n",
      "create a corrected image , which is subsequently used by  the autonomous vehicle driving system  to \n",
      "predict the steering wheel angle. As presented in Figure 1, we develop a DNN-based  autonomous \n",
      "vehicle driving system , which  comprise s of three DNN models . The first one is the DNN -based \n",
      "hazard detection and segmentation model, which d etect s the hazard  and creates a segmented \n",
      "image . The second model is the hazard analysis and avoidance model, which fuses  the segmented \n",
      "image  with the original input image  from the dashboard camera  to make the autonomous vehicle \n",
      "driving model aware of the unexpected roadway hazard s.  This model  then analyz es the hazard  \n",
      "and determin es if the hazard  should be ignored or consider ed as a threat for a potential crash using \n",
      "a threat factor ( 𝑇𝑓). The thi rd model is  the DNN -based autonomous vehicle driving model, which \n",
      "takes the fused image with hazard information and produce s the steering wheel angle required to \n",
      "navigate the vehicle safely  in an unexpected hazardous environment . We provide the detail \n",
      "description of these three models in the following subsections . \n",
      " \n",
      "FIGURE 1 DNN -based  autonomous  vehicle  driving system in an unexpected  hazardous \n",
      "environment .  \n",
      " \n",
      "DNN -based hazard detection and segmentation model  \n",
      "For hazard  detection and image segmentation, this study use s an FCN, which is a DNN -based \n",
      "image object detection and segmentation model  (25). Figure 2  shows the structure of the FCN \n",
      "network used in our study. It takes an input of image size 400x600x3 and outputs a segmented \n",
      "image of the same size. We use a pre -trained network with a weight o f VGGNet  (34), which is  a \n",
      "deep convolutional network for large-scale image recognition , and then we re-trained the model \n",
      "with our training dataset to classify the hazard and perform image segmentation.  \n",
      "Islam,  Chowdhury,  Li, Hu   7 \n",
      " \n",
      " \n",
      "  \n",
      "FIGURE 2 FCN -based object detection and image segmentation model used in this study.  \n",
      " \n",
      "Hazard analysis and avoidance model  \n",
      "As shown in  Figure  1, the image  captured  from the center dashboard camera first goes to the hazard \n",
      "detection and segmentation model , which provides an output of the detected object  in addition to \n",
      "a segmented image. Then, t his output is combined  with the original image in the hazard analysis \n",
      "and avoidance mode l. In this study, we develop a hazard analysis and avoidance model based on \n",
      "the following equation:   \n",
      " \n",
      "𝐼 =(1− 𝑇𝑓)×𝐼𝑜𝑟𝑖𝑔𝑖𝑛𝑎𝑙 +𝑇𝑓 × 𝐼𝑠𝑒𝑔𝑚𝑒𝑛𝑡𝑒𝑑  \n",
      "where  𝐼 is the image used to predict the autonomous vehicle driving model ; 𝐼𝑜𝑟𝑖𝑔𝑖𝑛𝑎𝑙  is the data \n",
      "from the center  dashboard  camera of the vehicle ; 𝐼𝑠𝑒𝑔𝑚𝑒𝑛𝑡𝑒𝑑  is the segmented image of  𝐼𝑜𝑟𝑖𝑔𝑖𝑛𝑎𝑙   \n",
      "containing the hazardous object detect ed and segment ed; and 𝑇𝑓 is the threat value  of the detected \n",
      "hazardous object or physical -world threat object . This t hreat value  depends on the position of a \n",
      "detected object on a driving lane . If the object  is dangerous to the autonomous vehicle, it will have \n",
      "a high threat factor , while a negligible threat object will have a low er threat factor.  This threat \n",
      "value depends on the longitudinal and latitudinal  distance from the autonomous vehicle. \n",
      "Depending on the hazardous object localization technique, w e have used two procedures to \n",
      "determine the threat value : (ii) Procedure  1 - threat value determination using a distance \n",
      "measurement sensor  (e.g., Radar ); and  (ii) Procedure 2 – threat value determination using image \n",
      "segmentation .  \n",
      " \n",
      "Procedure 1 - threat value determination using  a distance measurement sensor   \n",
      "According to the first procedure , we measure the longitudinal distance ( 𝑙𝑥), and latitudinal distance \n",
      "(𝑙𝑦) of hazardous objects from the vehicle using a distance measurement sensor. If the vehicle is \n",
      "moving forward  (longitudinal movement) or steering towards (latitudinal movement) the hazard \n",
      "the value of 𝑙𝑥 and 𝑙𝑦 decreases , respectively , and hence the haz ard poses  a higher threat  of \n",
      "colliding with the vehicle. We consider the hazard as a threat to the vehicle if the hazard is within \n",
      "the longitudinal distance , 𝑙𝑥,𝑚𝑎𝑥 and latitudinal distance , 𝑙𝑦,𝑚𝑎𝑥. In our study, w e use the Radar \n",
      "Islam,  Chowdhury,  Li, Hu   8 \n",
      " \n",
      " \n",
      " sensor  to measure the longitudinal distance and the latitudinal  distance , and we measure the threat \n",
      "value  using the following equations :  \n",
      " \n",
      "𝑇 =√(𝑙𝑥,𝑚𝑎𝑥 − 𝑙𝑥\n",
      "𝑙𝑥,𝑚𝑎𝑥)2\n",
      "+(𝑙𝑦,𝑚𝑎𝑥 − 𝑙𝑦\n",
      "𝑙𝑦,𝑚𝑎𝑥)2\n",
      " \n",
      " \n",
      "𝑇𝑓= {𝑇−𝑇𝑚𝑖𝑛\n",
      "𝑇𝑚𝑎𝑥 −𝑇𝑚𝑖𝑛               𝑖𝑓 𝑙𝑦≤ 𝑙𝑦,𝑚𝑎𝑥 ;𝑎𝑛𝑑  𝑙𝑥≤ 𝑙𝑥,𝑚𝑎𝑥\n",
      "0                                  𝑖𝑓 𝑙𝑦> 𝑙𝑦,𝑚𝑎𝑥 ;𝑜𝑟 𝑙𝑥> 𝑙𝑥,𝑚𝑎𝑥  \n",
      " \n",
      "where, 𝑇𝑓 is the threat value corresponding to the hazardous object ; 𝑙𝑥  and 𝑙𝑦 are the  longitudinal \n",
      "distance and latitudinal distance in centimeters (cm) to the detected hazard from the vehicle , \n",
      "respectively ; 𝑙𝑥,𝑚𝑎𝑥  and 𝑙𝑦,𝑚𝑎𝑥   is the maximum longitudinal distance and maximum latitudinal \n",
      "distance, correspondingly , to consider the hazard as a threat ; and 𝑇 is the threat value calculated \n",
      "from the longitudinal  and the latitudinal distance . Then,  the value of  𝑇 is normalized using the \n",
      "Min-Max normalization technique to obtain a value between 0 to +1  to determine the final threat  \n",
      "value , 𝑇𝑓 (35)(36). In our experiment, we hav e selected  𝑙𝑥,𝑚𝑎𝑥   as 6000cm  as this is the Radar’s \n",
      "maximum range of finding an object  in our experimental setup , and 𝑙𝑦,𝑚𝑎𝑥  is selected as 370cm \n",
      "which is the standard lane width of a roadway . We can visualize the relationship between  the threat \n",
      "value, and longitudinal and latitudinal distance  in Figure 3.  \n",
      " \n",
      "  \n",
      "FIGURE 3 Heatmap for the threat value based on the longitudin al and latitudi nal distance  \n",
      "of a hazardous object  using Radar sensor  data . \n",
      " \n",
      "Procedure 2 – threat value  determination  using image segmentation   \n",
      "In this procedure , instead of using a Radar sensor , we use the segmented image  to calculate the \n",
      "threat  value . In this way, we can eliminate the use of any sensor data beside s camera video feed.  Islam,  Chowdhury,  Li, Hu   9 \n",
      " \n",
      " \n",
      " After the image segmentation, we get the image coordinates  (𝑥,𝑦) of the hazard. As the camera is \n",
      "located at the center dashboard of the vehicle  facing the front roadway , we measure the relative \n",
      "distance of the hazardous object in the image of size (ℎ,𝑤), from the  bottom center pixel, (ℎ,𝑤\n",
      "2) to \n",
      "quantify the threat. We calculate the threat  based on the location of the hazard in the segmented \n",
      "image using the following equation : \n",
      " \n",
      "𝑇𝑓=1− √(𝑥−ℎ)2+(𝑦− 𝑤\n",
      "2)2\n",
      "ℎ2+ (𝑤\n",
      "2)2 \n",
      " \n",
      "where, 𝑇𝑓 is the threat value corresponding to the hazardous object  located in the segmented image \n",
      "at location (𝑥,𝑦) pixels , where (𝑥,𝑦) is the pixel value closest to the bottom center pixel, ( ℎ,𝑤\n",
      "2), \n",
      "of the image.  The value of ℎ and 𝑤 indicates the height and width of the image , respectively . As \n",
      "the camera of the vehicle is located at the center of the vehicle  facing the front roadway , we subtract \n",
      "ℎ and 𝑤\n",
      "2 values from the 𝑥 and 𝑦 values, r espectively , to obtain the longitudinal and latitudinal \n",
      "distance  of the hazard relative to the front center of the vehicle. As we  described  the equation \n",
      "above, we calculate the t hreat value . We can visualize the threat  value in Figure 4, where the  threat \n",
      "value decrease s as the object moves from the center b ottom  pixel  of the image.  \n",
      " \n",
      "FIGURE 4 Heat map for the threat value  based on the  location of hazard using pixel value \n",
      "from  the segmented  image.  \n",
      " \n",
      "DNN -based autonomous vehicle driving model   \n",
      "In our study, we have implemented an autonomous  vehicle driving model similar to DAVE -2, an \n",
      "end-to-end autonomous vehicle driving model  (7). As shown in Figure 5, the network receives an \n",
      "input image of 400x600x3 pixel s and produces a steering wheel angle as an output. This network \n",
      "includes one lambda layer,  one normalization layer,  five convolution layers (Conv2D), and four \n",
      "fully connected (FC)  layers. We have used a 5x5 kernel (i.e., filters) and 2x2 stride  (i.e., the Islam,  Chowdhury,  Li, Hu   10 \n",
      " \n",
      " \n",
      " increment of kernel movement) in the first 3 Conv2D layers, and a 1x1 stride and a 3x3 kernel in \n",
      "the last two Conv2D layers. The entire network contains a total of 7,970,619 trainable parameters.  \n",
      " \n",
      "FIGU RE 5 CNN -based end -to-end autonomous vehicle driving model used in this study.  \n",
      " \n",
      "We train our driving model  of an autonomous vehicle  from the output of hazard analysis and \n",
      "avoidance model followed by the deployment to test the performance. After the training, our \n",
      "trained autonomous vehicle driving model  is aware of hazardous objects on the roadway and \n",
      "produce s a steering wheel angle to navigate safely around the hazard.  \n",
      "EXPERIMENTAL SETUP  \n",
      "In the experimental setup , we describe the data collection  method , data preparation , and data \n",
      "augmentation ; and finally , we train and validate the DNN -based  autonomous vehicle driving  \n",
      "model . The steps of our experiment setup are as follows:    \n",
      " \n",
      "Data Collection  \n",
      "For this study, we have used the robotics simulation platform  Webots  (37) to create the roadway \n",
      "envir onment with hazardous objects and to collect the data including the driving attributes  of the \n",
      "camera  image, timestamp, location, vehicle speed, and steering wheel angle . The following \n",
      "subsections describe the collection procedure of the dataset.     \n",
      " \n",
      "Roadway Environment Setup   \n",
      "The roadway  built in the simulation  consist s of two lanes in each direction  and 1663m in  length  \n",
      "with 16 curves (having 45 degree to 90 degree  radius of curvature) and two intersections  as shown  \n",
      "in Figure 6(a). Six additional non-autonomous vehicles are placed randomly on the roadway. The \n",
      "hazard ous debris , which include s five objects : rocks, wooden box es, oil barrel s, wooden pallet s, \n",
      "and section s of pipe are created in W ebots  (37) and placed  randomly on the roadway  as shown in  \n",
      "Figure 6(b). \n",
      " \n",
      "Islam,  Chowdhury,  Li, Hu   11 \n",
      " \n",
      " \n",
      "  \n",
      "FIGURE 6 Roadway environment setup for an autonomous  vehicle  with hazardous objects . \n",
      " \n",
      "Autonomous Vehicle Setup  \n",
      "For collecting the data , the autonomous vehicle is equipped  with three dashboard cameras , a front, \n",
      "left and right camera  (as shown  in Figure 7) and a Radar  sensor . The data collected using these \n",
      "cameras are used to train the end-to-end autonomous vehicle driving model. For example,  as seen \n",
      "in Figure 8, the images collected by the left and right camera differ from the center camera. After \n",
      "training , the autonomous  vehicle use s only a single front camera to navigate through the roadway , \n",
      "similar  to the DAVE -2 system  (7). In our developed driving model, we have used the Delphi ESR \n",
      "Radar sensor , which is commercially used in the existing  autonomous vehicles  (38). We have u sed \n",
      "the medium range mode configurations (horizontal field of view of 90 degrees and a maximum \n",
      "range of 6000 cm ) of the Radar sensor in our autonomous vehicle  (39).  We have also equipped \n",
      "the vehicle with three  other Radar sensors in three  direction s (left, right and back side) for \n",
      "monitoring the near -by traffic condition and vehicles.  These Radars sensors are also configured  in \n",
      "the medium range mode .  \n",
      " \n",
      " \n",
      "FIGURE 7 Camera placements in the a utonomous vehicle ( left, center, and right camera s). \n",
      "Islam,  Chowdhury,  Li, Hu   12 \n",
      " \n",
      " \n",
      "  \n",
      " \n",
      "FIGURE 8 Example of images collected by the three cameras  in the  autonomous vehicle (left, \n",
      "center, and right camera  images (from left to right) ) \n",
      " \n",
      "Data  Preparation  \n",
      "After collecting the data, we prepare the image dataset for training  the end-to-end driving model  \n",
      "by normaliz ing and resizing . As shown in Figure 9, the steering wheel angle  output  is normalized  \n",
      "between the value s of -0.5 and +0.5, where a positive value indicate s the steering to the right , and \n",
      "a negative value represents steering to the left  using linear transformation  following this equation :  \n",
      " \n",
      "𝜃𝑛𝑜𝑟𝑚𝑎𝑙𝑖𝑧𝑒𝑑  = −0.5+max (0, min (1.0 ,𝜃𝑟𝑎𝑤 − 𝜃𝑚𝑖𝑛\n",
      "𝜃𝑚𝑎𝑥 − 𝜃𝑚𝑖𝑛))  \n",
      " \n",
      "where, 𝜃𝑛𝑜𝑟𝑚𝑎𝑙𝑖𝑧𝑒𝑑  is the normalized steering angle between -0.5 and +0.5; 𝜃𝑟𝑎𝑤 is the actual \n",
      "steering wheel angle  (in radian s) measured from the vehicle ; 𝜃𝑚𝑎𝑥   and 𝜃𝑚𝑖𝑛 are the maximum and \n",
      "minimum steering wheel angle , respectively . We also normalize the input images for training , \n",
      "which is necessary to improve the DNN model performance  (40). Normalization is also done on \n",
      "the input images. The red, green, and blue ( RGB ) channel values of the input  images are \n",
      "normalized  between  the values of -1.0 and + 1.0, and their top 200 pixels is cropped using a Lambda  \n",
      "layer  (as shown Figure 10) as top portion of the image is not necessary to predict the steering wheel \n",
      "angle , and doing so does not impact  the steering wheel angle output  of the driving model.  For all \n",
      "data collected, we use a n online image annotation tool, LabelMe (41), for labeling the hazard ous \n",
      "object  and segmented image . Using this tool, we have created the ground truth data for training \n",
      "the image segmentation model for detecting and segmenting the hazards in an image.  \n",
      "Islam,  Chowdhury,  Li, Hu   13 \n",
      " \n",
      " \n",
      "  \n",
      "FIGURE 9 Example of a normalized steering wheel angle  plot from  the training dataset . \n",
      " \n",
      "FIGURE 10 Example  of an original and cropp ed image i n the training dataset . \n",
      " \n",
      "Data Augmentation  \n",
      "To obtain satisfactory performance from the driving model , it is necessary to train the model on  \n",
      "multiple training dataset s. Using the techniques of data augmentation , we have created  additional \n",
      "data from the existing data  through affine transformation  (42), specifically random rotation, \n",
      "random brightness change, and horizontal flipping o f the images , to double the size of the dataset \n",
      "as shown in  Table 1 .  From our first simulation, we have collected 1390 images  in total , and we \n",
      "have split the image dataset in training  (i.e., 1112 images)  and validation dataset  (i.e., 27 8 images)  \n",
      "as shown in column 2 of Table 1. Then  we have doubled the dataset size (i.e., 2780 images) using \n",
      "data augmentation as presented in column 3 of Table 1. Among these 2780 images, 222 4 images \n",
      "are used for training , and the remaining 55 6 images are used for validation. Among the 222 4 \n",
      "images used for training, 468 images contained hazards. Furthermore, we have collected 104 \n",
      "images from a second simulation where all the images contained hazard. These 104 images are \n",
      "used to evaluate or test the driving mode l performance . \n",
      "Islam,  Chowdhury,  Li, Hu   14 \n",
      " \n",
      " \n",
      " TABLE 1 Dataset description  \n",
      "Dataset type Collected \n",
      "dataset size Dataset size after data \n",
      "augmentation  \n",
      "Dataset size   1390  2780  \n",
      "Training dataset  size  1112 2224 \n",
      "Validation  dataset size 278 556 \n",
      "Testing  dataset size (all containing hazard)  52 104 \n",
      " \n",
      "Model Training  and Validation  \n",
      "After the development of the end-to-end autonomous vehicle driving model , we train it using the \n",
      "augmented dataset . This dataset is divided  into two, 80% in a t raining  set (2224 images as per \n",
      "Table 1 ) and the remaining 20% in a validation set  (556 images as per Table 1) . We then train \n",
      "three models for our evaluation :  \n",
      "• Case 1:   A model trained on a dataset that includ es hazards  but without considering them \n",
      "as a separate input feature . \n",
      "• Case 2:  A model trained on a dataset that considers  hazards as separate  input feature s and \n",
      "uses a distance measurement sensor and image segmentation . In this case, the threat value \n",
      "is determin ed using a distance measurement sensors ( Radar in our case), following  the \n",
      "Procedure  1 as described in the method section .   \n",
      "• Case 3:  A model trained on a dataset that considers  hazards as separate input features  and \n",
      "uses image segmentation . In this case, the threat value is determin ed using  the image \n",
      "segmentation , following the P rocedure  2 as described in  the method section .   \n",
      " \n",
      "For the training  of the autonomous  vehicle driving model , we have used Adam optimize r that can \n",
      "change the learning rate dynamically (43). The m ean square error based loss function , a dropout \n",
      "rate of 0.5  in the last four FC layers, and L2 regularization  are used to reduce overfitting  and u nder-\n",
      "fitting and to minimize training  error  (44). We use model checkpoints to stop the training when \n",
      "the validation loss is not decreasing over time (45). Figure 11(a) shows the performance of the \n",
      "model training for Case 1, where the training is stopped after 14 epoch s because the model does \n",
      "not exhibit much improvement after 1 1 epochs . We observe  no overfitting or under -fitting  during \n",
      "the training.  In Case 2, the model stopped training after 16 epochs ( as shown in Figure 1 1(b)), and \n",
      "in Case 3, the model stopped the training after 15 epochs ( as shown in Figure 11(c))  Islam,  Chowdhury,  Li, Hu   15 \n",
      " \n",
      " \n",
      "  \n",
      "FIGURE 11 Training  and validation  performance of the end-to-end d riving model for Case \n",
      "1, Case 2, and Case 3 on the training  and validation dataset . \n",
      " \n",
      "ANALYSIS RESULT S \n",
      "After training and validating the model using the dataset from the first simulation, we evaluate the \n",
      "trained  end-to-end autonomous vehicle driving model  using the test dataset of 104 images (as \n",
      "depicted in Table 1). We have created this dataset of 104 images from a second simulation where \n",
      "all debris are placed  in the middle of the driving lane , and we measure the predicted steering wheel \n",
      "angle for each test image. In this second simulation, first , we create the ground truth by manually \n",
      "driving the vehicle on the roadway. Then we deploy the trained end-to-end autonomous vehicle \n",
      "driving model  for Case 1, Case 2 and Case 3. We then analyze the performance of the model for \n",
      "each cases using the following quantitative measures: root mean  square error (RMSE) and mean \n",
      "absolute error (MAE), and a qualitative measure through visualization.  \n",
      " \n",
      "Quantitative Results  of Model P erformance  \n",
      "The quantitative results include the RMSE and the MAE , are measured  by compar ing the predicted  \n",
      "steering wheel angle with  the actual steering wheel angle  (i.e., ground truth  data). We de fine the \n",
      "RMSE and MA E as follows:  \n",
      "Islam,  Chowdhury,  Li, Hu   16 \n",
      " \n",
      " \n",
      " 𝑅𝑀𝑆𝐸 =√1\n",
      "𝑁 ∑(𝐺𝑖−𝑃𝑖)2𝑁\n",
      "𝑖=1  \n",
      "𝑀𝐴𝐸 = 1\n",
      "𝑁 ∑(|𝐺𝑖− 𝑃𝑖|)𝑁\n",
      "𝑖=1 \n",
      "where N is  the total number of images  in the testing dataset ; and 𝐺𝑖 and 𝑃𝑖 are the ground truth and \n",
      "predicted steering wheel angle , respectively , for the 𝑖𝑡ℎ image  of the testing dataset . As shown in \n",
      "Figure 1 2, both the RMSE and M AE are higher for Case 1 than Case 2  and Case 3 . A lower RMSE \n",
      "and M AE indicate that  the predicted steering wheel angle is close ly following  the actual steering \n",
      "wheel angle  or ground truth data  related to steering wheel angle .  \n",
      " \n",
      "FIGURE 12 Error measurement  on the testing dataset . \n",
      " \n",
      "We measure  the steering wheel angle prediction accuracy and improvement of Case 2 and Case 3, \n",
      "over Case 1 . By comparing 𝑅𝑀𝑆𝐸  of Case 2 and Case 3 with  𝑅𝑀𝑆 𝐸𝑐𝑎𝑠𝑒 1, we calculat e the steering \n",
      "wheel angle prediction improvement  based on the equation below:  \n",
      "𝑃𝑒𝑟𝑐𝑒𝑛𝑡𝑎𝑔𝑒  𝑜𝑓 𝑖𝑚𝑝𝑟𝑜𝑣𝑒𝑚𝑒𝑛𝑡 =(| 𝑅𝑀𝑆𝐸 −𝑅𝑀𝑆 𝐸𝑐𝑎𝑠𝑒 1|\n",
      "𝑅𝑀𝑆 𝐸𝑐𝑎𝑠𝑒 1×100) %   \n",
      "Based on our experiment , we found a 21% improvement in the steering wheel angle prediction of \n",
      "Case  2 over Case 1 , and 18% im provement in the  steering wheel angle prediction of Case  3 over \n",
      "Case 1 . The results  suggest that both Case 2  and Case 3  improve the autonomous vehicle \n",
      "navigation to avoid  an unexpected  hazard on the roadway.   \n",
      "Qualitative Results  for Driving Direction  \n",
      "Figure 1 3 shows the qualitative results of our study  on the autonomous vehicle driving direction . \n",
      "To obtain the qualit ative  measurement, we transform the  steering wheel angle ( -0.5 to +0.5) into a \n",
      "driving direction angle  (-25 degre es to +25 degree s) using linear transformation.  In Webots, the Islam,  Chowdhury,  Li, Hu   17 \n",
      " \n",
      " \n",
      " steering wheel angle follows the Ackermann geometry , representing a linear relationship between \n",
      "steering wheel angle and driving direction  (37)(46). The prediction accuracy can be presented \n",
      "qualitative ly by observing the driving direction angle  or angle of movement of the autonomous \n",
      "vehicle . For example,  Figure 13 shows that the continuous steering wheel output of data from the \n",
      "time step of 6 4000 milliseconds  (ms) to 72000 ms window  for ground truth, Case 1, Case 2 , and \n",
      "Case 3 . In the presence of a h azard on the roadway , the autonomous vehicle driving  model is \n",
      "producing the output for maneuvering the autonomous  vehicle. According to Figure 13 , the \n",
      "autonomous vehicle is moving toward s the left for each case. For example, i n Case 1, at time step \n",
      "66000 ms, the predicted driving direction is +5.2 degree s, causing  the car to move closer  to the \n",
      "hazard  (represented here as a box ) compared to Case 2 and Case 3 . However, in Case 2  and Case \n",
      "3, the predicted driving direction is +11.7  degree  and +9.28 degree , respectively, which  is a value  \n",
      "closer to the ground truth than in Case 1 . Overall, the qualitative results  indicate better accuracy \n",
      "prediction for Case 2 and Case 3  than for Case 1.  \n",
      " \n",
      "FIGURE 13 Qualitative results  of ground truth, Case 1, Case 2 , and Case 3  of the driving \n",
      "direction . \n",
      " \n",
      "Islam,  Chowdhury,  Li, Hu   18 \n",
      " \n",
      " \n",
      " Quantitative Results for Driving Direction  \n",
      "Following  the F renet coordinate system, w e have performed quantitative  analys es of hazard  \n",
      "avoidance . In a Frenet coordinate  system, the longitudinal  movement and latitudinal movement \n",
      "are represented  in x-axis and y-axis, respectively  (47). Instead of following the Frenet coordinate \n",
      "system for the performance evaluation, we have  plotted  the time step in the x-axis and latitudinal \n",
      "movement in the y-axis (see Figure 14)  to show  the deviation of  latitudinal movement of an \n",
      "autonomous vehicle  and how the vehicle  avoid s a hazardous object  for different cases (as described \n",
      "in the ‘Model Training and Validation’ subsection)  over the time . We analyze the trajectory of the \n",
      "autonomous vehicle  and calculate the RMSE  between  the vehicle trajectory of each case  and the \n",
      "ground truth . In Figure 14 , we present the autonomous vehicle trajectories for all three cases from  \n",
      "the time step 6 2000ms to 72000 ms to show how accurately  the vehicle following the ground truth \n",
      "trajectory data  for each case  to avoid the hazardous object . For Case 2 , the vehicle trajectory \n",
      "produced from the autonomous vehicle driving systems  is closely following the ground truth  \n",
      "vehicle trajectory  compared to Case 1  and Case 3 . However, i n all cases, i.e., Case 1 , Case 2 , and \n",
      "Case 3 , the vehicle is able to avoid the hazard  (Figure 14) . In Case 1, the RMSE value was 0.52 . \n",
      "On the other hand,  the RMSE value s for Case 2 and Case 3 are  0.07 and 0.23 , respectively . We \n",
      "perform  a statistical significance test (pairwise t-test) between  the ground truth and each case \n",
      "separately  at a 95% confidence  interval . We find that Case 1 is significantly different from the \n",
      "ground truth at  a 95% confidence interval . However, Case 2, which uses  both image segmentation \n",
      "and a distance measurement sensor , and Case 3 , which only uses the segmented image, are not \n",
      "significantly different  from the ground truth . Thus, based on the statistical analys es of Case 2 and \n",
      "Case 3 , we achieve  the same  level of performance using image segmentation, and not using any \n",
      "additional distance mea surement sensor, i.e., Radar . \n",
      " \n",
      "FIGURE  14 Trajectory of the autonomous  vehicle for ground truth, Case 1, Case 2, and Case 3 . Islam,  Chowdhury,  Li, Hu   19 \n",
      " \n",
      " \n",
      " CONCLUSIONS  \n",
      "Detecting unexpected hazard s on a roadway is a crucial task for  the safe operation of an \n",
      "autonomous vehicle . In this work, we  have  developed and evaluated a  DNN -based driving system \n",
      "for autonomous vehicle s in an unexpected hazardous roadway environment . First, we detect  the \n",
      "hazard, and then using semantic segmentation , we extract the hazard information  and perform data \n",
      "fusion to improve the navigation of an autonomous vehicle . This study makes the following \n",
      "contribution s to the current body of research : (i) we evaluate  the effect of the h azardous roadway \n",
      "environment  on the DNN -based driving system  of an autonomous vehicle ; (ii) we develop a DNN -\n",
      "based driving system  for autonomous driving that can address an unexpected hazardous roadway \n",
      "environment  and can navigate the autonomous vehicle safely through this  environment.  More \n",
      "specifically, we explore the object detection and semantic segmentation based deep learning \n",
      "models to address an unsafe navigation al problem ; (iii) we contribute a new dataset that can be \n",
      "used by the autonomous vehicle community to improve the driving model in unexpected hazardous \n",
      "roadway environment.  Based on the analys es result , we conclude that our method improved the \n",
      "safety of the autonomous vehicle by 21%  in terms of  avoiding hazards , compared to a vision -based  \n",
      "navigation system of autonomous vehicles having no  hazard detection and segmentation  as \n",
      "separate input features . Future work will include fusing the temporal and spatial information into \n",
      "the DNN -based model , potentially further improv ing the safety of aut onomous vehicle s operating \n",
      "in an unexpected hazardous roadway environment.  \n",
      "ACKNOWLEDGMENTS   \n",
      "This paper is based  on the study  supported by the USDOT Center for Connected Multimodal \n",
      "Mobility (Tier 1 University Transportation Center) Grant headquartered  at Clemson  University . \n",
      "Any opinions, findings, and conclusions or recommendations expressed in this paper  are those of \n",
      "the author(s) and do not necessarily reflect the views of the  USDOT Center for Connected \n",
      "Multimodal Mobility (C2M2). The U.S. Government assumes no liability for the  contents or use \n",
      "thereof.  The authors would like to thank Aniqa Chowdhury and Mizanur Rahman, P h.D. for \n",
      "editing the paper.  \n",
      "AUTHOR CONTRIBUTION STATEMENT  \n",
      "The authors confirm contribution to the paper as follows: study conception and design: M. Islam, \n",
      "M. Chowdhury, H. Li, and H. Hu; Data collection: M. Islam; Analysis and interpretation of results: \n",
      "M. Islam, M. Chowdhury, H. Li; draft manuscript preparation: M. Islam, M. Chowdhury, H. Li, \n",
      "and H . Hu. All authors reviewed the results and approved the final version of the manuscript . \n",
      "REFERENCES  \n",
      "1.  Tefft, B. C. The Prevalence of Motor Vehicle Crashes Involving Road Debris, United States, 2011 -\n",
      "2014. AAA Foundation for Traffic Safety , No. 24, 2016, pp. 1 –10. \n",
      "2.  Bertozzi, M., A. Broggi, and A. Fascioli. Vision -Based Intelligent Vehicles: State of the Art and \n",
      "Perspectives. Robotics and Autonomous Systems , Vol. 32, No. 1, 2000, pp. 1 –16. \n",
      "https://doi.org/10.1016/S0921 -8890(99)00125 -6. \n",
      "3.  Dagan, E., O. Mano, G. P. Stein, and A. Shashua. Forward Collision War ning with a Single Camera. Islam,  Chowdhury,  Li, Hu   20 \n",
      " \n",
      " \n",
      " IEEE Intelligent Vehicles Symposium, 2004 , 2004, pp. 37 –42. \n",
      "https://doi.org/10.1109/IVS.2004.1336352.  \n",
      "4.  Tatarek, T., J. Kronenberger, and U. Handmann. Functionality ,  Advantages and Limits of the Tesla \n",
      "Autopilot.  \n",
      "5.  Krizhevsky , A., I. Sutskever, and G. E. Hinton. ImageNet Classification with Deep Convolutional \n",
      "Neural Networks. Advances In Neural Information Processing Systems , 2012, pp. 1 –9. \n",
      "https://doi.org/http://dx.doi.org/10.1016/j.protcy.2014.09.007.  \n",
      "6.  Yang, Z., Y. Zhang,  J. Yu, J. Cai, and J. Luo. End -to-End Multi -Modal Multi -Task Vehicle Control \n",
      "for Self -Driving Cars with Visual Perception. 2018.  \n",
      "7.  Bojarski, M., D. Del Testa, D. Dworakowski, B. Firner , B. Flepp, P. Goyal, L. D. Jackel, M. \n",
      "Monfort, U. Muller, J. Zhang, X. Zhang, J. Zhao, and K. Zieba. End to End Learning for Self -\n",
      "Driving Cars. 2016, pp. 1 –9. \n",
      "8.  Bhavsar, P., P. Das, M. Paugh, K. Dey, and M. Chowdhury. Risk Analysis of Autonomous Vehicles \n",
      "in Mixed Traffic Streams. Transportation Research Record: Journal o f the Transportation Research \n",
      "Board , Vol. 2625, No. 1, 2017, pp. 51 –61. https://doi.org/10.3141/2625 -06. \n",
      "9.  Yao, J., S. Fidler, and R. Urtasun. Describing the Scene as a Whole: Joint Object Detection, Scene \n",
      "Classification and Semantic Segmentation. Procee dings of the IEEE Computer Society Conference \n",
      "on Computer  Vision and Pattern Recognition , 2012, pp. 702 –709. \n",
      "https://doi.org/10.1109/CVPR.2012.6247739.  \n",
      "10.  Pomerleau, D. a. Alvinn : An Autonomous Land Vehicle in a Neural Network. Advances in Neural \n",
      "Inform ation Processing Systems 1 , 1989, pp. 305 –313. \n",
      "11.  Zhang, M., Y. Zhang, L. Zhang, C. Liu, and S. Khurshid. DeepRoad: GAN -Based Metamorphic \n",
      "Testing and Input Validation Framework for Autonomous Driving Systems. 2018, pp. 132 –142. \n",
      "https://doi.org/10.1145/32 38147.3238187.  \n",
      "12.  Beaufays, F., H. Sak, and A. Senior. Long Short -Term Memory Recurrent Neural Network \n",
      "Architectures for Large Scale Acoustic Modeling Has. Interspeech , No. September,  2014, pp. 338 –\n",
      "342. https://doi.org/arXiv:1402.1128.  \n",
      "13.  Udacity Self Driving Car. https://github.com/udacity/self -driving -car. \n",
      "14.  Carlini, N., and D. Wagner. Towards Evaluating the Robustness of Neural Networks. Proceedings \n",
      "- IEEE Symposium on Security and Privacy , 2017, pp. 39 –57. https://doi.org/10.1109/SP. 2017.49.  \n",
      "15.  Papernot , N., P. McDaniel, X. Wu, S. Jha, and A. Swami. Distillation as a Defense to Adversarial \n",
      "Perturbations Against Deep Neural Networks. Proceedings - 2016 IEEE Symposium on Security and \n",
      "Privacy, SP 2016 , 2016, pp. 582 –597. https://doi.or g/10.1109/SP.2016.41.  \n",
      "16.  Athalye, A., N. Carlini, and D. Wagner. Obfuscated Gradients Give a False Sense of Security: \n",
      "Circumventing Defenses to Adversarial Examples. 2018.  \n",
      "17.  Papernot , N., P. Mcdaniel, S. Jha, M. Fredrikson, Z. B. Celik, and A. Swami. The Limitations of \n",
      "Deep Learning in Adversarial Settings. Proceedings - 2016 IEEE European Symposium on Security \n",
      "and Privacy, EURO S and P 2016 , 2016, pp. 372 –387. https://doi.org/10.1109/EuroSP.2016.36.  \n",
      "18.  Eykholt, K., I. Evtimov, E. Fernandes, B. Li, A . Rahmati, C. Xiao, A. Prakash, T. Kohno, and D. \n",
      "Song. Robust Physical -World Attacks on Deep Learning Models. 2017. \n",
      "https://doi.org/10.1109/CVPR.2018.00175.  \n",
      "19.  Geiger, A., P. Lenz, C. Stiller, and R. Urtasun. Vision Meets Robotics: The KITTI Dataset. \n",
      "International Journal of Robotics Research , Vol. 32, No. 11, 2013, pp. 1231 –1237. \n",
      "https://doi.org/10.1177/0278364913491297.  \n",
      "20.  Cordts, M., M. Omran, S. Ramos, T. Rehfeld, M. Enzweiler, R. Benenson, U. Franke, S. Roth, and \n",
      "B. Schiele. The Cityscapes Dataset for Semantic Urban Scene Understanding. 2016. \n",
      "https://doi.org/10.1109/CVPR.2016.350.  \n",
      "21.  Pinggera, P., S. Ramos, S. Gehrig, U. Franke, C. Rother, and R. Mester. Lost and Found: Detecting \n",
      "Small Road Hazards for Self -Driving Vehicles. IEEE International Con ference on Intelligent \n",
      "Robots and Systems , Vol. 2016 -Novem, 2016, pp. 1099 –1106. \n",
      "https://doi.org/10.1109/IROS.2016.7759186.  Islam,  Chowdhury,  Li, Hu   21 \n",
      " \n",
      " \n",
      " 22.  Guo, Y., Y. Liu, T. Georgiou, and M. S. Lew. A Review of Semantic Segmentation Using Deep \n",
      "Neural Networks. International Journa l of Multimedia Information Retrieval , Vol. 7, No. 2, 2018, \n",
      "pp. 87 –93. https://doi.org/10.1007/s13735 -017-0141 -z. \n",
      "23.  Caesar, H., J. Uijlings, and V. Ferrari. Region -Based Semantic Segmentation with End -to-End \n",
      "Training. Lecture Notes in Computer Science ( including subseries Lecture Notes in Artificial \n",
      "Intelligence and Lecture Notes in Bioinformatics) , Vol. 9905 LNCS, 2016, pp. 381 –397. \n",
      "https://doi.org/10.1007/978 -3-319-46448 -0_23.  \n",
      "24.  Girshick, R., J. Donahue, T. Darrell, and J. Malik. Rich Feature Hierar chies for Accurate Object \n",
      "Detection and Semantic Segmentation. Proceedings of the IEEE Computer Society Conference on \n",
      "Computer Vision and Pattern Recognition , 2014, pp. 580 –587. \n",
      "https://doi.org/10.1109/CVPR.2014.81.  \n",
      "25.  Long, J., E. Shelhamer, and T. Darr ell. Fully Convolutional Networks for Semantic Segmentation. \n",
      "Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern \n",
      "Recognition , Vol. 07 -12-June, 2015, pp. 3431 –3440. https://doi.org/10.1109/CVPR.2015.7298965.  \n",
      "26.  Eigen, D., an d R. Fergus. Predicting Depth ,  Surface Normals and Semantic Labels with a Common \n",
      "Multi -Scale Convolutional Architecture. 2015. https://doi.org/10.1109/ICCV.2015.304.  \n",
      "27.  Liu, Y., Y. Guo, and M. S. Lew. On the Exploration of Convolutional Fusion Networks for Visual \n",
      "Recognition. Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial \n",
      "Intelligence and Lecture Notes in Bioinformatics) , Vol. 10132 LNCS, No. 1, 2017, pp. 277 –289. \n",
      "https://doi.org/10.1007/978 -3-319-51811 -4_23.  \n",
      "28.  Dai, J., K. He, and J. Sun. BoxSup: Exploiting Bounding Boxes to Supervise Convolutional \n",
      "Networks for Semantic Segmentation. Proceedings of the IEEE International Conference on \n",
      "Computer Vision , Vol. 2015 Inter, 2015, pp. 1635 –1643. https://doi.org/10.1109/ICCV .2015.191.  \n",
      "29.  Papandreou, G., L. -C. Chen, K. P. Murphy, and A. L. Yuille. Weakly -and Semi -Supervised \n",
      "Learning of a Deep Convolutional Network for Semantic Image Segmentation. 2015 IEEE \n",
      "International Conference on Computer Vision (ICCV) , 2015, pp. 1742 –1750. \n",
      "https://doi.org/10.1109/ICCV.2015.203.  \n",
      "30.  Khoreva, A., R. Benenson, J. Hosang, M. Hein, and B. Schiele. Simple Does It: Weakly Supervised \n",
      "Instance and Semantic Segmentation. Proceedings - 30th IEEE Conference on Computer Vision and \n",
      "Pattern Recognitio n, CVPR 2017 , Vol. 2017 -Janua, 2017, pp. 1665 –1674. \n",
      "https://doi.org/10.1109/CVPR.2017.181.  \n",
      "31.  Eraqi , H. M., M. N. Moustafa, and J. Honer. End -to-End Deep Learning for Steering Autonomous \n",
      "Vehicles Considering Temporal Dependencies. No. Nips, 2017, pp. 1 –8. \n",
      "32.  Teichmann, M., M. Weber, M. Zoellner, R. Cipolla, and R. Urtasun. MultiNet: Real -Time Joint \n",
      "Semantic Reasoning for Autonomous Driving. 2016. https://doi.org/10.1109/CVPR.2012.6248074.  \n",
      "33.  Siam, M., S. Elkerdawy, M. Jagersand, and S. Yogamani. Deep Semantic Segmentation for \n",
      "Automated Driving: Taxonomy, Roadmap and Challenges. IEEE Conference on Intelligent \n",
      "Transportation Systems, Proceedings, ITSC , Vol. 2018 -March, 2018, pp. 1 –8. \n",
      "https://doi.org/10.1109/ITSC.2017.8317714.  \n",
      "34.  Simonyan, K., and A. Zisserman. Very Deep Convolutional Networks for Large -Scale Image \n",
      "Recognition. CoRR , Vol. abs/1409.1, 2014.  \n",
      "35.  Suarez -Alvarez, M. M., D. T. Pham , M. Y. Prostov, and Y. I. Prostov. Statistical Approach to \n",
      "Normalization of Feature Vect ors and Clustering of Mixed Datasets. Proceedings of the Royal \n",
      "Society A: Mathematical, Physical and Engineering Sciences , Vol. 468, No. 2145, 2012, pp. 2630 –\n",
      "2651. https://doi.org/10.1098/rspa.2011.0704.  \n",
      "36.  About Feature Scaling and Normalization. \n",
      "https: //sebastianraschka.com/Articles/2014_about_feature_scaling.html. Accessed Nov. 16, 2018.  \n",
      "37.  Cyberbotics Ltd. Webots: Robot Simulator. http://www.cyberbotics.com. Accessed Nov. 15, 2018.  \n",
      "38.  AutonomouStuff. Delphi Electronically Scanning Radar. 1 –2. \n",
      "https://autonomoustuff.com/product/delphi -esr-2-5-24v/. Accessed Nov. 14, 2018.  \n",
      "39.  Webots Documentation: Radar Sensors. https://cyberbotics.com/doc/guide/radar -sensors#delphi -Islam,  Chowdhury,  Li, Hu   22 \n",
      " \n",
      " \n",
      " esr. Accessed Nov. 14, 2018.  \n",
      "40.  Zha, S., F. Luisier, W. Andrews, N. Srivastava, and R. Salakhutdinov. Exploiting Image -Trained \n",
      "CNN Architectures for Unconstrained Video Classification. 2015. https://doi.org/10.5244/C.29.60.  \n",
      "41.  Russell, B. C., A. Torralba, K. P. Murphy, and W. T. Freeman. LabelMe: A Database and Web -\n",
      "Based  Tool for Image Annotation. International Journal of Computer Vision , Vol. 77, No. 1 –3, \n",
      "2008, pp. 157 –173. https://doi.org/10.1007/s11263 -007-0090 -8. \n",
      "42.  Tian, Y., K. Pei, S. Jana, and B. Ray. DeepTest: Automated Testing of Deep -Neural -Network -\n",
      "Driven Auto nomous Cars. 2017. https://doi.org/10.1145/3180155.3180220.  \n",
      "43.  Konur, O. ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION. ICLR , Vol. 5, No. 2, 2015, \n",
      "pp. 365 –380. https://doi.org/10.1063/1.4902458.  \n",
      "44.  Baldi, P., and P. Sadowski. Understanding Dropout. Nips, No. 1, 2013, pp. 1 –9. \n",
      "https://doi.org/10.1007/978 -3-642-33269 -2_28.  \n",
      "45.  Keras. https://keras.io/callbacks/.  \n",
      "46.  Mitchell, W. C., A. Staniforth, and I. Scott. Analysis of Ackermann Steering Geometry. SAE \n",
      "Technical Papers U6 , No. 724, 2006. https://doi.org /10.4271/2006 -01-3638.  \n",
      "47.  Houenou, A., P. Bonnifait, V. Cherfaoui, and W. Yao. Vehicle Trajectory Prediction Based on \n",
      "Motion Model and Maneuver Recognition. IEEE International Conference on Intelligent Robots \n",
      "and Systems , 2013, pp. 4363 –4369. https://doi .org/10.1109/IROS.2013.6696982.  \n",
      " JOURNAL OF L ATEX CLASS FILES, VOL. 1\n",
      "Intelligent Perception System for Vehicle-Road\n",
      "Cooperation\n",
      "Songbin Chen\n",
      "Abstract —With the development of autonomous driving, the\n",
      "improvement of autonomous driving technology for individual\n",
      "vehicles has reached the bottleneck. The advancement of vehicle-\n",
      "road cooperation autonomous driving technology can expand the\n",
      "vehicle’s perception range, supplement the perception blind area\n",
      "and improve the perception accuracy, to promote the develop-\n",
      "ment of autonomous driving technology and achieve vehicle-road\n",
      "integration. This project mainly uses lidar to develop data fusion\n",
      "schemes to realize the sharing and combination of vehicle and\n",
      "road equipment data and achieve the detection and tracking of\n",
      "dynamic targets. At the same time, some test scenarios for the\n",
      "vehicle-road cooperative system were designed and used to test\n",
      "our vehicle-road cooperative awareness system, which proved the\n",
      "advantages of vehicle-road cooperative autonomous driving over\n",
      "single-vehicle autonomous driving.\n",
      "Index Terms —Autonomous Driving, Vehicle-Road Coopera-\n",
      "tion, Perception Systems.\n",
      "I. I NTRODUCTION\n",
      "A. Background\n",
      "Autonomous driving refers to a technology that replaces\n",
      "human driving operations by enabling cars to be equipped with\n",
      "advanced onboard sensors, controllers, actuators, and other\n",
      "devices to have complex environment perception, intelligent\n",
      "decision-making, and precise control. The use of automatic\n",
      "driving technology can not only avoid trafﬁc accidents caused\n",
      "by driver error but also make up for the shortcomings of\n",
      "human drivers in the perception of environmental situations,\n",
      "decision-making driving behavior, and other aspects. It is an\n",
      "industry trend to use autonomous driving to solve problems\n",
      "such as trafﬁc congestion and trafﬁc accidents, which can\n",
      "greatly improve the convenience of travel and improve the\n",
      "efﬁciency of cities.\n",
      "At present, the existing research on autonomous driving\n",
      "mainly focuses on the intelligence of a single-vehicle. Au-\n",
      "tonomous vehicles use their sensors, such as lidar and cam-\n",
      "eras, to sense the surrounding environment and make control\n",
      "decisions through their algorithms. Vehicle-road cooperation is\n",
      "a new research direction for autonomous driving. It can jointly\n",
      "perceive the road trafﬁc environment in real-time through the\n",
      "sensors of the vehicle end and the road end, and exchange and\n",
      "share the perceived information to enhance the perception and\n",
      "prediction ability of autonomous vehicles.\n",
      "In recent years, the perception ability and computing ability\n",
      "of autonomous driving of a single-vehicle have been developed\n",
      "very advanced, almost reaching the development bottleneck,\n",
      "but its limitations are still obvious, so the development of\n",
      "single-vehicle intelligence can not solve the problem of au-\n",
      "tonomous driving once and for all. The vehicle-road coopera-\n",
      "tion autonomous driving provides multi-ﬁeld and multi-angleperception, which can not only expand the range of perception\n",
      "of the vehicle but also overcome some defects left by a single-\n",
      "vehicle. However, in the ﬁeld of autonomous driving, there is\n",
      "still a big gap in the research on vehicle-road cooperation.\n",
      "B. Motivation\n",
      "The blind ﬁeld of the visual ﬁeld of a single-vehicle affects\n",
      "the safety of autonomous driving. Since the autonomous\n",
      "driving of a single-vehicle only senses from the perspective\n",
      "of the vehicle, it is likely to face the situation that the target\n",
      "object is blocked by other vehicles or buildings, resulting in\n",
      "the lack of perception of the target object, which is easy to\n",
      "cause trafﬁc accidents. The vehicle-road cooperation can solve\n",
      "the problem of the blind area of vehicle vision well. By placing\n",
      "sensors in different places on the road, it can obtain different\n",
      "perception perspectives. By sharing data with vehicles, it can\n",
      "expand the perception range and reduce the blind area of\n",
      "vision, which can greatly reduce trafﬁc accidents caused by\n",
      "insufﬁcient perception and improve the safety of autonomous\n",
      "driving.\n",
      "The potential sensor failure of autonomous driving affects\n",
      "the reliability of autonomous driving. Every sensor on the\n",
      "vehicle plays an important role. Once a sensor fails, it can\n",
      "lead to perceptual failure in a certain direction or even the\n",
      "whole system crash. Vehicle-road cooperation can solve the\n",
      "problem of vehicle sensor failure well. It can carry out multiple\n",
      "perceptions of an object through the multi-angle perception\n",
      "of road conditions, providing redundancy for the perception\n",
      "system. Even if the vehicle sensor fails, it can also sense the\n",
      "target object through road end equipment. This can greatly re-\n",
      "duce perceptual failures and improve the reliability of autopilot\n",
      "systems.\n",
      "C. Objective\n",
      "We want to design and implement a vehicle-road coopera-\n",
      "tive system in terms of perception. At the same time, a series\n",
      "of tests are designed to test our perception system.\n",
      "To realize information sharing, we need to realize the fusion\n",
      "of vehicle and road perception information to some extent. The\n",
      "data obtained by different sensors at the vehicle end and the\n",
      "road ends are distributed in different perspectives and features,\n",
      "which leads to that the data cannot be directly used by one end\n",
      "for perception or decision-making. This requires a mechanism\n",
      "to unify perception data into one domain.\n",
      "To verify the superiority of our vehicle-road cooperative\n",
      "system, we will design a series of experimental scenes andarXiv:2208.14052v1  [cs.RO]  30 Aug 2022JOURNAL OF L ATEX CLASS FILES, VOL. 2\n",
      "evaluation indexes for the system. Existing autonomous driv-\n",
      "ing scenarios cannot support the comprehensiveness and ef-\n",
      "fectiveness of vehicle-road cooperation testing, and cannot\n",
      "correctly reﬂect the advantages and disadvantages of the\n",
      "vehicle-road cooperation systems. This requires a new series\n",
      "of test scenarios and evaluation indicators for vehicle-road\n",
      "cooperation.\n",
      "II. R ELATED WORK\n",
      "Intelligent transportation systems (ITS) are systems that\n",
      "use cooperation technologies and systems engineering con-\n",
      "cepts to develop and improve various transportation systems.\n",
      "To build the network of ITS, four architectures have been\n",
      "proposed: vehicle-to-vehicle (V2V), vehicle-to-infrastructure\n",
      "(V2I), vehicle-to-pedestrian (V2P), and vehicle-to-Anything\n",
      "(V2X) [1]. V2V communication is implemented between\n",
      "moving vehicles, which act as source, destination, and router\n",
      "during communication. Intermediate nodes (vehicles) transfer\n",
      "messages between the source and destination nodes. V2I\n",
      "communication allows vehicles to communicate with roadside\n",
      "infrastructure [2], [3]. In this case, the vehicle acts as both\n",
      "source and destination. V2P allows direct, instant, and ﬂexible\n",
      "communication between mobile vehicles and roadside passen-\n",
      "gers. Through portable wireless devices, passengers can easily\n",
      "join V ANET as roadside nodes to express their travel needs\n",
      "[4], [5], [6]. V2X provides vehicle-to-network and vehicle-to-\n",
      "pedestrian communication services [7].\n",
      "Wu X et al. proposed a new multimodal framework, SFD, to\n",
      "solve the problem of multimodal fusion between point clouds\n",
      "[8] and images [9]. Wu H et al. designed the ﬁrst tracklet\n",
      "proposal network PC-TCNN, which signiﬁcantly improved\n",
      "multi-object tracking performance by introducing tracklet pro-\n",
      "posal design [10]. [11], [12] proposed the simulation platform\n",
      "for swarm robotics. Xiao Z et al. signiﬁcantly improved the\n",
      "integrity of target perception through the sharing of sensor\n",
      "information and the utilization of map data [13]. Wang Z et al.\n",
      "show different sensor fusion strategies and discuss the method\n",
      "of establishing motion model and data association in multi-\n",
      "target tracking [14], [15], [16]. Vishnukumar H J et al. think\n",
      "that artiﬁcial intelligence could be used to generate simulated\n",
      "scenes and verify results in autonomous driving [17].\n",
      "III. M ETHODOLOGY\n",
      "A. System Flow\n",
      "1) Sensor Setting: To perceive the environment, we need\n",
      "to set up sensors at the vehicle end and the road end to obtain\n",
      "environmental information. At the beginning of the whole\n",
      "process, the selection and setting of sensors have a decisive\n",
      "impact on the subsequent treatment and effect.\n",
      "To determine the vehicle position, the most direct way is to\n",
      "obtain the longitude and latitude coordinates provided by the\n",
      "satellite positioning system, but in reality, the signal may be\n",
      "weak or drift due to environmental interference. Therefore,\n",
      "the vehicle position can be deduced by using a satellite\n",
      "positioning sensor, inertial measurement unit, and other data\n",
      "comprehensively to improve the accuracy and robustness of\n",
      "vehicle position implementation.To observe the external environment around the vehicle,\n",
      "various lidar sensors, vision sensors, and V2X communication\n",
      "equipment are arranged in the rear of the vehicle to observe\n",
      "meteorological conditions, and road conditions and identify\n",
      "trafﬁc signs, as well as obstacles and trafﬁc participants\n",
      "identiﬁcation, tracking and prediction.\n",
      "Considering the vehicle-road cooperation system, in the\n",
      "vehicle end, usually adopt lidar as its main environmental\n",
      "sensors, install it on or around the roof, because laser radar\n",
      "usually has a 360 - degree Angle and have depth information,\n",
      "within a few hundred meters can simultaneously detect the\n",
      "contour of the object, at the same time with the reﬂectivity\n",
      "of the material of information can also be used to identify\n",
      "objects. However, the disadvantage of lidar is that it has\n",
      "the problem of insufﬁcient resolution for distant objects and\n",
      "insufﬁcient precision for close objects. A camera is also used\n",
      "as a sensor on the car end, which is installed in the front of the\n",
      "vehicle because the camera can obtain visible light information\n",
      "reﬂected by objects in a certain direction. The disadvantage is\n",
      "that ordinary cameras lack depth information and are easily\n",
      "confused by colors.\n",
      "Lidar or camera sensors are also used at the road end, but\n",
      "they are also different in many ways. Road end sensors are\n",
      "installed at a higher height than vehicle end sensors for better\n",
      "visibility and are usually installed on poles at intersections\n",
      "and roadsides. Because of its particularity, the road end sensor\n",
      "also needs a longer sensing range and precision than the car\n",
      "end sensor. Moreover, the device at the end of the road will\n",
      "not move after installation, so the data characteristics obtained\n",
      "by the sensor are quite different from those of the vehicle in\n",
      "motion.\n",
      "2) Object Detection: After obtaining the environmental\n",
      "information obtained by the sensor, to remove the unimpor-\n",
      "tant part of the environmental information and extract useful\n",
      "information, we need to detect objects in the data, such as\n",
      "pedestrians, vehicles, lane lines, and so on.\n",
      "For pedestrian and vehicle recognition, the target detection\n",
      "model is used to detect point cloud data obtained by lidar.\n",
      "For the recognition of point cloud, one approach regards point\n",
      "cloud as a sequence according to the scanning order and makes\n",
      "use of the continuity of time when the object is scanned, which\n",
      "can be recognized by R-CNN. Another approach is to mark\n",
      "point clouds as voxels in space, which can be identiﬁed by\n",
      "V oxel-CNN by taking advantage of the spatial proximity of\n",
      "objects. In addition, the image data obtained by the camera\n",
      "can also be detected by the detection model. Ultimately we\n",
      "want to get boundary information between pedestrians and\n",
      "vehicles.\n",
      "For man-made information such as lane lines, road signs,\n",
      "and trafﬁc lights, processing image data can be easier to detect\n",
      "than processing point cloud data. The mathematical character-\n",
      "istics of lane lines are obvious, so the track of lane lines can be\n",
      "extracted by the Hough transform, or the distribution of lane\n",
      "lines in space can be directly extracted by the neural network\n",
      "model. For road signs and trafﬁc lights, convolutional neural\n",
      "networks can be used for speciﬁc recognition [18], [19].\n",
      "In addition, relying on the advantage of the position of the\n",
      "sensor at the road end not changing, static elimination of dataJOURNAL OF L ATEX CLASS FILES, VOL. 3\n",
      "Fig. 1: The main workﬂow of the perception system.\n",
      "can also be tried, which can remove the motionless objects\n",
      "and leave the information of the moving objects that we care\n",
      "about, which can better extract the information of the moving\n",
      "objects.\n",
      "3) Object Tracking and Prediction: After object detection,\n",
      "to distinguish the threat degree of vehicles, achieve better\n",
      "avoidance and improve driving efﬁciency, we need to restore\n",
      "the target’s actions and deduce the target’s motion state at the\n",
      "next moment. Therefore, we trace the detected objects, trace\n",
      "the information of each object at each point in time, and get\n",
      "the trajectory of the object.\n",
      "For objects that can move, such as pedestrians and vehicles,\n",
      "after they are detected from the original data, they can be\n",
      "simply processed by a ﬁltering algorithm. The object infor-\n",
      "mation is input into the algorithm in chronological order, and\n",
      "the algorithm will judge whether a new object belongs to the\n",
      "same as the previous one according to the position and speed\n",
      "of each object at the previous moment, and can assign the\n",
      "same ID to the same object [20], [21], [22]. The same ID\n",
      "indicates that these objects are the same object at different\n",
      "moments. By placing the positions of objects with the same\n",
      "ID in chronological order, the trajectory of the object can be\n",
      "obtained.\n",
      "Then we need to predict the future motion according to the\n",
      "trajectory, mainly including the direction and speed of motion.\n",
      "This can also often be done by ﬁltering algorithms. New\n",
      "estimates can be generated from historical states combined\n",
      "with current states.\n",
      "B. Data Fusion\n",
      "After designing the perception process, we need to design\n",
      "the scheme of vehicle-road collaboration, among which the\n",
      "most important way of collaboration is the sharing and fusion\n",
      "of vehicle-road perception data. We design two data fusion\n",
      "schemes.\n",
      "1) Pixel-level Fusion: Pixel-level fusion is to directly share\n",
      "and combine the original data of sensors at the vehicle end and\n",
      "the road end and map each data point to the same space.\n",
      "For point cloud data obtained by lidar, each data point has\n",
      "3D coordinate information. To carry out a pixel-level fusion\n",
      "of point cloud data of road end and vehicle end radar, what\n",
      "we need to do is to unify the coordinate system of logarithm\n",
      "points.\n",
      "The data fused at pixel level needs special processing meth-\n",
      "ods. Different from the lidar point cloud of a single vehicle,\n",
      "the fused point cloud has two sources, and the usual objectdetection methods cannot make good use of the information\n",
      "in it [8]. Therefore, to exploit the advantages of pixel-level\n",
      "fusion, a new object detection model needs to be proposed.\n",
      "Pixel-level fusion has the advantage of high precision.\n",
      "However, the disadvantage is that the amount of data to be\n",
      "processed is large and it is difﬁcult to fuse the data of different\n",
      "types of sensors.\n",
      "2) Feature-level Fusion: Feature-level fusion is to share\n",
      "and combine the extracted features by processing sensor data\n",
      "separately.\n",
      "For the 3D boundary of pedestrians and vehicles identiﬁed,\n",
      "each boundary consists of eight coordinate points. To carry out\n",
      "a feature-level fusion of the 3D boundary of pedestrian and\n",
      "vehicle recognized by road end and vehicle end, what we need\n",
      "to do is to unify the coordinate system of the boundary. Then,\n",
      "the boundary of the same kind of object with a high overlap\n",
      "degree will be considered as the same object and uniﬁed into\n",
      "one.\n",
      "The feature-level fusion data can be easily utilized in the\n",
      "existing autonomous driving framework. After the fusion of\n",
      "the boundary obtained from 3D object detection of point cloud\n",
      "data, the quantity and quality of the perceived boundary can\n",
      "be improved, and the subsequent processing method will not\n",
      "change much. Therefore, feature-level fusion should be easily\n",
      "used by autonomous driving systems.\n",
      "The advantage of feature-level fusion is that it is convenient\n",
      "to implement, and the same feature extracted from different\n",
      "sensors can also be fused. However, the disadvantage is that\n",
      "some information will be lost after feature extraction.\n",
      "C. Implementation\n",
      "To verify the feasibility of our vehicle-road cooperation in-\n",
      "telligent perception system, we made a simple implementation\n",
      "for each part of the design.\n",
      "CARLA is an open-source simulator for autonomous driving\n",
      "research that supports the development, training, and valida-\n",
      "tion of autonomous driving systems[23]. Considering cost and\n",
      "security, we choose the CARLA simulation platform to build\n",
      "our system.\n",
      "1) Sensor Setting:\n",
      "1) We chose lidar as the primary sensor on the vehicle\n",
      "to sense pedestrians and vehicles, which was set to a\n",
      "sensing range of 20 meters and mounted on top of the\n",
      "car 2 meters above the ground.\n",
      "2) Lidar is also used at the end of the road, which is\n",
      "installed 3 meters above the intersection and has a wider\n",
      "sensing range of up to 40 meters.JOURNAL OF L ATEX CLASS FILES, VOL. 4\n",
      "3) Two GNSS modules are distributed in the front and rear\n",
      "of the vehicle so that the vehicle rotation Angle can be\n",
      "calculated while obtaining the vehicle position.\n",
      "(x;y) = (x1=2;y1=2) + (x2=2;y2=2) (1)\n",
      "yaw = arctan((y2\u0000y1)=(x2\u0000x1)) (2)\n",
      "4) Additional cameras are mounted on the roof, looking\n",
      "forward, to extract lane line information.\n",
      "(a) Vehicle and pedestrian detection results of the point cloud using point-\n",
      "RCNN. White dots are point clouds, and green, blue, and yellow boxes\n",
      "respectively represent vehicles, bicycles, and pedestrians.\n",
      "(b) Lane line detection results of the image using Gen-Lannet. The three\n",
      "sub-images are the original perspective, the aerial view, and the coordinate\n",
      "map.\n",
      "Fig. 2: Object detection approaches.\n",
      "2) Object Detection: In the detection of pedestrians and\n",
      "vehicles, we use point-RCNN[24] to process Point cloud\n",
      "data and obtain boundary information of each vehicle and\n",
      "pedestrian.\n",
      "In the detection of lane lines, Gen-Lanenet[25] was used\n",
      "to process the image data to obtain the spatial distribution of\n",
      "each lane.\n",
      "3) Object Tracking and Prediction: In the tracking of\n",
      "pedestrians and vehicles, we use AB3DMOT[26] to perform\n",
      "state estimation and data association for boundary information\n",
      "and obtain the object ID to which each boundary information\n",
      "belongs.\n",
      "Next, we use a simple prediction method that uses exponen-\n",
      "tial smoothing, in which the predicted motion is calculated and\n",
      "updated from the past trajectory.\n",
      "Sn+1=t\u0003Sn+ (1\u0000t)\u0003Sn\u00001 (3)\n",
      "Fig. 3: Uniﬁed scheme of coordinate system.\n",
      "4) Data Fusion: As for the data fusion method, we consider\n",
      "using a feature-level fusion scheme to share and combine the\n",
      "point cloud information sensed by lidar at the vehicle end and\n",
      "the road end.\n",
      "To unify the coordinate system of the point cloud, the ﬁrst\n",
      "thing to do is to establish a uniﬁed virtual coordinate system\n",
      "[27], [16]. We choose the coordinate system of CARLA world\n",
      "as the virtual coordinate system. Then we change the point\n",
      "cloud coordinate system to the virtual coordinate system.\n",
      "For the road-end lidar, it is assumed that we can directly\n",
      "know its position Lroad relative to the virtual coordinate\n",
      "system when installing it, then for each data proad, it’s ﬁnal\n",
      "coordinateProad is\n",
      "Proad=proad+Lroad (4)\n",
      "For vehicle-end lidar, we ﬁrst need to align it to the\n",
      "vehicle coordinate system according to the installation position\n",
      "Dvehicle of lidar relative to the vehicle. Then according to the\n",
      "real-time position Lvehicle of the vehicle relative to the virtual\n",
      "coordinate system and the yaw angle \u0012, the vehicle coordinate\n",
      "system is transformed into a uniﬁed virtual coordinate system.\n",
      "So for each data pvehicle , its ﬁnal coordinate Pvehicle is\n",
      "Pvehicle =R(pvehicle +Dvehicle ) +Lvehicle (5)\n",
      "where\n",
      "R=2\n",
      "4cos\u0012 \u0000sin\u0012 0\n",
      "sin\u0012 cos\u0012 0\n",
      "0 0 13\n",
      "5\n",
      "After the uniﬁcation of the lidar coordinate system at the\n",
      "opposite end of the vehicle and the road, the point cloud data\n",
      "of the two can be combined to participate in the subsequent\n",
      "object detection process as a whole.\n",
      "IV. E XPERIMENTAL SETUP\n",
      "We have designed three kinds of tests to verify our vehicle-\n",
      "road cooperative intelligent perception system, which will be\n",
      "tested for the perceptual ability of the system.\n",
      "A. Extended Range\n",
      "The autonomous driving of a single-vehicle can only per-\n",
      "ceive objects within a certain range due to the limited sens-\n",
      "ing range of sensors. However, in autonomous driving withJOURNAL OF L ATEX CLASS FILES, VOL. 5\n",
      "(a) Curve road test scenario. The blue circle is\n",
      "our vehicle, the green circle is the installation\n",
      "location of the road end equipment, and the red\n",
      "circle is the target vehicle.\n",
      "(b) Blind area test scenario. The blue circle is\n",
      "our vehicle, the green circle is where the road\n",
      "end lidar is installed, and the red circle is a\n",
      "pedestrian.\n",
      "(c) Blind area test scenario. The blue circle is\n",
      "our vehicle, the green circle is where the road\n",
      "end lidar is installed, and the red circle is a\n",
      "pedestrian.\n",
      "Fig. 4: Three test scenarioes\n",
      "vehicle-road cooperation, the vehicle can obtain the informa-\n",
      "tion perceived by the lidar at the far end of the road, so that\n",
      "the vehicle’s perception range can break through the limitation\n",
      "of the sensor and reach farther.\n",
      "In this test, we designed a vehicle driving on a curve road\n",
      "as shown in4(a). Road end lidar is installed on the side of the\n",
      "curve to sense the trafﬁc ﬂow at both ends of the road. Our\n",
      "vehicles entered from one end of the curve, but the lidar of\n",
      "the vehicle could not directly perceive the vehicles at the other\n",
      "end of the curve due to the limitation of the sensing range.\n",
      "We plan to use the vehicle-road cooperation perception\n",
      "system, in which the end of the road can share the perception\n",
      "information with our vehicles after perceiving the vehicles at\n",
      "the other end so that our vehicles can perceive the coming\n",
      "vehicles in the curves in advance.\n",
      "B. Supplemental Blind area\n",
      "Since the autonomous driving of a single-vehicle can only\n",
      "perceive the environment from one perspective, there will be a\n",
      "blind area due to the occlusion of other objects, which is easy\n",
      "to cause trafﬁc accidents. However, for autonomous driving\n",
      "with vehicle-road cooperation, road-end devices and vehicles\n",
      "can perceive objects from different perspectives, thus reducing\n",
      "blind areas and increasing the safety of autonomous driving.\n",
      "We chose a typical blind area scene for this test. In this\n",
      "scenario shown4(b), when our vehicle is passing the intersec-\n",
      "tion, a pedestrian is crossing the zebra crossing, but due to the\n",
      "obstruction of the sidecar body, the vehicle cannot sense the\n",
      "pedestrian. At the intersection, we set up the road end lidar,\n",
      "to perceive pedestrians and share the perception information\n",
      "with our vehicles.\n",
      "For the single-vehicle autonomous driving system, this\n",
      "scenario is dangerous for trafﬁc accidents, because the sidecar\n",
      "body obstruction is always unavoidable until it is about to\n",
      "collide with the pedestrian. However, for the vehicle-road\n",
      "cooperative system, the blind area problem is greatly reduced.\n",
      "Pedestrians crossing the road should be perceived and identi-\n",
      "ﬁed by the system to avoid collisions.C. Improved Accuracy\n",
      "the autonomous driving of a single-vehicle can usually\n",
      "only perceive the position of the target from one side, which\n",
      "can be inaccurate. However, for autonomous driving with\n",
      "vehicle-road cooperation, objects are viewed from multiple\n",
      "sides, which allows for more information and a more accurate\n",
      "estimate of position and pose.\n",
      "In this test, we set the target vehicle at a position that both\n",
      "our vehicle lidar and the road-end lidar can perceive, as shown\n",
      "in 4(c). Both our vehicle and the road-end can obtain the\n",
      "estimation of the target vehicle pose respectively. Through the\n",
      "vehicle-road cooperative system, the information perceived by\n",
      "both vehicles can be shared, which we hope can improve the\n",
      "accuracy of target perception.\n",
      "V. R ESULTS\n",
      "A. Extended Range\n",
      "(a) The perception result. The\n",
      "blue point cloud is perceived by\n",
      "the road end, the green point\n",
      "cloud is perceived by the vehi-\n",
      "cle end, and the blue box is the\n",
      "boundary detected by the road\n",
      "end.\n",
      "30m\n",
      "20m(b) Schematic diagram of perceptual\n",
      "range. The vehicle’s perception of 20 me-\n",
      "ters is expanded to 40 meters through the\n",
      "shared perception data at the road end,\n",
      "so the target vehicle can be sensed at 30\n",
      "meters.\n",
      "Fig. 5: Test1\n",
      "When the system runs in this scenario, we can see in 5(b)\n",
      "that the target vehicle is sensed and recognized by the road-\n",
      "end equipment when it enters the curve. At this moment, inJOURNAL OF L ATEX CLASS FILES, VOL. 6\n",
      "our vehicle’s view, the target vehicle is still out of range of\n",
      "perception.\n",
      "With the sharing of perceptual information by the equipment\n",
      "at the road end, our vehicle obtained the location information\n",
      "and boundary information of the target vehicle at the other end\n",
      "of the road. From the perspective of our vehicle, we can see\n",
      "that even though the sensing range of vehicle lidar is only\n",
      "20 meters, the position and pose information of the target\n",
      "vehicle 30 meters away can be obtained in advance through\n",
      "the vehicle-road cooperation system.\n",
      "In this scenario, through the vehicle’s cooperative intelli-\n",
      "gent perception system, the information of the target vehicle\n",
      "is acquired by our vehicle outside the perception range of\n",
      "our vehicle, so that the perception range of our vehicle is\n",
      "expanded.\n",
      "The expansion of perception range can solve the problem\n",
      "of trafﬁc jams to some extent because vehicles can sense the\n",
      "trafﬁc ﬂow on the road ahead in advance and make more\n",
      "efﬁcient strategies such as changing lanes accordingly.\n",
      "B. Supplemental Blind area\n",
      "When the system runs in this scenario, we can get the\n",
      "perception results in 6(a). It can be seen from the results\n",
      "that the original vehicle lidar point cloud could not perceive\n",
      "pedestrians because most of the perception range of the right\n",
      "front of the vehicle was blocked by the sidecar body. The view\n",
      "from 10 degrees to 160 degrees on the right side of the vehicle\n",
      "is blocked, while pedestrians appear 30 degrees on the right\n",
      "side of the vehicle. As can be seen from 6(b), the braking\n",
      "distance and reaction time of the vehicle from perceiving a\n",
      "pedestrian to the collision is only 8 meters and 1 second, which\n",
      "is insufﬁcient for the 12.7 meters braking distance required by\n",
      "the vehicle traveling at 30 km/h.\n",
      "However, with the help of the vehicle-road cooperation\n",
      "system, the perception information at the road end is shared\n",
      "with the vehicle end when the vehicle passes the intersection,\n",
      "which is combined with the vehicle end through data fusion\n",
      "to supplement the perception information of the covered area\n",
      "so that the vehicle end can indirectly perceive the pedestrian\n",
      "and avoid accidents before 20 meters.\n",
      "This test demonstrates the superiority of the vehicle-road\n",
      "cooperative system in terms of safety. In the case of only\n",
      "relying on the vehicle’s sensor, the vehicle can not perceive the\n",
      "covered target, resulting in a potential safety hazard. However,\n",
      "with the supplement of the vehicle-road cooperation system,\n",
      "the vehicle perception information is broadened, the blind\n",
      "area of the visual ﬁeld is reduced, and the hidden danger is\n",
      "eliminated.\n",
      "In this scenario, through the vehicle-road cooperative in-\n",
      "telligent perception system, the blind area of the perceptual\n",
      "information of the vehicle is supplemented, which solves\n",
      "the thorny blind area problem of single-vehicle autonomous\n",
      "driving.\n",
      "C. Improved Accuracy\n",
      "When the system runs in this scenario, we can get the\n",
      "perception results in 7(a). It can be seen that the vehicle and\n",
      "(a) The perception result. The blue point cloud is\n",
      "perceived by the road end, and the green point\n",
      "cloud is perceived by the vehicle end.\n",
      "Distance between walker and vehicle\n",
      "road end\n",
      "vehicle\n",
      "collision\n",
      "(b) Distance between pedestrians and vehicles changes over time. The\n",
      "green and blue zones represent pedestrians sensed at the road end and the\n",
      "vehicle end, respectively, and the orange zone represents that the collision\n",
      "occurred.\n",
      "Fig. 6: Test2\n",
      "the road end get different boundaries to the target vehicle\n",
      "through perception.\n",
      "We consider the boundary overlap as our evaluation indi-\n",
      "cator. Boundary overlap refers to the ratio of the intersection\n",
      "area between the detected boundary and the real boundary\n",
      "of the target to the real boundary area. After calculation, the\n",
      "boundary overlap of the vehicle is 92.9%, that of the road end\n",
      "is 92.8%, and that of the fusion result is 93.7%.\n",
      "In this scenario, through the vehicle-road cooperative intel-\n",
      "ligent perception system, the boundary overlap perceived by\n",
      "vehicles to target vehicles increased from 92.9% to 93.7%,\n",
      "indicating that vehicle-road cooperation can improve the ac-\n",
      "curacy of perception.\n",
      "With higher perceptual accuracy, autonomous vehicles can\n",
      "perform more precise operations, increasing the safety and\n",
      "efﬁciency of autonomous driving.\n",
      "VI. D ISCUSSION\n",
      "In this project, we designed and implemented the vehicle-\n",
      "road cooperation intelligent perception system, including itsJOURNAL OF L ATEX CLASS FILES, VOL. 7\n",
      "(a) The perception result. The blue\n",
      "point cloud is perceived by the road\n",
      "end, and the green point cloud is\n",
      "perceived by the vehicle end.\n",
      "(b) Comparison of detection accuracy.\n",
      "Red is the ground truth, blue is the\n",
      "vehicle detection result, green is the\n",
      "road end detection result, and orange\n",
      "is the fusion result.\n",
      "Fig. 7: Test3\n",
      "processing ﬂow and data fusion scheme. After that, we de-\n",
      "signed the feasibility and safety test scenarios for the vehicle-\n",
      "road cooperative system. Then, we used the test scenes\n",
      "we designed to test our vehicle-road cooperative intelligent\n",
      "perception system. The test results not only show that our\n",
      "system can realize the intelligent perception of vehicles and\n",
      "pedestrians, but also prove the feasibility and safety of the\n",
      "system by expanding the perception range, supplementing the\n",
      "perception blind area and improving perception accuracy. This\n",
      "also proves the superiority of vehicle-road collaboration over\n",
      "single-vehicle autonomous driving.\n",
      "This project can be improved as follows: ﬁrst, the system\n",
      "can adopt multi-mode sensor information and realize a multi-\n",
      "mode fusion scheme at the same time, to achieve a better\n",
      "perception effect. Second, more test scenarios can be designed\n",
      "later to increase the complexity of the system so that it can\n",
      "cope with more complex situations.\n",
      "REFERENCES\n",
      "[1] L. Wang, B. Ai, D. He, K. Guan, J. Zhang, J. Kim, and Z. Zhong,\n",
      "“Vehicle-to-infrastructure channel characterization in urban environment\n",
      "at 28 ghz,” China communications , vol. 16, no. 2, pp. 36–48, 2019.\n",
      "[2] H. Kaur and Meenakshi, “Analysis of vanet geographic routing protocols\n",
      "on real city map,” in 2017 2nd IEEE International Conference on\n",
      "Recent Trends in Electronics, Information Communication Technology\n",
      "(RTEICT) , 2017, pp. 895–899.\n",
      "[3] G. Lan, T. Liu, X. Wang, X. Pan, and Z. Huang, “A semantic web\n",
      "technology index,” Scientiﬁc Reports , vol. 12, no. 1, pp. 1–10, 2022.\n",
      "[4] G. Lan, Z. Gao, L. Tong, and T. Liu, “Class binarization to neuroevolu-\n",
      "tion for multiclass classiﬁcation,” Neural Computing and Applications ,\n",
      "pp. 1–18, 2022.\n",
      "[5] N. Liu, M. Liu, J. Cao, G. Chen, and W. Lou, “When transportation\n",
      "meets communication: V2p over vanets,” in 2010 IEEE 30th Interna-\n",
      "tional Conference on Distributed Computing Systems , 2010, pp. 567–\n",
      "576.\n",
      "[6] G. Lan, M. Jelisavcic, D. M. Roijers, E. Haasdijk, and A. E. Eiben,\n",
      "“Directed locomotion for modular robots with evolvable morphologies,”\n",
      "inInternational Conference on Parallel Problem Solving from Nature .\n",
      "Springer, 2018, pp. 476–487.\n",
      "[7] P. Panchapakesan, “Overview of lte based cellular v2x communication,”\n",
      "Telecom Business Review , vol. 10, no. 1, pp. 23–30, 2017, copyright\n",
      "Publishing India Group 2017.\n",
      "[8] H. Xu, G. Lan, S. Wu, and Q. Hao, “Online intelligent calibration of\n",
      "cameras and lidars for autonomous driving systems,” in 2019 IEEE\n",
      "Intelligent Transportation Systems Conference (ITSC) . IEEE, 2019,\n",
      "pp. 3913–3920.[9] X. Wu, L. Peng, H. Yang, L. Xie, C. Huang, C. Deng, H. Liu, and\n",
      "D. Cai, “Sparse fuse dense: Towards high quality 3d detection with\n",
      "depth completion,” arXiv preprint arXiv:2203.09780 , 2022.\n",
      "[10] H. Wu, Q. Li, C. Wen, X. Li, X. Fan, and C. Wang, “Tracklet proposal\n",
      "network for multi-object tracking on point clouds,” in Proceedings of the\n",
      "International Joint Conference on Artiﬁcial Intelligence (IJCAI) , 2021,\n",
      "pp. 1165–1171.\n",
      "[11] G. Lan, J. Chen, and Eiben, A. E., “Evolutionary predator-prey robot\n",
      "systems: From simulation to real world,” in Proceedings of the Genetic\n",
      "and Evolutionary Computation Conference Companion , 2019, pp. 123–\n",
      "124.\n",
      "[12] G. Lan, J. Chen, and A. E. Eiben, “Simulated and real-world evolution\n",
      "of predator robots,” in 2019 IEEE Symposium Series on Computational\n",
      "Intelligence (SSCI) . IEEE, 2019, pp. 1974–1981.\n",
      "[13] Z. Xiao, D. Yang, F. Wen, and K. Jiang, “A uniﬁed multiple-target posi-\n",
      "tioning framework for intelligent connected vehicles,” Sensors , vol. 19,\n",
      "no. 9, 2019.\n",
      "[14] Z. Wang, Y . Wu, and Q. Niu, “Multi-sensor fusion in automated driving:\n",
      "A survey,” IEEE Access , vol. 8, pp. 2847–2868, 2020.\n",
      "[15] G. Lan, J. Liang, G. Liu, and Q. Hao, “Development of a smart ﬂoor\n",
      "for target localization with bayesian binary sensing,” in 2017 IEEE\n",
      "31st International Conference on Advanced Information Networking and\n",
      "Applications (AINA) . IEEE, 2017, pp. 447–453.\n",
      "[16] G. Lan, Z. Luo, and Q. Hao, “Development of a virtual reality tele-\n",
      "conference system using distributed depth sensors,” in 2016 2nd IEEE\n",
      "International Conference on Computer and Communications (ICCC) .\n",
      "IEEE, 2016, pp. 975–978.\n",
      "[17] H. J. Vishnukumar, B. Butting, C. Müller, and E. Sax, “Machine learning\n",
      "and deep neural network — artiﬁcial intelligence core for lab and real-\n",
      "world test and validation for adas and autonomous vehicles: Ai for\n",
      "efﬁcient and quality test and validation,” in 2017 Intelligent Systems\n",
      "Conference (IntelliSys) , 2017, pp. 714–721.\n",
      "[18] G. Lan, L. De Vries, and S. Wang, “Evolving efﬁcient deep neural\n",
      "networks for real-time object recognition,” in 2019 IEEE Symposium\n",
      "Series on Computational Intelligence (SSCI) . IEEE, 2019, pp. 2571–\n",
      "2578.\n",
      "[19] G. Lan, J. Benito-Picazo, D. M. Roijers, E. Domínguez, and A. E. Eiben,\n",
      "“Real-time robot vision on low-performance computing hardware,” in\n",
      "2018 15th international conference on control, automation, robotics and\n",
      "vision (ICARCV) . IEEE, 2018, pp. 1959–1965.\n",
      "[20] G. Lan, J. M. Tomczak, D. M. Roijers, and A. E. Eiben, “Time efﬁciency\n",
      "in optimization with a bayesian-evolutionary algorithm,” Swarm and\n",
      "Evolutionary Computation , vol. 69, p. 100970, 2022.\n",
      "[21] G. Lan, M. De Carlo, F. van Diggelen, J. M. Tomczak, D. M. Roijers,\n",
      "and A. E. Eiben, “Learning directed locomotion in modular robots with\n",
      "evolvable morphologies,” Applied Soft Computing , vol. 111, p. 107688,\n",
      "2021.\n",
      "[22] G. Lan, M. van Hooft, M. De Carlo, J. M. Tomczak, and A. E. Eiben,\n",
      "“Learning locomotion skills in evolvable robots,” Neurocomputing , vol.\n",
      "452, pp. 294–306, 2021.\n",
      "[23] A. Dosovitskiy, G. Ros, F. Codevilla, A. Lopez, and V . Koltun,\n",
      "“CARLA: An open urban driving simulator,” in Proceedings of the 1st\n",
      "Annual Conference on Robot Learning , 2017, pp. 1–16.\n",
      "[24] O. D. Team, “Openpcdet: An open-source toolbox for 3d object detection\n",
      "from point clouds,” https://github.com/open-mmlab/OpenPCDet, 2020.\n",
      "[25] Y . Guo, G. Chen, P. Zhao, W. Zhang, J. Miao, J. Wang, and T. E.\n",
      "Choe, “Gen-lanenet: A generalized and scalable approach for 3d lane\n",
      "detection,” 2020.\n",
      "[26] X. Weng, J. Wang, D. Held, and K. Kitani, “3D Multi-Object Tracking:\n",
      "A Baseline and New Evaluation Metrics,” IROS , 2020.\n",
      "[27] G. Lan, J. Sun, C. Li, Z. Ou, Z. Luo, J. Liang, and Q. Hao, “Development\n",
      "of uav based virtual reality systems,” in 2016 IEEE International Con-\n",
      "ference on Multisensor Fusion and Integration for Intelligent Systems\n",
      "(MFI) . IEEE, 2016, pp. 481–486.A Highway Toll Lane Framework that Unites Autonomous Vehicles and\n",
      "High-occupancy Vehicles\n",
      "Ruolin Li1, Philip N. Brown2and Roberto Horowitz1\n",
      "Abstract — We consider the scenario where human-\n",
      "driven/autonomous vehicles with low/high occupancy are\n",
      "sharing a segment of highway and autonomous vehicles are\n",
      "capable of increasing the trafﬁc throughput by preserving a\n",
      "shorter headway than human-driven vehicles. We propose a\n",
      "toll lane framework where a lane on the highway is reserved\n",
      "freely for autonomous vehicles with high occupancy, which\n",
      "have the greatest capability to increase the social mobility, and\n",
      "the other three classes of vehicles can choose to use the toll lane\n",
      "with a toll or use the other regular lanes freely. All vehicles\n",
      "are assumed to be only interested in minimizing their own\n",
      "travel costs. We explore the resulting lane choice equilibria\n",
      "under the framework and establish desirable properties of\n",
      "the equilibria, which implicitly compare high-occupancy\n",
      "vehicles with autonomous vehicles in terms of their capabilities\n",
      "to increase the social mobility. We further use numerical\n",
      "examples in the optimal toll design, the occupancy threshold\n",
      "design and the policy design problems to clarify the various\n",
      "potential applications of this toll lane framework that unites\n",
      "high-occupancy vehicles and autonomous vehicles. To our best\n",
      "knowledge, this is the ﬁrst work that systematically studies\n",
      "a toll lane framework that unites autonomous vehicles and\n",
      "high-occupancy vehicles on the roads.\n",
      "I. I NTRODUCTION\n",
      "With the advancement of autonomous driving technolo-\n",
      "gies, researchers and policy designers have been extensively\n",
      "investigating the potential application of autonomous ve-\n",
      "hicles in intelligent transportation systems. Compared to\n",
      "human-driven vehicles, autonomous vehicles can be more\n",
      "reliable by mitigating human operation errors [1], [2] and\n",
      "more advantageous in sustainable development by optimizing\n",
      "fuel consumption [3], [4]. Previous literature has also shown\n",
      "that autonomous vehicles are capable of increasing lane\n",
      "capacities by forming platoons and preserving a shorter\n",
      "headway compared to human-driven vehicles, and therefore,\n",
      "increase the trafﬁc throughput [5]–[7].\n",
      "However, some advantages of connected and autonomous\n",
      "vehicles rely heavily on the organization of autonomous\n",
      "vehicles on the roads. For example, gathering autonomous\n",
      "vehicles on the roads together will facilitate the platooning\n",
      "of autonomous vehicles and also be safer due to the lack\n",
      "of disturbances from human-driven vehicles. Therefore, lane\n",
      "policies for autonomous vehicles are of signiﬁcant impor-\n",
      "tance and can be decisive on the efﬁciency of employing au-\n",
      "tonomous vehicles. Currently, there are two major categories\n",
      "1R. Li and R. Horowitz are with the Department\n",
      "of Mechanical Engineering, University of California,\n",
      "Berkeley, CA, USA. ruolin li@berkeley.edu ,\n",
      "horowitz@me.berkeley.edu.\n",
      "2P. N. Brown is with the Department of Computer Science, University\n",
      "of Colorado Colorado Springs, USA. philip.brown@uccs.edu.of lane policies for autonomous vehicles. The ﬁrst category\n",
      "is the integrated lane policy [8]. The integrated lane policy\n",
      "indicates that autonomous vehicles travel along with human-\n",
      "driven vehicles on the same group of lanes. Such policies\n",
      "are convenient but may compromise the platooning ability\n",
      "and safety of autonomous vehicles. The second category\n",
      "of policies are dedicated lane policies [9]–[11]. Under such\n",
      "policies, some lanes are reserved exclusively for autonomous\n",
      "vehicles. Such policies are preferred considering the safety\n",
      "and the easy organization of autonomous vehicles. However,\n",
      "when the penetration rate of autonomous vehicles is low,\n",
      "the employment of dedicated lanes shows adverse effects\n",
      "and compromises the social mobility [12], [13]. Further,\n",
      "in [14], autonomous vehicle toll lanes are studied, which\n",
      "admit autonomous vehicles to travel freely but also allow\n",
      "human-driven vehicles to enter paying a toll. This way, when\n",
      "the penetration rate of autonomous vehicles is low, human-\n",
      "driven vehicles can effectively use the toll lane and relieve\n",
      "congestion on regular lanes.\n",
      "Even when autonomous vehicles are prevalent and ded-\n",
      "icated lanes are necessary in terms of the safety and ad-\n",
      "vantageous mobility, the implementation or construction of\n",
      "brand new dedicated lanes can be costly and time-consuming.\n",
      "Therefore, researchers recently consider converting other ex-\n",
      "isting dedicated lanes such as high-occupancy vehicle lanes\n",
      "to dedicated lanes for autonomous vehicles. For example,\n",
      "in [15], [16], simulations and experiments are conducted\n",
      "to investigate the beneﬁt of converting an existing high-\n",
      "occupancy vehicle lane to a dedicated lane for autonomous\n",
      "vehicles.\n",
      "In this work, we consider the scenario where four classes\n",
      "of vehicles are sharing a segment of highway: human-driven\n",
      "vehicles with low occupancy, human-driven vehicles with\n",
      "high occupancy, autonomous vehicles with low occupancy\n",
      "and autonomous vehicles with high occupancy. Autonomous\n",
      "vehicles are capable of increasing the trafﬁc throughput by\n",
      "preserving a shorter headway than human-driven vehicles.\n",
      "High-occupancy vehicles carry multiple commuters per ve-\n",
      "hicle and low-occupancy vehicles carry a single commuter\n",
      "per vehicle. We propose a toll lane framework, where on\n",
      "the highway, a toll lane is reserved freely for autonomous\n",
      "vehicles with high occupancy and the other three classes of\n",
      "vehicles can choose to enter the toll lane paying a toll or use\n",
      "the other regular lanes freely. We consider all vehicles are\n",
      "selﬁsh and only interested in minimizing their own travel\n",
      "costs. We then explore the resulting lane choice equilibria\n",
      "and establish properties of the equilibria, which implicitly\n",
      "compare high-occupancy vehicles with autonomous vehiclesarXiv:2107.03477v2  [eess.SY]  26 Jul 2021AV, LOHV, LOAV, HOHV, HO\n",
      "Lane 1Lane 2Fig. 1: Problem setting: all autonomous vehicles with high\n",
      "occupancy travel freely on lane 1, whereas the other three\n",
      "classes of vehicles either pay a toll traveling on lane 1 or\n",
      "travel on lane 2 freely.\n",
      "in terms of their capabilities to increase the social mobility.\n",
      "We further use numerical examples to clarify the various\n",
      "potential applications of this toll lane framework that unites\n",
      "high-occupancy vehicles and autonomous vehicles in the op-\n",
      "timal toll design, the optimal occupancy threshold design and\n",
      "the policy design problems. To our best knowledge, this is the\n",
      "ﬁrst work that systematically studies a toll lane framework\n",
      "that unites autonomous vehicles and high-occupancy vehicles\n",
      "on the roads.\n",
      "This paper is organized as follows. In Section II, we give\n",
      "detailed descriptions of the toll lane framework and vehicles’\n",
      "lane choice model. In Section III, we establish the properties\n",
      "of the resulting lane choice equilibria. In Section IV, we\n",
      "clarify how the toll lane framework can be used to ﬁnd\n",
      "the optimal toll that minimizes the total commuter delay.\n",
      "In Section V, we clarify how the toll lane framework can be\n",
      "used to design the occupancy threshold. In Section VI, we\n",
      "clarify how the toll lane framework can be used to design the\n",
      "lane policy. In Section VII, we propose an efﬁcient method\n",
      "to decrease the total commuter delay by differentiating the\n",
      "tolls. Finally, in Section VIII, we draw conclusions of this\n",
      "work.\n",
      "II. T HEMODEL\n",
      "LetI=f1;2gbe the lane index set for a segment of\n",
      "highway shown in Figure 1, where lane 1 is the reserved\n",
      "toll lane, and lane 2 is a regular lane that can be used by\n",
      "any class of vehicles freely. We consider that four classes\n",
      "of vehicles are sharing the roads: human-driven vehicles\n",
      "with low occupancy (HV ,LO), human-driven vehicles with\n",
      "high occupancy (HV ,HO), autonomous vehicles with low\n",
      "occupancy (A V ,LO) and autonomous vehicles with high\n",
      "occupancy (A V ,HO). We assume high-occupancy vehicles\n",
      "haven\u00152commuters per vehicle and low-occupancy\n",
      "vehicles have only one commuter per vehicle. Throughout\n",
      "this work, we assume the commuter demands are inelastic.\n",
      "LetdHV;LObe the ﬁxed demand of commuters who individ-\n",
      "ually drive a human-driven vehicle and let dHV;HObe the\n",
      "ﬁxed demand of commuters who carpool in a human-driven\n",
      "vehicle. Similarly, we have dAV;LOas the ﬁxed demand of\n",
      "commuters who individually use an autonomous vehicle andletdAV;HObe the ﬁxed demand of commuters who carpool in\n",
      "an autonomous vehicle. We collect the commuter demands\n",
      "in the vector d:=\u0000\n",
      "dHV;LO; dHV;HO; dAV;LO; dAV;HO\u0001\n",
      ".\n",
      "Therefore, on the segment of highway, we have dHV;LO\n",
      "human-driven vehicles with low occupancy,dHV;HO\n",
      "nhuman-\n",
      "driven vehicles with high occupancy, dAV;LOautonomous\n",
      "vehicles with low occupancy, anddAV;HO\n",
      "nautonomous vehi-\n",
      "cles with high occupancy. Also in this framework, we assume\n",
      "autonomous vehicles can preserve a shorter headway than\n",
      "human-driven vehicles and therefore, increase the lane capac-\n",
      "ities. We employ the concept introduced and studied in [8],\n",
      "[17], the capacity symmetry degree \u00162(0;1), to indicate\n",
      "autonomous vehicles’ lane capacity-increasing ability. When\n",
      "\u0016decreases, autonomous vehicles’ lane capacity-increasing\n",
      "ability increases. When \u0016approaches 1, autonomous vehicles\n",
      "have almost the same headway as human-driven vehicles\n",
      "and barely increase lane capacity. In this work, autonomous\n",
      "vehicles share a uniform and ﬁxed capacity asymmetry\n",
      "degree\u0016.\n",
      "We reserve lane 1 for the autonomous vehicles with\n",
      "high occupancy due to their best capability to increase\n",
      "the social mobility among the four classes of vehicles by\n",
      "carrying multiple commuters per vehicle and preserving a\n",
      "shorter headway than human-driven vehicles. The other three\n",
      "classes of vehicles can then choose to either pay a toll\n",
      "and enter lane 1 or travel freely on lane 2. For i2I,\n",
      "letfHV;LO\n",
      "i be the ﬂow of human-driven vehicles with low\n",
      "occupancy on lane i,fHV;HO\n",
      "i be the ﬂow of human-driven\n",
      "vehicles with high occupancy on lane i, andfAV;LO\n",
      "i be\n",
      "the ﬂow of autonomous vehicles with low occupancy on\n",
      "lanei. We then have the ﬂow distribution vector f:= \u0010\n",
      "fHV;LO\n",
      "i; fHV;HO\n",
      "i; fAV;LO\n",
      "i :i2I\u0011\n",
      "2R6. A feasible and\n",
      "meaningful ﬂow distribution vector fsatisﬁes:\n",
      "X\n",
      "i2IfHV;LO\n",
      "i =dHV;LO; (1)\n",
      "X\n",
      "i2IfHV;HO\n",
      "i =dHV;HO\n",
      "n; (2)\n",
      "X\n",
      "i2IfAV;LO\n",
      "i =dAV;LO; (3)\n",
      "fHV;LO\n",
      "i\u00150; fHV;HO\n",
      "i\u00150; fAV;LO\n",
      "i\u00150;8i2I: (4)\n",
      "For simplicity, we may use f := \u0010\n",
      "fHV;LO\n",
      "1; fHV;HO\n",
      "1; fAV;LO\n",
      "1\u0011\n",
      "2R3for future reference\n",
      "with constraints (1) – (4) implied.\n",
      "We naturally assume vehicles are selﬁsh and the three\n",
      "classes of vehicles make their lane choices to minimize\n",
      "their own travel cost. In this framework, we use the type of\n",
      "volume-capacity delay models (such as BPR functions [18]),\n",
      "in which the travel delay is a continuous and increasing\n",
      "function of the ﬂow-capacity ratio. For lane i2I, letDi\n",
      "be the travel delay on the lane. To incorporate the impact\n",
      "of autonomous vehicles, we refer to the results from [19]\n",
      "and [8], and for lane i2I, we letfibe the effective ﬂow\n",
      "on lanei, which indicates the impact of the mixed autonomyﬂow on the lane delay. We have\n",
      "f1:=fHV;LO\n",
      "1 +fHV;HO\n",
      "1 +\u0016\u0012\n",
      "fAV;LO\n",
      "1 +dAV;HO\n",
      "n\u0013\n",
      ";(5)\n",
      "f2:=fHV;LO\n",
      "2 +fHV;HO\n",
      "2 +\u0016fAV;LO\n",
      "2: (6)\n",
      "Therefore, for lane i2I, we have that travel delay Diis\n",
      "a continuous and increasing function of fi. Letfmin\n",
      "1be the\n",
      "theoretical minimum of f1, and letfmax\n",
      "1 be the theoretical\n",
      "maximum of f1. Notice that for ﬁxed commuter demands,\n",
      "fmin\n",
      "1andfmax\n",
      "1 are constants. We have\n",
      "fmin\n",
      "1=\u0016dAV;HO\n",
      "n; (7)\n",
      "fmax\n",
      "1=dHV;LO+dHV;HO\n",
      "n+\u0016\u0012\n",
      "dAV;LO+dAV;HO\n",
      "n\u0013\n",
      ":\n",
      "(8)\n",
      "We assume that a uniform toll price \u001C\u00150is designed for the\n",
      "three classes of vehicles. For lane 1, the travel cost equals\n",
      "the sum of the travel delay and the toll, whereas for lane 2,\n",
      "the travel cost is exactly the travel delay. Let Cibe the travel\n",
      "cost for lane i2I, and we have\n",
      "C1(f) =D1(f1) +\u001C; (9)\n",
      "C2(f) =D2(f2): (10)\n",
      "Let the tuple G= (D;d;\u001C;n;\u0016 )represent a segment of\n",
      "highway shown in Figure 1 with the delay models D,\n",
      "commuter demands d, a toll price \u001C, an occupancy threshold\n",
      "nfor high-occupancy vehicles and a capacity asymmetry\n",
      "degree\u0016for autonomous vehicles. The selﬁsh lane choice\n",
      "equilibrium of the three classes of vehicles can then be\n",
      "modeled as a Wardrop equilibrium [20] as below.\n",
      "Deﬁnition 1. For a segment of highway G= (D;d;\u001C;n;\u0016 ),\n",
      "a feasible ﬂow distribution vector fis a lane choice equilib-\n",
      "rium if and only if\n",
      "fHV;LO\n",
      "1 (C1(f)\u0000C2(f))\u00140; (11a)\n",
      "fHV;LO\n",
      "2 (C2(f)\u0000C1(f))\u00140; (11b)\n",
      "fHV;HO\n",
      "1 (C1(f)\u0000C2(f))\u00140; (11c)\n",
      "fHV;HO\n",
      "2 (C2(f)\u0000C1(f))\u00140; (11d)\n",
      "fAV;LO\n",
      "1 (C1(f)\u0000C2(f))\u00140; (11e)\n",
      "fAV;LO\n",
      "2 (C2(f)\u0000C1(f))\u00140: (11f)\n",
      "The deﬁnition guarantees that at the choice equilibrium, if\n",
      "the travel cost of lane 1 is higher than the travel cost of lane\n",
      "2, then all of the three classes of vehicles would travel on\n",
      "lane 2; if the travel cost of lane 1 is lower than the travel\n",
      "cost of lane 2, then all of the three classes of vehicles would\n",
      "choose to pay the toll and travel on lane 1; if the travel cost\n",
      "of lane 1 is equal to the travel cost of lane 2, then any vehicle\n",
      "of the three classes of vehicles could travel either on lane 1\n",
      "or on lane 2. Moreover, if any of the three classes of vehicles\n",
      "are on lane 1, then the travel cost of lane 1 cannot be higher\n",
      "than the cost of lane 2; if any of the three classes of vehicles\n",
      "are on lane 2, then the travel cost of lane 2 cannot be higherthan the cost of lane 1; if the any class of vehicles use both\n",
      "lane 1 and lane 2, then the travel cost of lane 1 and lane 2\n",
      "must be equal.\n",
      "The metric we use in this framework to evaluate the social\n",
      "mobility is the total delay of all commuters. The total delay\n",
      "of all commuters at an lane choice equilibrium fcan be\n",
      "calculated as\n",
      "J(f) =\u0014\n",
      "fHV;LO\n",
      "1 +fAV;LO\n",
      "1 +n\u0012\n",
      "fHV;HO\n",
      "1 +dAV;HO\n",
      "n\u0013\u0015\n",
      "D1(f1)\n",
      "+\u0010\n",
      "fHV;LO\n",
      "2 +fAV;LO\n",
      "2 +nfHV;HO\n",
      "2\u0011\n",
      "D2(f2): (12)\n",
      "III. E QUILIBRIUM PROPERTIES\n",
      "In this section, we establish crucial properties of the\n",
      "resulting lane choice equilibria under the framework as\n",
      "described in Deﬁnition 1. According to the core theorem\n",
      "in [21], we give the following proposition without proof.\n",
      "Proposition 1. For a segment of highway G =\n",
      "(D;d;\u001C;n;\u0016 ), there always exists at least one lane choice\n",
      "equilibrium as described in Deﬁnition 1.\n",
      "The next theorem claims that the resulting lane choice\n",
      "equilibrium is generally only unique if at the equilibrium,\n",
      "all of the three classes of vehicles travel on the same lane.\n",
      "Theorem 1. For a segment of highway G= (D;d;\u001C;n;\u0016 ),\n",
      "the lane choice equilibrium as described in Deﬁnition 1 is\n",
      "unique if and only if any of the following conditions holds:\n",
      "\u000F\u001C\u0015D2\u0000\n",
      "fmax\n",
      "1\u0000fmin\n",
      "1\u0001\n",
      "\u0000D1\u0000\n",
      "fmin\n",
      "1\u0001\n",
      ";\n",
      "\u000F\u001C\u0014D2(0)\u0000D1(fmax\n",
      "1):\n",
      "Proof. The travel cost on lane 1, C1(f)is a continuous,\n",
      "increasing function of f1, thus can be written as C1(f1).\n",
      "Also notice that, we always have\n",
      "f1+f2=fmax\n",
      "1: (13)\n",
      "Thus with slight abuse of notation, we can treat the travel\n",
      "cost on lane 2, C2(f)as a continuous, decreasing function\n",
      "off1, written as C2(f1). Three possible sketches of C1(f1)\n",
      "andC2(f1)forf12[fmin\n",
      "1;fmax\n",
      "1]are shown in Figure 2.\n",
      "In case (a), C1(f1)\u0015C2(f1)for any possible f12\n",
      "[fmin\n",
      "1;fmax\n",
      "1], thus all of the three classes of vehicles would\n",
      "use lane 2, and the lane choice equilibrium is unique at\n",
      "(0;0;0). In case (c), C1(f1)\u0014C2(f1)for any possible\n",
      "f12[fmin\n",
      "1;fmax\n",
      "1], thus all of the three classes of vehicles\n",
      "would use lane 1, and the lane choice equilibrium is unique\n",
      "at\u0010\n",
      "dHV;LO;dHV;HO\n",
      "n; dAV;LO\u0011\n",
      ".\n",
      "In case (b), the resulting lane choice equilibria are in\n",
      "general not unique. One can check that possible lane choice\n",
      "equilibria that satisfy Deﬁnition 1 must satisfy\n",
      "C1(f\u0003\n",
      "1) =C2(f\u0003\n",
      "1); (14)\n",
      "wheref\u0003\n",
      "12(fmin\n",
      "1;fmax\n",
      "1)is the value of f1at the equilibria.\n",
      "Thus according to Equation (5), the resulting equilibria must𝑓!\"#$𝑓!\"%&0Travel cost\n",
      "𝐶!(𝑓!)𝐶'(𝑓!)𝑓!(a)C1(f1)\u0015C2(f1),8f12[fmin\n",
      "1; fmax\n",
      "1].\n",
      "𝑓!\"#$𝑓!\"%&0Travel cost\n",
      "𝐶!(𝑓!)𝐶'(𝑓!)𝑓!𝑓!∗ (b)C1(f1)andC2(f1)intersect at f\u0003\n",
      "1.\n",
      "𝑓!\"#$𝑓!\"%&0Travel cost\n",
      "𝐶!(𝑓!)𝐶'(𝑓!)𝑓! (c)C1(f1)\u0014C2(f1),8f12[fmin\n",
      "1; fmax\n",
      "1].\n",
      "Fig. 2: Possible sketches of the travel cost on both lanes. Resulting lane choice equilibria are indicated by the green dots.\n",
      "Non-unique equilibria only exist in case (b).\n",
      "satisfy\n",
      "fHV;LO\n",
      "1 +fHV;HO\n",
      "1 +\u0016fAV;LO\n",
      "1 =f\u0003\n",
      "1\u0000fmin\n",
      "1: (15)\n",
      "All resulting equilibria should also satisfy the feasibility\n",
      "conditions, thus the resulting equilibria lie in a simplex\n",
      "S\u001AR3which can be characterized as\n",
      "S:=ff2R3:fsatisﬁes (15) ;(1);(2);(3);(4)g:(16)\n",
      "Through the proof, for a segment of highway G=\n",
      "(D;d;\u001C;n;\u0016 ), the resulting lane choice equilibrium is only\n",
      "unique if the toll is so big or so small that at the equilibrium,\n",
      "all of the three classes of vehicles choose the same lane.\n",
      "Otherwise, we can easily characterize the non-unique lane\n",
      "choice equilibria by a simplex Sin Equation (16). The total\n",
      "commuter delay at the equilibrium can be ambiguous if there\n",
      "are multiple equilibria. Therefore, we give the following\n",
      "theorem to further characterize the non-unique equilibria in\n",
      "terms of the total commuter delay, which is helpful for future\n",
      "analysis. For a segment of highway G= (D;d;\u001C;n;\u0016 )\n",
      "with non-unique equilibria, we let f+2 S be the worst\n",
      "equilibrium that satisﬁes\n",
      "J(f)\u0014J\u0000\n",
      "f+\u0001\n",
      ";8f2S; (17)\n",
      "andf\u00002S be the best equilibrium that satisﬁes\n",
      "J(f)\u0015J\u0000\n",
      "f\u0000\u0001\n",
      ";8f2S: (18)\n",
      "Theorem 2. For a segment of highway G= (D;d;\u001C;n;\u0016 )\n",
      "with non-unique lane choice equilibria as described in\n",
      "Deﬁnition 1:\n",
      "\u000Fifn>1\n",
      "\u0016, we have\n",
      "f+=\u0012\n",
      "max\n",
      "f2SfHV;LO\n",
      "1;min\n",
      "f2SfHV;HO\n",
      "1;\u0003\u0013\n",
      "; (19a)\n",
      "f\u0000=\u0012\n",
      "min\n",
      "f2SfHV;LO\n",
      "1;max\n",
      "f2SfHV;HO\n",
      "1;\u0003\u0013\n",
      "; (19b)\u000Fifn<1\n",
      "\u0016, we have\n",
      "f+=\u0012\n",
      "max\n",
      "f2SfHV;LO\n",
      "1;\u0003;min\n",
      "f2SfAV;LO\n",
      "1\u0013\n",
      "; (20a)\n",
      "f\u0000=\u0012\n",
      "min\n",
      "f2SfHV;LO\n",
      "1;\u0003;max\n",
      "f2SfAV;LO\n",
      "1\u0013\n",
      "; (20b)\n",
      "\u000Fifn=1\n",
      "\u0016, we have\n",
      "f+=\u0012\n",
      "max\n",
      "f2SfHV;LO\n",
      "1;\u0003;\u0003\u0013\n",
      "; (21a)\n",
      "f\u0000=\u0012\n",
      "min\n",
      "f2SfHV;LO\n",
      "1;\u0003;\u0003\u0013\n",
      "; (21b)\n",
      "where\u0003indicates the quantity can be any value that\n",
      "fulﬁlls that f+2S andf\u00002S.\n",
      "Proof. In this proof, we ﬁrst give a detailed explana-\n",
      "tion for f+whenn >1\n",
      "\u0016. Whenn >1\n",
      "\u0016, letf=\u0010\n",
      "fHV;LO\n",
      "1; fHV;HO\n",
      "1; fAV;LO\n",
      "1\u0011\n",
      "2 S andf6=f+. Due to\n",
      "f2S andf+2S, we have that fandf+both satisfy\n",
      "Equation (15). Thus we have\n",
      "J(f)\u0000J\u0000\n",
      "f+\u0001\n",
      "=\u0014\n",
      "fHV;LO\n",
      "1\u0000max\n",
      "f2SfHV;LO\n",
      "1\u0000\n",
      "1\n",
      "\u0016\u0012\n",
      "fHV;LO\n",
      "1\u0000max\n",
      "f2SfHV;LO\n",
      "1 +fHV;HO\n",
      "1\u0000min\n",
      "f2SfHV;HO\n",
      "1\u0013\n",
      "+n\u0012\n",
      "fHV;HO\n",
      "1\u0000min\n",
      "f2SfHV;HO\n",
      "1\u0013\u0015\n",
      "D1(f\u0003\n",
      "1)\n",
      "\u0000\u0014\n",
      "fHV;LO\n",
      "1\u0000max\n",
      "f2SfHV;LO\n",
      "1\u0000\n",
      "1\n",
      "\u0016\u0012\n",
      "fHV;LO\n",
      "1\u0000max\n",
      "f2SfHV;LO\n",
      "1 +fHV;HO\n",
      "1\u0000min\n",
      "f2SfHV;HO\n",
      "1\u0013\n",
      "+n\u0012\n",
      "fHV;HO\n",
      "1\u0000min\n",
      "f2SfHV;HO\n",
      "1\u0013\u0015\n",
      "D2(fmax\n",
      "1\u0000f\u0003\n",
      "1)(22)=\u0014\n",
      "fHV;LO\n",
      "1\u0000max\n",
      "f2SfHV;LO\n",
      "1\u0000\n",
      "1\n",
      "\u0016\u0012\n",
      "fHV;LO\n",
      "1\u0000max\n",
      "f2SfHV;LO\n",
      "1 +fHV;HO\n",
      "1\u0000min\n",
      "f2SfHV;HO\n",
      "1\u0013\n",
      "+n\u0012\n",
      "fHV;HO\n",
      "1\u0000min\n",
      "f2SfHV;HO\n",
      "1\u0013\u0015\n",
      "\u0002\n",
      "(D1(f\u0003\n",
      "1)\u0000D2(fmax\n",
      "1\u0000f\u0003\n",
      "1))(23)\n",
      "=\u0014\u0012\n",
      "1\u00001\n",
      "\u0016\u0013\u0012\n",
      "fHV;LO\n",
      "1\u0000max\n",
      "f2SfHV;LO\n",
      "1\u0013\n",
      "+\u0012\n",
      "n\u00001\n",
      "\u0016\u0013\u0012\n",
      "fHV;HO\n",
      "1\u0000min\n",
      "f2SfHV;HO\n",
      "1\u0013\u0015\n",
      "\u0002\n",
      "(D1(f\u0003\n",
      "1)\u0000D2(fmax\n",
      "1\u0000f\u0003\n",
      "1)):\n",
      "(24)\n",
      "According to Equation (14), we have\n",
      "D1(f\u0003\n",
      "1) +\u001C=D2(fmax\n",
      "1\u0000f\u0003\n",
      "1): (25)\n",
      "Since\u001C\u00150, we have\n",
      "D1(f\u0003\n",
      "1)\u0000D2(fmax\n",
      "1\u0000f\u0003\n",
      "1)\u00140: (26)\n",
      "Also, we have 1\u00001\n",
      "\u0016<0,n\u00001\n",
      "\u0016>0,fHV;LO\n",
      "1\u0000\n",
      "max\n",
      "f2SfHV;LO\n",
      "1\u00140andfHV;HO\n",
      "1\u0000min\n",
      "f2SfHV;HO\n",
      "1\u00150, thus\n",
      "we have\n",
      "J(f)\u0000J\u0000\n",
      "f+\u0001\n",
      "\u00140: (27)\n",
      "To complete the proof, we have to also show that f+2\n",
      "Sexists. To show this, we prove that there exists \u0003that\n",
      "both satisﬁes condition (15) and (3), i.e., there exists \u0003that\n",
      "satisﬁes\n",
      "max\n",
      "f2SfHV;LO\n",
      "1 +min\n",
      "f2SfHV;HO\n",
      "1 +\u0003\u0016=f\u0003\n",
      "1\u0000fmin\n",
      "1;(28)\n",
      "0\u0014\u0003\u0014dAV;LO: (29)\n",
      "Equivalently, we want to show that\n",
      "0\u0014f\u0003\n",
      "1\u0000fmin\n",
      "1\u0000max\n",
      "f2SfHV;LO\n",
      "1\u0000min\n",
      "f2SfHV;HO\n",
      "1\u0014\u0016dAV;LO:\n",
      "(30)\n",
      "We ﬁrst prove the ﬁrst inequality. Let ~fHV;HO\n",
      "1 be the ﬂow\n",
      "of human-driven vehicles with high occupancy on lane 1 at\n",
      "anyf2S where the ﬂow of human-driven vehicles with\n",
      "low occupancy on lane 1 equals max\n",
      "f2SfHV;LO\n",
      "1 . According to\n",
      "Equation (15), we must have\n",
      "~fHV;HO\n",
      "1\u0014f\u0003\n",
      "1\u0000fmin\n",
      "1\u0000max\n",
      "f2SfHV;LO\n",
      "1: (31)\n",
      "Due to min\n",
      "f2SfHV;HO\n",
      "1\u0014~fHV;HO\n",
      "1 , we have\n",
      "min\n",
      "f2SfHV;HO\n",
      "1\u0014f\u0003\n",
      "1\u0000fmin\n",
      "1\u0000max\n",
      "f2SfHV;LO\n",
      "1; (32)\n",
      "which shows the ﬁrst inequality. Then let ~fHV;LO\n",
      "1 be the\n",
      "ﬂow of human-driven vehicles with low occupancy on lane\n",
      "1,~fAV;LO\n",
      "1 be the ﬂow of autonomous vehicles with low\n",
      "occupancy on lane 1 at any f2 S where the ﬂow of\n",
      "human-driven vehicles with high occupancy on lane 1 equalsmin\n",
      "f2SfHV;HO\n",
      "1 . According to Equation (15), we must have\n",
      "f\u0003\n",
      "1\u0000fmin\n",
      "1\u0000min\n",
      "f2SfHV;HO\n",
      "1 =~fHV;LO\n",
      "1 +\u0016~fAV;LO\n",
      "1:(33)\n",
      "Due to ~fHV;LO\n",
      "1 +\u0016~fAV;LO\n",
      "1\u0014max\n",
      "f2SfHV;LO\n",
      "1 +\u0016dAV;LO, we\n",
      "have\n",
      "f\u0003\n",
      "1\u0000fmin\n",
      "1\u0000min\n",
      "f2SfHV;HO\n",
      "1\u0014max\n",
      "f2SfHV;LO\n",
      "1 +\u0016dAV;LO;\n",
      "(34)\n",
      "which shows the second inequality. With a similar process,\n",
      "we can prove for the other claims. Thus details are omitted.\n",
      "Theorem 2 implicitly compares the capability of au-\n",
      "tonomous vehicles with low-occupancy and human-driven\n",
      "vehicles with high-occupancy to decrease the total commuter\n",
      "delay. When n >1\n",
      "\u0016, human-driven vehicles with high-\n",
      "occupancy are more capable than autonomous vehicles with\n",
      "low-occupancy, and therefore, among the multiple equilibria,\n",
      "the best case equilibrium happens when we prioritize high-\n",
      "occupancy vehicles instead of autonomous vehicles on the\n",
      "toll lane 1. When n<1\n",
      "\u0016, human-driven vehicles with high-\n",
      "occupancy are less capable than autonomous vehicles with\n",
      "low-occupancy, and therefore, among the multiple equilib-\n",
      "ria, the best case equilibrium happens when we prioritize\n",
      "autonomous vehicles instead of high-occupancy vehicles on\n",
      "the toll lane 1. In all cases, the least capable class of\n",
      "vehicles is human-driven vehicles with low-occupancy, thus\n",
      "the worst equilibrium happens when we prioritize human-\n",
      "driven vehicles with low-occupancy on toll lane 1.\n",
      "With Theorem 1, we can obtain the unique equilibrium\n",
      "when conditions hold and when equilibria are not unique,\n",
      "with Theorem 2, we can easily obtain the best/worst case\n",
      "equilibrium in terms of the total commuter delay.\n",
      "Example 1. To better clarify, we give a numerical exam-\n",
      "ple. Let d=fdAV;HO= 4; dAV;LO= 3; dHV;HO=\n",
      "4; dHV;LO= 5g. Assume the delay functions as BPR\n",
      "functions [18] in the form:\n",
      "i\u0012fii) =\u0012i+\n",
      "mi\u0013\fi\n",
      ";8i2I; (35)\n",
      "i= 1; \fi= 1; mi= 10 := 3; \n",
      "i2Ig. Whenfn= 4; \u0016= 0:5g, the lane choice equilibrium\n",
      "always exists and is unique when \u001C\u00150:7. Setting\u001C= 0:5,\n",
      "the resulting equilibria form a simplex. The best-case\n",
      "equilibrium in terms of the total commuter delay lies at\u0010\n",
      "fHV;LO\n",
      "1 = 0; fHV;HO\n",
      "1 = 1; fAV;LO\n",
      "1 = 0\u0011\n",
      ", and the worst\n",
      "equilibrium at\u0010\n",
      "fHV;LO\n",
      "1 = 1; fHV;HO\n",
      "1 = 0; fAV;LO\n",
      "1 = 0\u0011\n",
      ".\n",
      "Whenfn= 2; \u0016 = 0:4g, the equilibrium is unique\n",
      "when\u001C\u00150:74. Setting\u001C= 0:5, we have the best\n",
      "equilibrium at\u0010\n",
      "fHV;LO\n",
      "1 = 0; fHV;HO\n",
      "1 = 0; fAV;LO\n",
      "1 = 3\u0011\n",
      ",\n",
      "and the worst equilibrium at\u0010\n",
      "fHV;LO\n",
      "1 = 1:2; fHV;HO\n",
      "1 = 0; fAV;LO\n",
      "1 = 0\u0011\n",
      ".0 0.2 0.4 0.6 0.8 1\n",
      "Toll price 525354555657585960Total commuter delayworst case\n",
      "best caseFig. 3: The best/worst-case total commuter delay versus\n",
      "different toll values in Example 2.\n",
      "IV. D ESIGN THE TOLL\n",
      "One intriguing problem for the policy designers is to\n",
      "design the toll properly and therefore, induce the resulting\n",
      "choice equilibrium to a socially optimal one. The optimiza-\n",
      "tion problem can be formulated as\n",
      "min\n",
      "\u001C\u00150J(f)\n",
      "subject to Conditions (1) \u0000(11):\n",
      "Usually, optimization problems with equilibrium conditions\n",
      "are difﬁcult to deal with. However, with the characterization\n",
      "of the equilibria in section III, we propose a simple but\n",
      "effective algorithm to ﬁnd the optimal toll that minimizes\n",
      "the total commuter delay.\n",
      "At each value of toll, according to Theorem 1, the\n",
      "equilibrium is either on the pure strategy points or in the\n",
      "simplexS. The simplex is easily obtained by solving a single\n",
      "variable equation (14). Moreover, according to Theorem 2,\n",
      "the best/worst case equilibrium in terms of the total delay\n",
      "can be easily selected from the contour of S. Therefore, at\n",
      "each value of toll, the total delay or the best/worst total delay\n",
      "are easily calculated. Naturally, the toll optimization problem\n",
      "becomes a one dimensional search problem, which can be\n",
      "readily solved by well established algorithms such as golden\n",
      "section search. Also, the algorithm has no requirements for\n",
      "the convexity of delay conﬁgurations.\n",
      "Example 2. To better clarify, we use a numerical example\n",
      "to validate our method. Let fdAV;HO= 4; dAV;LO=\n",
      "3; dHV;HO= 4; dHV;LO= 5; n= 4; \u0016= 0:5g. Assume\n",
      "the delay functions as BPR functions with parameters D=\n",
      "i= 1; \fi= 1; mi= 10 :i2Ig. The plot of\n",
      "best/worst case total delay at different values of toll is shown\n",
      "in Figure 3. As we can see, in this case, with toll increasing,\n",
      "the worst case total delay increases, whereas the best case\n",
      "total delay ﬁrst decreases and then increases. We may choose\n",
      "the toll to be 0 to minimize the worst case total delay or we\n",
      "may choose the toll to be around 0.25 to minimize the best\n",
      "2 2.5 3 3.5 4\n",
      "Occupancy threshold n525354555657585960Total commuter delayworst case\n",
      "best caseFig. 4: The best/worst case total commuter delay versus\n",
      "different values of occupancy threshold nin Example 3.\n",
      "case total delay.\n",
      "V. D ESIGN THE OCCUPANCY THRESHOLD\n",
      "Another interesting problem is to ﬁnd a proper occu-\n",
      "pancy threshold n. With the ﬁxed total commuter demands,\n",
      "policy designers may want to set the value of nhigher\n",
      "to encourage a higher occupancy of vehicles, however, the\n",
      "carpooling difﬁculty at a higher nalso increases, which may\n",
      "lead to a decreased demand of commuters who are willing\n",
      "to carpool. To address such trade-off, in this section, we\n",
      "assume the demand of commuters who take human-driven\n",
      "or autonomous vehicles is ﬁxed, and is denoted by dHVand\n",
      "dAVrespectively. Also, for an occupancy threshold n\u00152,\n",
      "the probability of a commuter to carpool is p(n)2[0;1].\n",
      "The function p(\u0001)is a non-increasing function. Therefore,\n",
      "we have\n",
      "dHV;LO=dHV(1\u0000p(n)); (36)\n",
      "dHV;HO=dHVp(n); (37)\n",
      "dAV;LO=dAV(1\u0000p(n)): (38)\n",
      "To ﬁnd the optimal n, we are solving the optimization\n",
      "problem:\n",
      "min\n",
      "n\u00152J(f)\n",
      "subject to Conditions (1) \u0000(11):\n",
      "Similar to the toll design problem, we propose an effective\n",
      "solution algorithm with no requirement for the convexity\n",
      "of the delay conﬁgurations. At each value of n, we either\n",
      "obtain a pure strategy equilibrium or a simplex Saccording\n",
      "to Theorem 1. The best/worst case equilibrium in terms of\n",
      "the total delay can then be easily selected by Theorem 2.\n",
      "Therefore, at each value of n, the total delay or the best/worst\n",
      "total delay is obtained. Naturally, the n-optimization problem\n",
      "becomes a one dimensional search problem, which can be\n",
      "solved by algorithms such as golden section search. Notice\n",
      "that the algorithm works ﬁne with any candidate range of n\n",
      "even when the range is discrete.Example 3. We employ the following numerical example\n",
      "to support the proposed algorithm. Let fdAV= 7; dHV=\n",
      "9; \u0016= 0:5; \u001C= 0:5g. Assume the delay functions as BPR\n",
      "i= 1; \fi= with parameters D=f\u0012i= 3; \n",
      "1; mi= 10 :i2Ig. We assume p(n) =1\n",
      "nfor any\n",
      "n2[2;4]. The corresponding total delay of each value of\n",
      "nis shown in Figure 4. As we can see from the result,\n",
      "increasingndoes not necessarily decrease the total delay.\n",
      "VI. D ESIGN THE POLICY\n",
      "Currently on the roads, we have high-occupancy vehicle\n",
      "lanes which are reserved freely for high-occupancy vehicles\n",
      "and let other vehicles enter with a toll. With the development\n",
      "of the autonomous driving technologies, the concept of\n",
      "dedicated lanes, which are reserved freely for autonomous\n",
      "vehicles and other vehicles may enter with a toll, has also\n",
      "been proposed and experimented. However, in a scenario\n",
      "where human-driven/autonomous vehicles with low/high-\n",
      "occupancy are sharing the roads, with limited budget, is\n",
      "it better to employ a high-occupancy vehicle lane or a\n",
      "dedicated lane for autonomous vehicles? In this section, we\n",
      "ﬁrst elaborate how the policies of high-occupancy vehicle\n",
      "lanes and dedicated lanes for autonomous vehicles ﬁt into\n",
      "the toll lane framework in section II and further investigate\n",
      "the proper choice of the policy.\n",
      "The high-occupancy vehicle lane policy admits all high-\n",
      "occupancy vehicles to travel freely. Thus, we can see the\n",
      "high-occupancy vehicle lane policy as a special case when\n",
      "we always have fHV;HO\n",
      "1 =dHV;HO\n",
      "n. And the two classes of\n",
      "vehicles making lane choices are human-driven/autonomous\n",
      "low-occupancy vehicles. The properties of the resulting equi-\n",
      "libria then can be investigated by Theorem 1 and 2. The\n",
      "dedicated lane policy admits all autonomous vehicles freely.\n",
      "Thus, we can see the dedicated lane policy as a special case\n",
      "whenfAV;LO\n",
      "1 =dAV;LO. And the two classes of vehicles\n",
      "making lane choices are human-driven low/high-occupancy\n",
      "vehicles. Theorem 1 and 2 can then be applied to characterize\n",
      "the properties of the resulting equilibria.\n",
      "For a speciﬁc segment of highway with a uniform toll,\n",
      "under either of the policies, according to Theorem 1, the\n",
      "resulting equilibrium can be obtained if it is unique or\n",
      "otherwise, the best/worst case equilibrium in terms of the\n",
      "total delay can be obtained by Theorem 2. Therefore, the\n",
      "evaluation of the strategies becomes a rather simple problem.\n",
      "Example 4. To better clarify, we use the following numerical\n",
      "example. LetfdAV;HO= 4; dAV;LO= 3; dHV;HO=\n",
      "4; dHV;LO= 5; n = 4; \u0016 = 0:5g. Assume the delay\n",
      "functions as BPR functions with parameters D=f\u0012i=\n",
      "i= 1; \fi= 1; mi= 10 :i2Ig. The comparison\n",
      "of the two policies can be seen in Figure 5. As we can see,\n",
      "for this segment of highway, with any toll value, the high-\n",
      "occupancy vehicle lane policy outperforms the dedicated lane\n",
      "policy for autonomous vehicles.\n",
      "VII. D IFFERENTIATE THE TOLLS\n",
      "Further, we consider the scenario where the three tolled\n",
      "classes of vehicles are assigned with heterogeneous tolls.\n",
      "0 0.2 0.4 0.6 0.8 1\n",
      "Toll price 5353.55454.55555.556Total commuter delayHOVL-worst case\n",
      "HOVL-best case\n",
      "DLA-worst case\n",
      "DLA-best caseFig. 5: The best/worst case total delay versus different\n",
      "toll values under the dedicated lane policy for autonomous\n",
      "vehicles (DLA) or the high-occupancy vehicle lane policy\n",
      "(HOVL) in Example 4.\n",
      "Instead of using a uniform toll, we deﬁne a vector toll\n",
      "\u001C:=\u0000\n",
      "\u001CHV;LO; \u001CHV;HO; \u001CAV;LO\u0001\n",
      "containing the tolls for\n",
      "the three classes of vehicles. Correspondingly, we let J(\u001C)\n",
      "be the total commuter delay under the heterogeneous vec-\n",
      "tor toll \u001C. The toll optimization problem as described in\n",
      "Section IV when tolls are heterogeneous is a nontrivial bi-\n",
      "level optimization problem, which may potentially be solved\n",
      "by iterative optimization algorithms. However, iterative algo-\n",
      "rithms may take time to converge and for non-convex delay\n",
      "conﬁgurations, the convergence is not guaranteed. Therefore,\n",
      "we propose another efﬁcient method to decrease the total\n",
      "delay: ﬁrst, assuming all tolls are uniform, ﬁnd the optimal\n",
      "toll which has the smallest best case total delay according to\n",
      "the method described in Section IV; second, if the optimal\n",
      "toll is non-zero and there are multiple equilibria under the\n",
      "optimal uniform toll, differentiate the tolls and induce the\n",
      "best case equilibrium under the optimal uniform toll. This\n",
      "way, we can effectively decrease the total delay without any\n",
      "requirement for the algorithm convergence. Notice that we\n",
      "exclude the case when the optimal toll is zero, since the\n",
      "multiple equilibria under zero toll share the same total delay.\n",
      "Speciﬁcally, we can differentiate the tolls according to the\n",
      "following proposition.\n",
      "Proposition 2. For a segment of highway G =\n",
      "(D;d;\u001C\u0003;n;\u0016 ), where\u001C\u0003>0is a predetermined optimal\n",
      "uniform toll which induce non-unique equilibria, let J\u0003(\u001C\u0003)\n",
      "be the best total commuter delay under the uniform toll \u001C\u0003.\n",
      "Let\u001C\u0000\u00150be any value of toll satisfying \u001C\u0000< \u001C\u0003and\n",
      "\u001C+>0be any value of toll satisfying \u001C+>\u001C\u0003.\n",
      "\u000FIfn\u00141\n",
      "\u0016,\n",
      "–iff\u0003\n",
      "1\u0014\u0016\u0010\n",
      "dAV;LO+dAV;HO\n",
      "n\u0011\n",
      ", then set \u001C=\n",
      "(\u001C+; \u001C+; \u001C\u0003)and we have J(\u001C) =J\u0003(\u001C\u0003).\n",
      "–if\u0016\u0010\n",
      "dAV;LO+dAV;HO\n",
      "n\u0011\n",
      "< f\u0003\n",
      "1\u0014dHV;HO\n",
      "n+\n",
      "\u0016\u0010\n",
      "dAV;LO+dAV;HO\n",
      "n\u0011\n",
      ", then set \u001C= (\u001C+;\u001C\u0003;\u001C\u0000)and we have J(\u001C) =J\u0003(\u001C\u0003).\n",
      "–ifdHV;HO\n",
      "n+\u0016\u0010\n",
      "dAV;LO+dAV;HO\n",
      "n\u0011\n",
      "<f\u0003\n",
      "1, then set \u001C=\n",
      "(\u001C\u0003;\u001C\u0000;\u001C\u0000)and we have J(\u001C) =J\u0003(\u001C\u0003).\n",
      "\u000FIfn>1\n",
      "\u0016,\n",
      "–iff\u0003\n",
      "1\u0014dHV;HO\n",
      "n+\u0016dAV;HO\n",
      "n, then set \u001C= (\u001C+;\u001C\u0003;\u001C+)\n",
      "and we have J(\u001C) =J\u0003(\u001C\u0003).\n",
      "–b) ifdHV;HO\n",
      "n+\u0016dAV;HO\n",
      "n< f\u0003\n",
      "1\u0014dHV;HO\n",
      "n+\n",
      "\u0016\u0010\n",
      "dAV;LO+dAV;HO\n",
      "n\u0011\n",
      ", then set \u001C= (\u001C+;\u001C\u0000;\u001C\u0003)\n",
      "and we have J(\u001C) =J\u0003(\u001C\u0003).\n",
      "–c) ifdHV;HO\n",
      "n+\u0016\u0010\n",
      "dAV;LO+dAV;HO\n",
      "n\u0011\n",
      "<f\u0003\n",
      "1, then set\n",
      "\u001C= (\u001C\u0003;\u001C\u0000;\u001C\u0000)and we have J(\u001C) =J\u0003(\u001C\u0003).\n",
      "Proof. We give the detailed explanation for the ﬁrst sub-\n",
      "case whenn\u00141\n",
      "\u0016. According to Theorem 2, when n\u00141\n",
      "\u0016,\n",
      "we should ﬁrst prioritize autonomous vehicles with low\n",
      "occupancy on lane 1. When f\u0003\n",
      "1\u0014\u0016\u0010\n",
      "dAV;LO+dAV;HO\n",
      "n\u0011\n",
      ",\n",
      "the best equilibrium under the optimal uniform toll would\n",
      "be(0;0;f\u0003\n",
      "1\u0000fmin\n",
      "1\n",
      "\u0016). One can check that (0;0;f\u0003\n",
      "1\u0000fmin\n",
      "1\n",
      "\u0016)is\n",
      "an equilibrium and is the only equilibrium that fulﬁlls\n",
      "Deﬁnition 1 when tolls are selected as \u001C. The proof for other\n",
      "cases follows the same logic, thus omitted here.\n",
      "The general idea of this toll design proposition is to ﬁrst\n",
      "identify the best equilibrium, and then assign the toll of\n",
      "\u001C\u0003to the class of vehicles that use both lanes at the best\n",
      "equilibrium, a toll higher than \u001C\u0003to the class of vehicles\n",
      "less prior and a toll lower than \u001C\u0003to the class of vehicles\n",
      "more prior.\n",
      "VIII. CONCLUSION\n",
      "We proposed a toll lane framework where four classes\n",
      "of vehicles are sharing a segment of highway: autonomous\n",
      "vehicles with high occupancy travel freely on a reserved\n",
      "lane and the other three classes of vehicles: human-driven\n",
      "vehicles with low occupancy, human-driven vehicles with\n",
      "high occupancy, autonomous vehicles with low occupancy\n",
      "can choose to enter the reserved lane paying a toll or use the\n",
      "other regular lanes freely. We consider all vehicles are selﬁsh\n",
      "and established desirable properties of the resulting lane\n",
      "choice equilibria, which implicitly compare high-occupancy\n",
      "vehicles with autonomous vehicles in terms of their capabil-\n",
      "ities to increase the social mobility. We further clariﬁed the\n",
      "various potential applications of this toll lane framework that\n",
      "unites high-occupancy vehicles and autonomous vehicles in\n",
      "the optimal toll design, occupancy threshold design and the\n",
      "policy design problems.\n",
      "ACKNOWLEDGMENTS\n",
      "This work was supported by the National Science Foun-\n",
      "dation under Grants CPS 1545116 and ECCS-2013779.\n",
      "REFERENCES\n",
      "[1] C. M. Farmer, “Crash avoidance potential of ﬁve vehicle technologies,”\n",
      "Insurance Institute for Highway Safety , 2008.\n",
      "[2] S. A. Bagloee, M. Tavana, M. Asadi, and T. Oliver, “Autonomous\n",
      "vehicles: challenges, opportunities, and future implications for trans-\n",
      "portation policies,” Journal of modern transportation , vol. 24, no. 4,\n",
      "pp. 284–303, 2016.[3] B. Asadi and A. Vahidi, “Predictive cruise control: Utilizing upcoming\n",
      "trafﬁc signal information for improving fuel economy and reducing\n",
      "trip time,” IEEE transactions on control systems technology , vol. 19,\n",
      "no. 3, pp. 707–714, 2010.\n",
      "[4] L. Luo, H. Liu, P. Li, and H. Wang, “Model predictive control for\n",
      "adaptive cruise control with multi-objectives: comfort, fuel-economy,\n",
      "safety and car-following,” Journal of Zhejiang University SCIENCE\n",
      "A, vol. 11, no. 3, pp. 191–201, 2010.\n",
      "[5] I. H. Zohdy, R. K. Kamalanathsharma, and H. Rakha, “Intersection\n",
      "management for autonomous vehicles using icacc,” in 2012 15th\n",
      "international IEEE conference on intelligent transportation systems .\n",
      "IEEE, 2012, pp. 1109–1114.\n",
      "[6] A. Talebpour and H. S. Mahmassani, “Inﬂuence of connected and\n",
      "autonomous vehicles on trafﬁc ﬂow stability and throughput,” Trans-\n",
      "portation Research Part C: Emerging Technologies , vol. 71, pp. 143–\n",
      "163, 2016.\n",
      "[7] J. Lioris, R. Pedarsani, F. Y . Tascikaraoglu, and P. Varaiya, “Platoons\n",
      "of connected vehicles can double throughput in urban roads,” Trans-\n",
      "portation Research Part C: Emerging Technologies , vol. 77, pp. 292–\n",
      "305, 2017.\n",
      "[8] N. Mehr and R. Horowitz, “How will the presence of autonomous\n",
      "vehicles affect the equilibrium state of trafﬁc networks?” IEEE Trans-\n",
      "actions on Control of Network Systems , vol. 7, no. 1, pp. 96–105,\n",
      "2019.\n",
      "[9] H. S. Mahmassani, “50th anniversary invited article—autonomous\n",
      "vehicles and connected vehicle systems: Flow and operations con-\n",
      "siderations,” Transportation Science , vol. 50, no. 4, pp. 1140–1162,\n",
      "2016.\n",
      "[10] L. Ye and T. Yamamoto, “Impact of dedicated lanes for connected and\n",
      "autonomous vehicle on trafﬁc ﬂow throughput,” Physica A: Statistical\n",
      "Mechanics and its Applications , vol. 512, pp. 588–597, 2018.\n",
      "[11] J. Ivanchev, A. Knoll, D. Zehe, S. Nair, and D. Eckhoff, “A macro-\n",
      "scopic study on dedicated highway lanes for autonomous vehicles,” in\n",
      "International Conference on Computational Science . Springer, 2019,\n",
      "pp. 520–533.\n",
      "[12] A. Talebpour, H. S. Mahmassani, and A. Elfar, “Investigating the\n",
      "effects of reserved lanes for autonomous vehicles on congestion and\n",
      "travel time reliability,” Transportation Research Record , vol. 2622,\n",
      "no. 1, pp. 1–12, 2017. [Online]. Available: https://doi.org/10.3141/\n",
      "2622-01\n",
      "[13] Z. Zhong, “Assessing the effectiveness of managed lane strategies for\n",
      "the rapid deployment of cooperative adaptive cruise control technol-\n",
      "ogy,” 2018.\n",
      "[14] Z. Liu and Z. Song, “Strategic planning of dedicated autonomous\n",
      "vehicle lanes and autonomous vehicle/toll lanes in transportation\n",
      "networks,” Transportation Research Part C: Emerging Technologies ,\n",
      "vol. 106, pp. 381–403, 2019.\n",
      "[15] L. Xiao, M. Wang, and B. van Arem, “Trafﬁc ﬂow impacts of\n",
      "converting an hov lane into a dedicated cacc lane on a freeway\n",
      "corridor,” IEEE Intelligent Transportation Systems Magazine , vol. 12,\n",
      "no. 1, pp. 60–73, 2019.\n",
      "[16] Y . Guo and J. Ma, “Leveraging existing high-occupancy vehicle lanes\n",
      "for mixed-autonomy trafﬁc management with emerging connected au-\n",
      "tomated vehicle applications,” Transportmetrica A: Transport Science ,\n",
      "vol. 16, no. 3, pp. 1375–1399, 2020.\n",
      "[17] R. Li, N. Mehr, and R. Horowitz, “The impact of autonomous vehicles’\n",
      "headway on the social delay of trafﬁc networks,” in 2020 59th IEEE\n",
      "Conference on Decision and Control (CDC) . IEEE, 2020, pp. 268–\n",
      "273.\n",
      "[18] U. B. O. P. Roads, “Trafﬁc assignment manual,” US Department of\n",
      "Commerce, Washington, DC , 1964.\n",
      "[19] D. A. Lazar, S. Coogan, and R. Pedarsani, “Capacity modeling and\n",
      "routing for trafﬁc networks with mixed autonomy,” in Decision and\n",
      "Control (CDC), 2017 IEEE 56th Conference on, to appear, IEEE ,\n",
      "2017.\n",
      "[20] J. G. Wardrop, “Some theoretical aspects of road trafﬁc research,” in\n",
      "Proceedings of the Institution of Civil Engineers, Volume 1 Issue 3 ,\n",
      "1952, pp. 325–362.\n",
      "[21] D. Braess and G. Koch, “On the existence of equilibria in asymmet-\n",
      "rical multiclass-user transportation networks,” Transportation Science ,\n",
      "vol. 13, no. 1, pp. 56–63, 1979.\n"
     ]
    }
   ],
   "source": [
    "print(extract_papers(\"Autonomous Vehicles\", 5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
